{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saidm\\Documents\\Universidad\\9no_Semestre\\Data Mining\\Deberes\\Deep-Learning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>183</td>\n",
       "      <td>165</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>165</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>206</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>121</td>\n",
       "      <td>104</td>\n",
       "      <td>103</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>132</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>167</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>175</td>\n",
       "      <td>156</td>\n",
       "      <td>160</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>181</td>\n",
       "      <td>178</td>\n",
       "      <td>181</td>\n",
       "      <td>159</td>\n",
       "      <td>153</td>\n",
       "      <td>172</td>\n",
       "      <td>151</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>160</td>\n",
       "      <td>124</td>\n",
       "      <td>146</td>\n",
       "      <td>164</td>\n",
       "      <td>131</td>\n",
       "      <td>152</td>\n",
       "      <td>167</td>\n",
       "      <td>127</td>\n",
       "      <td>146</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>162</td>\n",
       "      <td>167</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>162</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>175</td>\n",
       "      <td>142</td>\n",
       "      <td>121</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>133</td>\n",
       "      <td>178</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>174</td>\n",
       "      <td>137</td>\n",
       "      <td>125</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "10010        183        165        181        182        165        180   \n",
       "10011          2          3          1         38         33         32   \n",
       "10012        132        118        118        167        149        149   \n",
       "10013        160        124        146        164        131        152   \n",
       "10014        175        142        121        181        150        134   \n",
       "\n",
       "       pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2343  pixel2344  \\\n",
       "10010        184        166        182        188  ...        208        185   \n",
       "10011        121        104        103        132  ...         96         79   \n",
       "10012        175        156        160        184  ...        204        181   \n",
       "10013        167        127        146        169  ...        185        162   \n",
       "10014        181        150        133        178  ...        159         79   \n",
       "\n",
       "       pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "10010        187        208        186        186        206        187   \n",
       "10011         76         24         23         21          3          4   \n",
       "10012        178        181        159        153        172        151   \n",
       "10013        167        184        157        166        185        162   \n",
       "10014         82        174        137        125        175        139   \n",
       "\n",
       "       pixel2351  label  \n",
       "10010        189      0  \n",
       "10011          1      0  \n",
       "10012        145      0  \n",
       "10013        172      0  \n",
       "10014        126      6  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfpath=\"hmnist_28_28_RGB.csv\"\n",
    "df=pd.read_csv(dfpath)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 28, 28, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Extracting 'y' column\n",
    "y = df['label']\n",
    "# Extracting 'X' DataFrame without the 'label' column\n",
    "X = df.drop(columns=['label'])\n",
    "# Normalizing the 'X' DataFrame\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_resize=np.array([i.reshape(28,28,3) for i in np.array(X)  ])\n",
    "X_resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, roc_curve, auc, precision_recall_curve,roc_curve, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization,ReLU,Add,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input, Model\n",
    "#from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "\n",
    "# Define your CNN model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "model = load_model(\"model_keras.keras\",compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "\n",
    "# Define your CNN model\n",
    "def create_model():\n",
    "    model_cnn = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3,3), input_shape=(28, 28, 3), activation='relu', padding='same'),\n",
    "        MaxPool2D(pool_size=(2,2), strides=2),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "        MaxPool2D(pool_size=(2,2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(units=7, activation='softmax')\n",
    "    ])\n",
    "    return model_cnn\n",
    "\n",
    "def create_model_2():\n",
    "    model_cnn = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(7, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model_cnn\n",
    "def create_resnet_model():\n",
    "    \n",
    "    def residual_block(x, filters, kernel_size=3, strides=2):\n",
    "        # First convolutional layer\n",
    "        y = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        y = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        # Shortcut connection\n",
    "        if strides != 1:\n",
    "            x = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "        # Add the shortcut and residual\n",
    "        y = Add()([x, y])\n",
    "        y = ReLU()(y)\n",
    "        return y\n",
    "    inputs = Input(shape=(28, 28, 3))\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "    # First residual block\n",
    "    x = residual_block(x, 64, strides=4)\n",
    "    # Second residual block\n",
    "    x = residual_block(x, 64)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(7, activation='softmax')(x)\n",
    "\n",
    "    model_resnet = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model_resnet\n",
    "\n",
    "# Define function to train and evaluate model\n",
    "def train_evaluate_model(X_train, y_train, X_test, y_test,num_model):\n",
    "\n",
    "    model = create_resnet_model()\n",
    "    checkpoint_dir='model_'+str(num_model)\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_path = checkpoint_dir+'/'+\"checkpoint.weights.h5\" \n",
    "    \n",
    "    cp_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.save(checkpoint_dir+'/'+'model.keras')\n",
    "    history = model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), callbacks=[cp_callback])\n",
    "    #model=load_model(checkpoint_dir+'/model.h5')\n",
    "    eval_metrics = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    auc_score= roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "    acc = accuracy_score(y_test, y_pred_classes)\n",
    "    precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "    mcc = matthews_corrcoef(y_test, y_pred_classes)\n",
    "    loss = eval_metrics[0]\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "    return acc, auc_score, precision, recall, f1, mcc, loss, cm, y_pred,history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define function to plot AUC-ROC and Precision-Recall curves for multiclass\n",
    "from itertools import cycle\n",
    "from sklearn.calibration import label_binarize\n",
    "def plot_curves(y_true, y_pred_prob, n_classes):\n",
    "        # Binarize the output\n",
    "        y_true_bin = label_binarize(y_true, classes=[0, 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_prob.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # Compute Precision-Recall curve for each class\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        for i in range(n_classes):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot ROC curve for each class\n",
    "        plt.subplot(1, 2, 1)\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'green', 'purple', 'yellow'])\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2, label='ROC curve of class {0} (AUC = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        # Plot Precision-Recall curve for each class\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(recall[i], precision[i], color=color, lw=2, label='Precision-Recall curve of class {0}'.format(i))\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another function. First we calculate the roc_auc_score for each class and then we calculate the mean of all the scores. and then we plot the roc curve\n",
    "# we do the same for the precision-recall curve\n",
    "def plot_curves_v2(y_true, y_pred_prob, n_classes):\n",
    "    # Binarize the output\n",
    "    y_true_bin = label_binarize(y_true, classes=[0, 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_prob.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Compute Precision-Recall curve for each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    \n",
    "    # Compute micro-average Precision-Recall curve and area\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true_bin.ravel(), y_pred_prob.ravel())\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "   #calculate the mean of the roc_auc_score\n",
    "    all_auc = np.mean(list(roc_auc.values()))\n",
    "    # Plot all_auc score\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % all_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic mean AUC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Plot all_precision-recall score\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall[\"micro\"], precision[\"micro\"], color='green', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve mean Precision and Recall')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n",
      "Epoch 1/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6071 - loss: 1.1761\n",
      "Epoch 1: val_loss improved from inf to 1.36376, saving model to model_0/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6086 - loss: 1.1710 - val_accuracy: 0.6617 - val_loss: 1.3638\n",
      "Epoch 2/200\n",
      "\u001b[1m273/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7133 - loss: 0.8020\n",
      "Epoch 2: val_loss improved from 1.36376 to 0.90770, saving model to model_0/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7133 - loss: 0.8017 - val_accuracy: 0.6846 - val_loss: 0.9077\n",
      "Epoch 3/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7388 - loss: 0.7269\n",
      "Epoch 3: val_loss improved from 0.90770 to 0.78550, saving model to model_0/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7388 - loss: 0.7269 - val_accuracy: 0.7166 - val_loss: 0.7855\n",
      "Epoch 4/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7487 - loss: 0.6926\n",
      "Epoch 4: val_loss improved from 0.78550 to 0.75829, saving model to model_0/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7488 - loss: 0.6921 - val_accuracy: 0.7265 - val_loss: 0.7583\n",
      "Epoch 5/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7707 - loss: 0.6326\n",
      "Epoch 5: val_loss improved from 0.75829 to 0.75001, saving model to model_0/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7707 - loss: 0.6326 - val_accuracy: 0.7255 - val_loss: 0.7500\n",
      "Epoch 6/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7935 - loss: 0.5728\n",
      "Epoch 6: val_loss improved from 0.75001 to 0.73603, saving model to model_0/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7935 - loss: 0.5730 - val_accuracy: 0.7425 - val_loss: 0.7360\n",
      "Epoch 7/200\n",
      "\u001b[1m273/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7970 - loss: 0.5679\n",
      "Epoch 7: val_loss improved from 0.73603 to 0.73078, saving model to model_0/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7971 - loss: 0.5673 - val_accuracy: 0.7345 - val_loss: 0.7308\n",
      "Epoch 8/200\n",
      "\u001b[1m273/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8235 - loss: 0.5025\n",
      "Epoch 8: val_loss improved from 0.73078 to 0.70203, saving model to model_0/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8230 - loss: 0.5031 - val_accuracy: 0.7445 - val_loss: 0.7020\n",
      "Epoch 9/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.4855\n",
      "Epoch 9: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.4855 - val_accuracy: 0.7405 - val_loss: 0.8175\n",
      "Epoch 10/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.4590\n",
      "Epoch 10: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 0.4588 - val_accuracy: 0.7455 - val_loss: 0.7793\n",
      "Epoch 11/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8508 - loss: 0.4159\n",
      "Epoch 11: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8508 - loss: 0.4159 - val_accuracy: 0.6936 - val_loss: 0.8125\n",
      "Epoch 12/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8654 - loss: 0.3882\n",
      "Epoch 12: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8654 - loss: 0.3882 - val_accuracy: 0.7096 - val_loss: 0.8197\n",
      "Epoch 13/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8775 - loss: 0.3546\n",
      "Epoch 13: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8775 - loss: 0.3547 - val_accuracy: 0.7435 - val_loss: 0.8415\n",
      "Epoch 14/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8812 - loss: 0.3311\n",
      "Epoch 14: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8812 - loss: 0.3312 - val_accuracy: 0.7375 - val_loss: 0.9127\n",
      "Epoch 15/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8936 - loss: 0.3121\n",
      "Epoch 15: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8935 - loss: 0.3121 - val_accuracy: 0.7216 - val_loss: 0.8427\n",
      "Epoch 16/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9074 - loss: 0.2789\n",
      "Epoch 16: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9073 - loss: 0.2789 - val_accuracy: 0.7465 - val_loss: 0.8333\n",
      "Epoch 17/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9199 - loss: 0.2378\n",
      "Epoch 17: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9197 - loss: 0.2381 - val_accuracy: 0.7186 - val_loss: 0.8463\n",
      "Epoch 18/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9278 - loss: 0.2236\n",
      "Epoch 18: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9276 - loss: 0.2239 - val_accuracy: 0.7415 - val_loss: 0.9072\n",
      "Epoch 19/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9310 - loss: 0.2155\n",
      "Epoch 19: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9309 - loss: 0.2156 - val_accuracy: 0.6766 - val_loss: 1.0727\n",
      "Epoch 20/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.1848\n",
      "Epoch 20: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.1848 - val_accuracy: 0.7555 - val_loss: 0.8896\n",
      "Epoch 21/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.1625\n",
      "Epoch 21: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9481 - loss: 0.1627 - val_accuracy: 0.7365 - val_loss: 0.9687\n",
      "Epoch 22/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9573 - loss: 0.1394\n",
      "Epoch 22: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9571 - loss: 0.1397 - val_accuracy: 0.7275 - val_loss: 0.9748\n",
      "Epoch 23/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9590 - loss: 0.1306\n",
      "Epoch 23: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.1307 - val_accuracy: 0.7475 - val_loss: 0.9670\n",
      "Epoch 24/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.1097\n",
      "Epoch 24: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9705 - loss: 0.1098 - val_accuracy: 0.7475 - val_loss: 0.9928\n",
      "Epoch 25/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9664 - loss: 0.1073\n",
      "Epoch 25: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9664 - loss: 0.1074 - val_accuracy: 0.7485 - val_loss: 1.0239\n",
      "Epoch 26/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9677 - loss: 0.1068\n",
      "Epoch 26: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9677 - loss: 0.1069 - val_accuracy: 0.7236 - val_loss: 1.1292\n",
      "Epoch 27/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.0891\n",
      "Epoch 27: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9728 - loss: 0.0892 - val_accuracy: 0.7345 - val_loss: 1.3552\n",
      "Epoch 28/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9744 - loss: 0.0831\n",
      "Epoch 28: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.0831 - val_accuracy: 0.7236 - val_loss: 1.2424\n",
      "Epoch 29/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0743\n",
      "Epoch 29: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0742 - val_accuracy: 0.7236 - val_loss: 1.2171\n",
      "Epoch 30/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.0668\n",
      "Epoch 30: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0674 - val_accuracy: 0.7485 - val_loss: 1.2545\n",
      "Epoch 31/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9806 - loss: 0.0675\n",
      "Epoch 31: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0676 - val_accuracy: 0.7355 - val_loss: 1.2597\n",
      "Epoch 32/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0639\n",
      "Epoch 32: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0638 - val_accuracy: 0.7216 - val_loss: 1.3878\n",
      "Epoch 33/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0542\n",
      "Epoch 33: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0542 - val_accuracy: 0.7275 - val_loss: 1.3849\n",
      "Epoch 34/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9875 - loss: 0.0474\n",
      "Epoch 34: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9875 - loss: 0.0474 - val_accuracy: 0.7405 - val_loss: 1.4665\n",
      "Epoch 35/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9848 - loss: 0.0499\n",
      "Epoch 35: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9848 - loss: 0.0499 - val_accuracy: 0.7425 - val_loss: 1.4564\n",
      "Epoch 36/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9806 - loss: 0.0582\n",
      "Epoch 36: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0584 - val_accuracy: 0.7265 - val_loss: 1.5138\n",
      "Epoch 37/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0629\n",
      "Epoch 37: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0629 - val_accuracy: 0.7355 - val_loss: 1.3029\n",
      "Epoch 38/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0337\n",
      "Epoch 38: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0338 - val_accuracy: 0.7375 - val_loss: 1.3394\n",
      "Epoch 39/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0265\n",
      "Epoch 39: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0265 - val_accuracy: 0.7315 - val_loss: 1.5278\n",
      "Epoch 40/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9853 - loss: 0.0480\n",
      "Epoch 40: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0483 - val_accuracy: 0.7206 - val_loss: 1.5208\n",
      "Epoch 41/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0404\n",
      "Epoch 41: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0404 - val_accuracy: 0.7615 - val_loss: 1.2990\n",
      "Epoch 42/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0269\n",
      "Epoch 42: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0269 - val_accuracy: 0.7385 - val_loss: 1.4807\n",
      "Epoch 43/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0314\n",
      "Epoch 43: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0313 - val_accuracy: 0.7465 - val_loss: 1.5772\n",
      "Epoch 44/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0288\n",
      "Epoch 44: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0290 - val_accuracy: 0.7525 - val_loss: 1.4929\n",
      "Epoch 45/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.0654\n",
      "Epoch 45: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9778 - loss: 0.0652 - val_accuracy: 0.7505 - val_loss: 1.4300\n",
      "Epoch 46/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0221\n",
      "Epoch 46: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0222 - val_accuracy: 0.7465 - val_loss: 1.6584\n",
      "Epoch 47/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0350\n",
      "Epoch 47: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0351 - val_accuracy: 0.7465 - val_loss: 1.4909\n",
      "Epoch 48/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0393\n",
      "Epoch 48: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0392 - val_accuracy: 0.7455 - val_loss: 1.4649\n",
      "Epoch 49/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0299\n",
      "Epoch 49: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0299 - val_accuracy: 0.7425 - val_loss: 1.5906\n",
      "Epoch 50/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0152\n",
      "Epoch 50: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0152 - val_accuracy: 0.7485 - val_loss: 1.4707\n",
      "Epoch 51/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0194\n",
      "Epoch 51: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0195 - val_accuracy: 0.7026 - val_loss: 1.8170\n",
      "Epoch 52/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9813 - loss: 0.0503\n",
      "Epoch 52: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0506 - val_accuracy: 0.7176 - val_loss: 2.0468\n",
      "Epoch 53/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0472\n",
      "Epoch 53: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0472 - val_accuracy: 0.7495 - val_loss: 1.6085\n",
      "Epoch 54/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0199\n",
      "Epoch 54: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0199 - val_accuracy: 0.7325 - val_loss: 1.6096\n",
      "Epoch 55/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0182\n",
      "Epoch 55: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0182 - val_accuracy: 0.7525 - val_loss: 1.5309\n",
      "Epoch 56/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0178\n",
      "Epoch 56: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0178 - val_accuracy: 0.7495 - val_loss: 1.6225\n",
      "Epoch 57/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0280\n",
      "Epoch 57: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0281 - val_accuracy: 0.7565 - val_loss: 1.5890\n",
      "Epoch 58/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0281\n",
      "Epoch 58: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0281 - val_accuracy: 0.7565 - val_loss: 1.5383\n",
      "Epoch 59/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0166\n",
      "Epoch 59: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0166 - val_accuracy: 0.7146 - val_loss: 1.7666\n",
      "Epoch 60/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0222\n",
      "Epoch 60: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0222 - val_accuracy: 0.7465 - val_loss: 1.7350\n",
      "Epoch 61/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0236\n",
      "Epoch 61: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0235 - val_accuracy: 0.7395 - val_loss: 1.6557\n",
      "Epoch 62/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0125\n",
      "Epoch 62: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0126 - val_accuracy: 0.7226 - val_loss: 2.0388\n",
      "Epoch 63/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9766 - loss: 0.0702\n",
      "Epoch 63: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0699 - val_accuracy: 0.7525 - val_loss: 1.6875\n",
      "Epoch 64/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0200\n",
      "Epoch 64: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0199 - val_accuracy: 0.7425 - val_loss: 1.6328\n",
      "Epoch 65/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0110\n",
      "Epoch 65: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0110 - val_accuracy: 0.7435 - val_loss: 1.6713\n",
      "Epoch 66/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0098\n",
      "Epoch 66: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0098 - val_accuracy: 0.7535 - val_loss: 1.8289\n",
      "Epoch 67/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0195\n",
      "Epoch 67: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0196 - val_accuracy: 0.7166 - val_loss: 1.7628\n",
      "Epoch 68/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9841 - loss: 0.0460\n",
      "Epoch 68: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9842 - loss: 0.0457 - val_accuracy: 0.7505 - val_loss: 1.7200\n",
      "Epoch 69/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0232\n",
      "Epoch 69: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0232 - val_accuracy: 0.7565 - val_loss: 1.7712\n",
      "Epoch 70/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0183\n",
      "Epoch 70: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0183 - val_accuracy: 0.7575 - val_loss: 1.6723\n",
      "Epoch 71/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0247\n",
      "Epoch 71: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0246 - val_accuracy: 0.7435 - val_loss: 1.6298\n",
      "Epoch 72/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0153\n",
      "Epoch 72: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0155 - val_accuracy: 0.7325 - val_loss: 2.1392\n",
      "Epoch 73/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0267\n",
      "Epoch 73: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0266 - val_accuracy: 0.7505 - val_loss: 1.8649\n",
      "Epoch 74/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0115\n",
      "Epoch 74: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0115 - val_accuracy: 0.7345 - val_loss: 1.7514\n",
      "Epoch 75/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0150\n",
      "Epoch 75: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0151 - val_accuracy: 0.7335 - val_loss: 2.4607\n",
      "Epoch 76/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0276\n",
      "Epoch 76: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0278 - val_accuracy: 0.7505 - val_loss: 1.7723\n",
      "Epoch 77/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0242\n",
      "Epoch 77: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0242 - val_accuracy: 0.7515 - val_loss: 1.7345\n",
      "Epoch 78/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0182\n",
      "Epoch 78: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0181 - val_accuracy: 0.7545 - val_loss: 1.7588\n",
      "Epoch 79/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0064\n",
      "Epoch 79: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0064 - val_accuracy: 0.7455 - val_loss: 1.7955\n",
      "Epoch 80/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0058\n",
      "Epoch 80: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0058 - val_accuracy: 0.7585 - val_loss: 1.7638\n",
      "Epoch 81/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0077\n",
      "Epoch 81: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0077 - val_accuracy: 0.7405 - val_loss: 1.9809\n",
      "Epoch 82/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9944 - loss: 0.0169\n",
      "Epoch 82: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0171 - val_accuracy: 0.6806 - val_loss: 2.2475\n",
      "Epoch 83/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0601\n",
      "Epoch 83: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0599 - val_accuracy: 0.7495 - val_loss: 2.1469\n",
      "Epoch 84/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9885 - loss: 0.0311\n",
      "Epoch 84: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9885 - loss: 0.0310 - val_accuracy: 0.7545 - val_loss: 1.8501\n",
      "Epoch 85/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0133\n",
      "Epoch 85: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0133 - val_accuracy: 0.7655 - val_loss: 1.7234\n",
      "Epoch 86/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0117\n",
      "Epoch 86: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0116 - val_accuracy: 0.7735 - val_loss: 1.7318\n",
      "Epoch 87/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0073\n",
      "Epoch 87: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.7515 - val_loss: 1.9087\n",
      "Epoch 88/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0263\n",
      "Epoch 88: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0262 - val_accuracy: 0.7385 - val_loss: 1.9991\n",
      "Epoch 89/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0187\n",
      "Epoch 89: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0186 - val_accuracy: 0.7585 - val_loss: 1.7835\n",
      "Epoch 90/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0100\n",
      "Epoch 90: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0100 - val_accuracy: 0.7655 - val_loss: 1.7951\n",
      "Epoch 91/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0091\n",
      "Epoch 91: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.7365 - val_loss: 2.5425\n",
      "Epoch 92/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0208\n",
      "Epoch 92: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0210 - val_accuracy: 0.7066 - val_loss: 1.9304\n",
      "Epoch 93/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.0328\n",
      "Epoch 93: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0328 - val_accuracy: 0.7485 - val_loss: 1.7279\n",
      "Epoch 94/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0116\n",
      "Epoch 94: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0117 - val_accuracy: 0.7415 - val_loss: 1.9423\n",
      "Epoch 95/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0114\n",
      "Epoch 95: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0115 - val_accuracy: 0.7535 - val_loss: 1.9885\n",
      "Epoch 96/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9921 - loss: 0.0239\n",
      "Epoch 96: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0239 - val_accuracy: 0.7615 - val_loss: 1.7281\n",
      "Epoch 97/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0082\n",
      "Epoch 97: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.7655 - val_loss: 1.7705\n",
      "Epoch 98/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0022\n",
      "Epoch 98: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 0.7595 - val_loss: 1.8169\n",
      "Epoch 99/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0162\n",
      "Epoch 99: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0164 - val_accuracy: 0.6996 - val_loss: 2.2419\n",
      "Epoch 100/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0318\n",
      "Epoch 100: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0318 - val_accuracy: 0.7435 - val_loss: 2.0242\n",
      "Epoch 101/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0188\n",
      "Epoch 101: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0188 - val_accuracy: 0.7555 - val_loss: 1.6809\n",
      "Epoch 102/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0083\n",
      "Epoch 102: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.7465 - val_loss: 1.9069\n",
      "Epoch 103/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0120\n",
      "Epoch 103: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0121 - val_accuracy: 0.7216 - val_loss: 2.0488\n",
      "Epoch 104/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0123\n",
      "Epoch 104: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0123 - val_accuracy: 0.7505 - val_loss: 1.9739\n",
      "Epoch 105/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0111\n",
      "Epoch 105: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0111 - val_accuracy: 0.7455 - val_loss: 1.9292\n",
      "Epoch 106/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0174\n",
      "Epoch 106: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0174 - val_accuracy: 0.7635 - val_loss: 1.9081\n",
      "Epoch 107/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0237\n",
      "Epoch 107: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0238 - val_accuracy: 0.7435 - val_loss: 1.8092\n",
      "Epoch 108/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0193\n",
      "Epoch 108: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0192 - val_accuracy: 0.7166 - val_loss: 1.9898\n",
      "Epoch 109/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0114\n",
      "Epoch 109: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0114 - val_accuracy: 0.7505 - val_loss: 1.7054\n",
      "Epoch 110/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0048\n",
      "Epoch 110: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0048 - val_accuracy: 0.7715 - val_loss: 1.7318\n",
      "Epoch 111/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 111: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7545 - val_loss: 1.8197\n",
      "Epoch 112/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0026\n",
      "Epoch 112: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.7645 - val_loss: 1.9500\n",
      "Epoch 113/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0065\n",
      "Epoch 113: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.7285 - val_loss: 2.4419\n",
      "Epoch 114/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9793 - loss: 0.0599\n",
      "Epoch 114: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.0597 - val_accuracy: 0.7166 - val_loss: 1.7698\n",
      "Epoch 115/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0185\n",
      "Epoch 115: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0184 - val_accuracy: 0.7605 - val_loss: 1.7700\n",
      "Epoch 116/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0055\n",
      "Epoch 116: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.7605 - val_loss: 1.7480\n",
      "Epoch 117/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0068\n",
      "Epoch 117: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.7854 - val_loss: 1.7247\n",
      "Epoch 118/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0031\n",
      "Epoch 118: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.7725 - val_loss: 1.7857\n",
      "Epoch 119/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0055\n",
      "Epoch 119: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.7435 - val_loss: 2.0632\n",
      "Epoch 120/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0184\n",
      "Epoch 120: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0185 - val_accuracy: 0.7186 - val_loss: 2.3545\n",
      "Epoch 121/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0224\n",
      "Epoch 121: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0224 - val_accuracy: 0.7515 - val_loss: 1.8853\n",
      "Epoch 122/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0154\n",
      "Epoch 122: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0154 - val_accuracy: 0.7685 - val_loss: 1.8242\n",
      "Epoch 123/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0037\n",
      "Epoch 123: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.7545 - val_loss: 1.9357\n",
      "Epoch 124/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0077\n",
      "Epoch 124: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0078 - val_accuracy: 0.7605 - val_loss: 1.9424\n",
      "Epoch 125/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0420\n",
      "Epoch 125: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0420 - val_accuracy: 0.7535 - val_loss: 1.9868\n",
      "Epoch 126/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0123\n",
      "Epoch 126: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0123 - val_accuracy: 0.7495 - val_loss: 1.8468\n",
      "Epoch 127/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0073\n",
      "Epoch 127: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.7545 - val_loss: 1.8138\n",
      "Epoch 128/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0037\n",
      "Epoch 128: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.7774 - val_loss: 1.8692\n",
      "Epoch 129/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0106\n",
      "Epoch 129: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0107 - val_accuracy: 0.7525 - val_loss: 1.8799\n",
      "Epoch 130/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0145\n",
      "Epoch 130: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0145 - val_accuracy: 0.7445 - val_loss: 1.9453\n",
      "Epoch 131/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0301\n",
      "Epoch 131: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0299 - val_accuracy: 0.7485 - val_loss: 1.8070\n",
      "Epoch 132/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0252\n",
      "Epoch 132: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0250 - val_accuracy: 0.7525 - val_loss: 1.8770\n",
      "Epoch 133/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0071\n",
      "Epoch 133: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0071 - val_accuracy: 0.7615 - val_loss: 1.8660\n",
      "Epoch 134/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0035\n",
      "Epoch 134: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0036 - val_accuracy: 0.7515 - val_loss: 2.0601\n",
      "Epoch 135/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0056\n",
      "Epoch 135: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 0.7675 - val_loss: 1.9798\n",
      "Epoch 136/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0072\n",
      "Epoch 136: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.7335 - val_loss: 2.0739\n",
      "Epoch 137/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0217\n",
      "Epoch 137: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0217 - val_accuracy: 0.7295 - val_loss: 2.5280\n",
      "Epoch 138/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0286\n",
      "Epoch 138: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0285 - val_accuracy: 0.7415 - val_loss: 1.7890\n",
      "Epoch 139/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0126\n",
      "Epoch 139: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0126 - val_accuracy: 0.7565 - val_loss: 1.8072\n",
      "Epoch 140/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0109\n",
      "Epoch 140: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0109 - val_accuracy: 0.7655 - val_loss: 1.8855\n",
      "Epoch 141/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0181\n",
      "Epoch 141: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0181 - val_accuracy: 0.7226 - val_loss: 2.0804\n",
      "Epoch 142/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0115\n",
      "Epoch 142: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0115 - val_accuracy: 0.7555 - val_loss: 1.9127\n",
      "Epoch 143/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0082\n",
      "Epoch 143: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0083 - val_accuracy: 0.7345 - val_loss: 1.9098\n",
      "Epoch 144/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0159\n",
      "Epoch 144: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0159 - val_accuracy: 0.7645 - val_loss: 1.8525\n",
      "Epoch 145/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0110\n",
      "Epoch 145: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0111 - val_accuracy: 0.7495 - val_loss: 2.1374\n",
      "Epoch 146/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0072\n",
      "Epoch 146: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0072 - val_accuracy: 0.7794 - val_loss: 1.8887\n",
      "Epoch 147/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0022\n",
      "Epoch 147: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.7565 - val_loss: 1.9262\n",
      "Epoch 148/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0088\n",
      "Epoch 148: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0089 - val_accuracy: 0.7595 - val_loss: 2.0612\n",
      "Epoch 149/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0130\n",
      "Epoch 149: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0129 - val_accuracy: 0.7605 - val_loss: 1.9428\n",
      "Epoch 150/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0029\n",
      "Epoch 150: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.7375 - val_loss: 2.2729\n",
      "Epoch 151/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0257\n",
      "Epoch 151: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0257 - val_accuracy: 0.7345 - val_loss: 2.0717\n",
      "Epoch 152/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0326\n",
      "Epoch 152: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0324 - val_accuracy: 0.7365 - val_loss: 2.0577\n",
      "Epoch 153/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0129\n",
      "Epoch 153: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0129 - val_accuracy: 0.7545 - val_loss: 1.9785\n",
      "Epoch 154/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0073\n",
      "Epoch 154: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0073 - val_accuracy: 0.7555 - val_loss: 2.4153\n",
      "Epoch 155/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0201\n",
      "Epoch 155: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0201 - val_accuracy: 0.7465 - val_loss: 2.4097\n",
      "Epoch 156/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0114\n",
      "Epoch 156: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0114 - val_accuracy: 0.7515 - val_loss: 1.8946\n",
      "Epoch 157/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0049\n",
      "Epoch 157: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0049 - val_accuracy: 0.7625 - val_loss: 1.8465\n",
      "Epoch 158/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0016\n",
      "Epoch 158: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.7655 - val_loss: 1.9666\n",
      "Epoch 159/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0012\n",
      "Epoch 159: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.7754 - val_loss: 1.9358\n",
      "Epoch 160/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 5.2221e-04\n",
      "Epoch 160: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 5.2361e-04 - val_accuracy: 0.7585 - val_loss: 1.9958\n",
      "Epoch 161/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 0.0451\n",
      "Epoch 161: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0452 - val_accuracy: 0.7156 - val_loss: 2.0599\n",
      "Epoch 162/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0174\n",
      "Epoch 162: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0173 - val_accuracy: 0.7665 - val_loss: 1.9164\n",
      "Epoch 163/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0053\n",
      "Epoch 163: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 0.7575 - val_loss: 1.9577\n",
      "Epoch 164/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0026\n",
      "Epoch 164: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.7176 - val_loss: 2.1998\n",
      "Epoch 165/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0024\n",
      "Epoch 165: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.7565 - val_loss: 1.9919\n",
      "Epoch 166/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0185\n",
      "Epoch 166: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0185 - val_accuracy: 0.7545 - val_loss: 2.0803\n",
      "Epoch 167/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0158\n",
      "Epoch 167: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0157 - val_accuracy: 0.7625 - val_loss: 2.0417\n",
      "Epoch 168/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0099\n",
      "Epoch 168: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0099 - val_accuracy: 0.7635 - val_loss: 1.8741\n",
      "Epoch 169/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0022\n",
      "Epoch 169: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.7645 - val_loss: 1.9523\n",
      "Epoch 170/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0043\n",
      "Epoch 170: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 0.7705 - val_loss: 2.0090\n",
      "Epoch 171/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0051\n",
      "Epoch 171: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.7605 - val_loss: 2.0500\n",
      "Epoch 172/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0210\n",
      "Epoch 172: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0213 - val_accuracy: 0.7325 - val_loss: 2.0011\n",
      "Epoch 173/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0095\n",
      "Epoch 173: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0095 - val_accuracy: 0.7136 - val_loss: 2.1369\n",
      "Epoch 174/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0084\n",
      "Epoch 174: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.7655 - val_loss: 2.1289\n",
      "Epoch 175/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0089\n",
      "Epoch 175: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0089 - val_accuracy: 0.7555 - val_loss: 1.8520\n",
      "Epoch 176/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0119\n",
      "Epoch 176: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0118 - val_accuracy: 0.7585 - val_loss: 1.8840\n",
      "Epoch 177/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0033\n",
      "Epoch 177: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.7425 - val_loss: 2.0582\n",
      "Epoch 178/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0258\n",
      "Epoch 178: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0257 - val_accuracy: 0.7595 - val_loss: 2.0357\n",
      "Epoch 179/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0087\n",
      "Epoch 179: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.7445 - val_loss: 2.0789\n",
      "Epoch 180/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0134\n",
      "Epoch 180: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0133 - val_accuracy: 0.7345 - val_loss: 2.0740\n",
      "Epoch 181/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0085\n",
      "Epoch 181: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0084 - val_accuracy: 0.7415 - val_loss: 2.4282\n",
      "Epoch 182/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0042\n",
      "Epoch 182: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.7515 - val_loss: 2.0580\n",
      "Epoch 183/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0167\n",
      "Epoch 183: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0167 - val_accuracy: 0.7435 - val_loss: 2.0185\n",
      "Epoch 184/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0082\n",
      "Epoch 184: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0082 - val_accuracy: 0.7505 - val_loss: 1.9374\n",
      "Epoch 185/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0032\n",
      "Epoch 185: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.7505 - val_loss: 2.1347\n",
      "Epoch 186/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0027\n",
      "Epoch 186: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.7465 - val_loss: 2.0438\n",
      "Epoch 187/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0038\n",
      "Epoch 187: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0037 - val_accuracy: 0.7685 - val_loss: 2.0906\n",
      "Epoch 188/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0063\n",
      "Epoch 188: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.7405 - val_loss: 2.0880\n",
      "Epoch 189/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0160\n",
      "Epoch 189: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0159 - val_accuracy: 0.7595 - val_loss: 1.9315\n",
      "Epoch 190/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0035\n",
      "Epoch 190: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.7395 - val_loss: 1.9993\n",
      "Epoch 191/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0119\n",
      "Epoch 191: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0121 - val_accuracy: 0.7236 - val_loss: 2.0698\n",
      "Epoch 192/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0206\n",
      "Epoch 192: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0205 - val_accuracy: 0.7415 - val_loss: 1.9969\n",
      "Epoch 193/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0082\n",
      "Epoch 193: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0082 - val_accuracy: 0.7525 - val_loss: 2.2623\n",
      "Epoch 194/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0033\n",
      "Epoch 194: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.7605 - val_loss: 2.0523\n",
      "Epoch 195/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.3892e-04\n",
      "Epoch 195: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.4104e-04 - val_accuracy: 0.7605 - val_loss: 2.0295\n",
      "Epoch 196/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 6.9184e-04\n",
      "Epoch 196: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 7.0037e-04 - val_accuracy: 0.7565 - val_loss: 2.2832\n",
      "Epoch 197/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0062\n",
      "Epoch 197: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0062 - val_accuracy: 0.7136 - val_loss: 2.4397\n",
      "Epoch 198/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0127\n",
      "Epoch 198: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0129 - val_accuracy: 0.7305 - val_loss: 2.7778\n",
      "Epoch 199/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0261\n",
      "Epoch 199: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0261 - val_accuracy: 0.7415 - val_loss: 2.0095\n",
      "Epoch 200/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0081\n",
      "Epoch 200: val_loss did not improve from 0.70203\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0081 - val_accuracy: 0.7585 - val_loss: 1.9264\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6163 - loss: 3.2247\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "model0 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6451 - loss: 1.0619\n",
      "Epoch 1: val_loss improved from inf to 1.68003, saving model to model_1/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6456 - loss: 1.0599 - val_accuracy: 0.2295 - val_loss: 1.6800\n",
      "Epoch 2/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7162 - loss: 0.7984\n",
      "Epoch 2: val_loss improved from 1.68003 to 1.14567, saving model to model_1/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7162 - loss: 0.7984 - val_accuracy: 0.6148 - val_loss: 1.1457\n",
      "Epoch 3/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 0.7489\n",
      "Epoch 3: val_loss improved from 1.14567 to 0.71684, saving model to model_1/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 0.7487 - val_accuracy: 0.7405 - val_loss: 0.7168\n",
      "Epoch 4/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7429 - loss: 0.7035\n",
      "Epoch 4: val_loss did not improve from 0.71684\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7431 - loss: 0.7032 - val_accuracy: 0.7285 - val_loss: 0.7442\n",
      "Epoch 5/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7692 - loss: 0.6438\n",
      "Epoch 5: val_loss did not improve from 0.71684\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7692 - loss: 0.6438 - val_accuracy: 0.7106 - val_loss: 0.8218\n",
      "Epoch 6/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7755 - loss: 0.6222\n",
      "Epoch 6: val_loss improved from 0.71684 to 0.71479, saving model to model_1/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7757 - loss: 0.6218 - val_accuracy: 0.7385 - val_loss: 0.7148\n",
      "Epoch 7/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8046 - loss: 0.5468\n",
      "Epoch 7: val_loss improved from 0.71479 to 0.67925, saving model to model_1/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8044 - loss: 0.5471 - val_accuracy: 0.7495 - val_loss: 0.6793\n",
      "Epoch 8/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8146 - loss: 0.5202\n",
      "Epoch 8: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8145 - loss: 0.5203 - val_accuracy: 0.7495 - val_loss: 0.6832\n",
      "Epoch 9/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8212 - loss: 0.4906\n",
      "Epoch 9: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.4906 - val_accuracy: 0.7495 - val_loss: 0.7013\n",
      "Epoch 10/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8382 - loss: 0.4564\n",
      "Epoch 10: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8382 - loss: 0.4564 - val_accuracy: 0.7535 - val_loss: 0.7076\n",
      "Epoch 11/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8523 - loss: 0.4144\n",
      "Epoch 11: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 0.4148 - val_accuracy: 0.7285 - val_loss: 0.8473\n",
      "Epoch 12/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8706 - loss: 0.3704\n",
      "Epoch 12: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8704 - loss: 0.3707 - val_accuracy: 0.7345 - val_loss: 0.7401\n",
      "Epoch 13/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8736 - loss: 0.3504\n",
      "Epoch 13: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8736 - loss: 0.3505 - val_accuracy: 0.7395 - val_loss: 0.7582\n",
      "Epoch 14/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8862 - loss: 0.3211\n",
      "Epoch 14: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8862 - loss: 0.3213 - val_accuracy: 0.7605 - val_loss: 0.7905\n",
      "Epoch 15/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8965 - loss: 0.3028\n",
      "Epoch 15: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8965 - loss: 0.3028 - val_accuracy: 0.7096 - val_loss: 0.8510\n",
      "Epoch 16/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9090 - loss: 0.2709\n",
      "Epoch 16: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9090 - loss: 0.2709 - val_accuracy: 0.7565 - val_loss: 0.7641\n",
      "Epoch 17/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2345\n",
      "Epoch 17: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9207 - loss: 0.2349 - val_accuracy: 0.7325 - val_loss: 0.8379\n",
      "Epoch 18/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9294 - loss: 0.2083\n",
      "Epoch 18: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9294 - loss: 0.2084 - val_accuracy: 0.7335 - val_loss: 0.8672\n",
      "Epoch 19/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9324 - loss: 0.1997\n",
      "Epoch 19: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9324 - loss: 0.1997 - val_accuracy: 0.7475 - val_loss: 0.8619\n",
      "Epoch 20/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.1778\n",
      "Epoch 20: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.1778 - val_accuracy: 0.7246 - val_loss: 0.9490\n",
      "Epoch 21/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.1652\n",
      "Epoch 21: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9481 - loss: 0.1653 - val_accuracy: 0.7385 - val_loss: 0.9194\n",
      "Epoch 22/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9591 - loss: 0.1338\n",
      "Epoch 22: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.1341 - val_accuracy: 0.7106 - val_loss: 0.9972\n",
      "Epoch 23/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9582 - loss: 0.1281\n",
      "Epoch 23: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9581 - loss: 0.1282 - val_accuracy: 0.7665 - val_loss: 1.0463\n",
      "Epoch 24/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9602 - loss: 0.1229\n",
      "Epoch 24: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9602 - loss: 0.1230 - val_accuracy: 0.7435 - val_loss: 0.9887\n",
      "Epoch 25/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9700 - loss: 0.0979\n",
      "Epoch 25: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9700 - loss: 0.0980 - val_accuracy: 0.7265 - val_loss: 1.0400\n",
      "Epoch 26/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9731 - loss: 0.0873\n",
      "Epoch 26: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9730 - loss: 0.0874 - val_accuracy: 0.7345 - val_loss: 1.1084\n",
      "Epoch 27/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0761\n",
      "Epoch 27: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.0761 - val_accuracy: 0.7485 - val_loss: 1.0864\n",
      "Epoch 28/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0707\n",
      "Epoch 28: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.0707 - val_accuracy: 0.7335 - val_loss: 1.1427\n",
      "Epoch 29/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.0683\n",
      "Epoch 29: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.0685 - val_accuracy: 0.7535 - val_loss: 1.3703\n",
      "Epoch 30/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0778\n",
      "Epoch 30: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.0777 - val_accuracy: 0.7305 - val_loss: 1.3829\n",
      "Epoch 31/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9839 - loss: 0.0543\n",
      "Epoch 31: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0543 - val_accuracy: 0.7495 - val_loss: 1.2654\n",
      "Epoch 32/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0578\n",
      "Epoch 32: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0578 - val_accuracy: 0.7255 - val_loss: 1.2499\n",
      "Epoch 33/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9835 - loss: 0.0528\n",
      "Epoch 33: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0528 - val_accuracy: 0.7246 - val_loss: 1.3598\n",
      "Epoch 34/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0584\n",
      "Epoch 34: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0582 - val_accuracy: 0.7166 - val_loss: 1.4183\n",
      "Epoch 35/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9861 - loss: 0.0414\n",
      "Epoch 35: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0415 - val_accuracy: 0.7046 - val_loss: 1.4415\n",
      "Epoch 36/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.0409\n",
      "Epoch 36: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9859 - loss: 0.0410 - val_accuracy: 0.7365 - val_loss: 1.4428\n",
      "Epoch 37/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0511\n",
      "Epoch 37: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0513 - val_accuracy: 0.7106 - val_loss: 1.5004\n",
      "Epoch 38/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0432\n",
      "Epoch 38: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0432 - val_accuracy: 0.7375 - val_loss: 1.5331\n",
      "Epoch 39/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0357\n",
      "Epoch 39: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0358 - val_accuracy: 0.7535 - val_loss: 1.4149\n",
      "Epoch 40/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 0.0467\n",
      "Epoch 40: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9854 - loss: 0.0468 - val_accuracy: 0.7355 - val_loss: 1.4473\n",
      "Epoch 41/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9864 - loss: 0.0397\n",
      "Epoch 41: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9864 - loss: 0.0397 - val_accuracy: 0.7485 - val_loss: 1.3975\n",
      "Epoch 42/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0260\n",
      "Epoch 42: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0260 - val_accuracy: 0.7325 - val_loss: 1.4758\n",
      "Epoch 43/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0283\n",
      "Epoch 43: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0283 - val_accuracy: 0.7345 - val_loss: 1.4349\n",
      "Epoch 44/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.0300\n",
      "Epoch 44: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0301 - val_accuracy: 0.7136 - val_loss: 1.7417\n",
      "Epoch 45/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.0497\n",
      "Epoch 45: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9816 - loss: 0.0496 - val_accuracy: 0.7475 - val_loss: 1.4930\n",
      "Epoch 46/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9862 - loss: 0.0381\n",
      "Epoch 46: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0383 - val_accuracy: 0.7365 - val_loss: 1.7933\n",
      "Epoch 47/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0282\n",
      "Epoch 47: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0282 - val_accuracy: 0.7635 - val_loss: 1.7177\n",
      "Epoch 48/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0284\n",
      "Epoch 48: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0285 - val_accuracy: 0.7206 - val_loss: 1.5419\n",
      "Epoch 49/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0290\n",
      "Epoch 49: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0290 - val_accuracy: 0.7395 - val_loss: 1.7244\n",
      "Epoch 50/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0270\n",
      "Epoch 50: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0269 - val_accuracy: 0.7465 - val_loss: 1.5701\n",
      "Epoch 51/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0259\n",
      "Epoch 51: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0260 - val_accuracy: 0.7425 - val_loss: 1.8063\n",
      "Epoch 52/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0325\n",
      "Epoch 52: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0325 - val_accuracy: 0.7425 - val_loss: 1.6203\n",
      "Epoch 53/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0304\n",
      "Epoch 53: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0305 - val_accuracy: 0.7505 - val_loss: 1.5225\n",
      "Epoch 54/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0294\n",
      "Epoch 54: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0294 - val_accuracy: 0.7285 - val_loss: 1.6338\n",
      "Epoch 55/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0243\n",
      "Epoch 55: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0242 - val_accuracy: 0.7425 - val_loss: 1.5200\n",
      "Epoch 56/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0118\n",
      "Epoch 56: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0119 - val_accuracy: 0.7405 - val_loss: 1.6396\n",
      "Epoch 57/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0346\n",
      "Epoch 57: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0346 - val_accuracy: 0.7415 - val_loss: 1.7789\n",
      "Epoch 58/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0366\n",
      "Epoch 58: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0364 - val_accuracy: 0.7365 - val_loss: 1.7921\n",
      "Epoch 59/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0400\n",
      "Epoch 59: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9872 - loss: 0.0399 - val_accuracy: 0.7425 - val_loss: 1.5824\n",
      "Epoch 60/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0210\n",
      "Epoch 60: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0209 - val_accuracy: 0.6986 - val_loss: 1.9450\n",
      "Epoch 61/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0205\n",
      "Epoch 61: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0205 - val_accuracy: 0.7455 - val_loss: 1.5589\n",
      "Epoch 62/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0280\n",
      "Epoch 62: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0280 - val_accuracy: 0.6747 - val_loss: 2.2276\n",
      "Epoch 63/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0259\n",
      "Epoch 63: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0261 - val_accuracy: 0.7265 - val_loss: 1.8152\n",
      "Epoch 64/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9893 - loss: 0.0365\n",
      "Epoch 64: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0365 - val_accuracy: 0.7445 - val_loss: 1.7141\n",
      "Epoch 65/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0175\n",
      "Epoch 65: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0175 - val_accuracy: 0.7405 - val_loss: 1.6376\n",
      "Epoch 66/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0172\n",
      "Epoch 66: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0173 - val_accuracy: 0.7216 - val_loss: 1.7962\n",
      "Epoch 67/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0186\n",
      "Epoch 67: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0186 - val_accuracy: 0.7415 - val_loss: 1.8377\n",
      "Epoch 68/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0222\n",
      "Epoch 68: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0222 - val_accuracy: 0.7525 - val_loss: 1.7464\n",
      "Epoch 69/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0206\n",
      "Epoch 69: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0206 - val_accuracy: 0.7365 - val_loss: 1.6855\n",
      "Epoch 70/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0229\n",
      "Epoch 70: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0230 - val_accuracy: 0.7405 - val_loss: 1.7420\n",
      "Epoch 71/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0099\n",
      "Epoch 71: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0100 - val_accuracy: 0.7325 - val_loss: 1.9197\n",
      "Epoch 72/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9839 - loss: 0.0553\n",
      "Epoch 72: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0550 - val_accuracy: 0.6697 - val_loss: 2.1487\n",
      "Epoch 73/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0240\n",
      "Epoch 73: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0239 - val_accuracy: 0.7186 - val_loss: 1.7892\n",
      "Epoch 74/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0351\n",
      "Epoch 74: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0352 - val_accuracy: 0.6956 - val_loss: 2.2404\n",
      "Epoch 75/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0260\n",
      "Epoch 75: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0259 - val_accuracy: 0.7385 - val_loss: 1.7155\n",
      "Epoch 76/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0058\n",
      "Epoch 76: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0058 - val_accuracy: 0.7485 - val_loss: 1.7749\n",
      "Epoch 77/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0045\n",
      "Epoch 77: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0047 - val_accuracy: 0.7106 - val_loss: 1.9981\n",
      "Epoch 78/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0422\n",
      "Epoch 78: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0422 - val_accuracy: 0.7545 - val_loss: 1.6747\n",
      "Epoch 79/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0300\n",
      "Epoch 79: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0300 - val_accuracy: 0.7335 - val_loss: 1.8452\n",
      "Epoch 80/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0214\n",
      "Epoch 80: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0214 - val_accuracy: 0.7375 - val_loss: 1.7876\n",
      "Epoch 81/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0126\n",
      "Epoch 81: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.7455 - val_loss: 1.7351\n",
      "Epoch 82/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0043\n",
      "Epoch 82: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0043 - val_accuracy: 0.7425 - val_loss: 1.8126\n",
      "Epoch 83/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0124\n",
      "Epoch 83: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0125 - val_accuracy: 0.7265 - val_loss: 1.8712\n",
      "Epoch 84/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0240\n",
      "Epoch 84: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0242 - val_accuracy: 0.7345 - val_loss: 1.7187\n",
      "Epoch 85/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0327\n",
      "Epoch 85: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0325 - val_accuracy: 0.7495 - val_loss: 1.7742\n",
      "Epoch 86/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0099\n",
      "Epoch 86: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.7485 - val_loss: 1.8911\n",
      "Epoch 87/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0193\n",
      "Epoch 87: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0193 - val_accuracy: 0.7505 - val_loss: 1.8209\n",
      "Epoch 88/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0205\n",
      "Epoch 88: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0207 - val_accuracy: 0.6677 - val_loss: 2.3081\n",
      "Epoch 89/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0420\n",
      "Epoch 89: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0418 - val_accuracy: 0.7615 - val_loss: 1.7982\n",
      "Epoch 90/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0133\n",
      "Epoch 90: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0132 - val_accuracy: 0.7475 - val_loss: 1.7522\n",
      "Epoch 91/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 91: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.7505 - val_loss: 1.7878\n",
      "Epoch 92/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 0.0375\n",
      "Epoch 92: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0375 - val_accuracy: 0.7265 - val_loss: 1.7404\n",
      "Epoch 93/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0110\n",
      "Epoch 93: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 0.7515 - val_loss: 1.7872\n",
      "Epoch 94/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0070\n",
      "Epoch 94: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0071 - val_accuracy: 0.7455 - val_loss: 1.8318\n",
      "Epoch 95/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0085\n",
      "Epoch 95: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.7535 - val_loss: 1.7799\n",
      "Epoch 96/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0296\n",
      "Epoch 96: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0296 - val_accuracy: 0.7325 - val_loss: 1.9565\n",
      "Epoch 97/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0292\n",
      "Epoch 97: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0293 - val_accuracy: 0.7315 - val_loss: 1.8127\n",
      "Epoch 98/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0160\n",
      "Epoch 98: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0159 - val_accuracy: 0.7465 - val_loss: 1.8149\n",
      "Epoch 99/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0072\n",
      "Epoch 99: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.7086 - val_loss: 2.1028\n",
      "Epoch 100/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0260\n",
      "Epoch 100: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0260 - val_accuracy: 0.7335 - val_loss: 1.8760\n",
      "Epoch 101/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0180\n",
      "Epoch 101: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0179 - val_accuracy: 0.7465 - val_loss: 1.7410\n",
      "Epoch 102/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0039\n",
      "Epoch 102: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0039 - val_accuracy: 0.7405 - val_loss: 1.6981\n",
      "Epoch 103/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0174\n",
      "Epoch 103: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0174 - val_accuracy: 0.7455 - val_loss: 1.8666\n",
      "Epoch 104/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0068\n",
      "Epoch 104: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.7325 - val_loss: 2.0997\n",
      "Epoch 105/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0228\n",
      "Epoch 105: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0227 - val_accuracy: 0.7275 - val_loss: 1.9264\n",
      "Epoch 106/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0195\n",
      "Epoch 106: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0195 - val_accuracy: 0.7216 - val_loss: 1.9392\n",
      "Epoch 107/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0152\n",
      "Epoch 107: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0152 - val_accuracy: 0.7325 - val_loss: 2.0182\n",
      "Epoch 108/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9915 - loss: 0.0262\n",
      "Epoch 108: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0262 - val_accuracy: 0.7335 - val_loss: 1.9539\n",
      "Epoch 109/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9862 - loss: 0.0373\n",
      "Epoch 109: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0370 - val_accuracy: 0.7595 - val_loss: 1.8052\n",
      "Epoch 110/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0115\n",
      "Epoch 110: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0115 - val_accuracy: 0.7485 - val_loss: 1.6379\n",
      "Epoch 111/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0056\n",
      "Epoch 111: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.7535 - val_loss: 1.7214\n",
      "Epoch 112/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0031\n",
      "Epoch 112: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.6816 - val_loss: 2.2500\n",
      "Epoch 113/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0104\n",
      "Epoch 113: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0104 - val_accuracy: 0.6956 - val_loss: 2.1796\n",
      "Epoch 114/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0384\n",
      "Epoch 114: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0384 - val_accuracy: 0.7485 - val_loss: 1.8386\n",
      "Epoch 115/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0106\n",
      "Epoch 115: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0106 - val_accuracy: 0.7335 - val_loss: 1.7508\n",
      "Epoch 116/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0041\n",
      "Epoch 116: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0041 - val_accuracy: 0.7375 - val_loss: 1.8975\n",
      "Epoch 117/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0041\n",
      "Epoch 117: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0041 - val_accuracy: 0.7375 - val_loss: 1.9521\n",
      "Epoch 118/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0101\n",
      "Epoch 118: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0102 - val_accuracy: 0.6846 - val_loss: 2.3691\n",
      "Epoch 119/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 0.0433\n",
      "Epoch 119: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0433 - val_accuracy: 0.7325 - val_loss: 1.7959\n",
      "Epoch 120/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0092\n",
      "Epoch 120: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0092 - val_accuracy: 0.7285 - val_loss: 1.8387\n",
      "Epoch 121/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0036\n",
      "Epoch 121: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.7545 - val_loss: 1.8170\n",
      "Epoch 122/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0044\n",
      "Epoch 122: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0044 - val_accuracy: 0.7455 - val_loss: 1.7690\n",
      "Epoch 123/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 123: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7535 - val_loss: 1.8557\n",
      "Epoch 124/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 124: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0023 - val_accuracy: 0.6916 - val_loss: 2.3068\n",
      "Epoch 125/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0514\n",
      "Epoch 125: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0513 - val_accuracy: 0.6776 - val_loss: 2.0480\n",
      "Epoch 126/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0208\n",
      "Epoch 126: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0207 - val_accuracy: 0.7305 - val_loss: 1.8722\n",
      "Epoch 127/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0097\n",
      "Epoch 127: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0097 - val_accuracy: 0.7505 - val_loss: 1.8955\n",
      "Epoch 128/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0044\n",
      "Epoch 128: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0044 - val_accuracy: 0.7475 - val_loss: 1.8393\n",
      "Epoch 129/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0012\n",
      "Epoch 129: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.7435 - val_loss: 2.0182\n",
      "Epoch 130/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0168\n",
      "Epoch 130: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0169 - val_accuracy: 0.7146 - val_loss: 2.1718\n",
      "Epoch 131/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0490\n",
      "Epoch 131: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.0489 - val_accuracy: 0.7405 - val_loss: 1.7476\n",
      "Epoch 132/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0048\n",
      "Epoch 132: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0047 - val_accuracy: 0.7365 - val_loss: 1.7534\n",
      "Epoch 133/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0036\n",
      "Epoch 133: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.7515 - val_loss: 1.7184\n",
      "Epoch 134/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0031\n",
      "Epoch 134: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.7255 - val_loss: 1.9420\n",
      "Epoch 135/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0016\n",
      "Epoch 135: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.7505 - val_loss: 1.8097\n",
      "Epoch 136/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Epoch 136: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7445 - val_loss: 1.8517\n",
      "Epoch 137/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0014\n",
      "Epoch 137: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 0.7295 - val_loss: 2.6916\n",
      "Epoch 138/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0656\n",
      "Epoch 138: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0660 - val_accuracy: 0.7435 - val_loss: 1.8744\n",
      "Epoch 139/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9921 - loss: 0.0208\n",
      "Epoch 139: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0208 - val_accuracy: 0.7525 - val_loss: 1.8442\n",
      "Epoch 140/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0035\n",
      "Epoch 140: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.7535 - val_loss: 1.8333\n",
      "Epoch 141/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0017\n",
      "Epoch 141: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0017 - val_accuracy: 0.7655 - val_loss: 1.7927\n",
      "Epoch 142/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.6254e-04\n",
      "Epoch 142: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.6294e-04 - val_accuracy: 0.7605 - val_loss: 1.8095\n",
      "Epoch 143/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 143: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.7585 - val_loss: 1.8690\n",
      "Epoch 144/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0019\n",
      "Epoch 144: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0019 - val_accuracy: 0.7625 - val_loss: 1.8306\n",
      "Epoch 145/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 9.1453e-04\n",
      "Epoch 145: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 9.1468e-04 - val_accuracy: 0.7605 - val_loss: 1.8999\n",
      "Epoch 146/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.6015e-04\n",
      "Epoch 146: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.6002e-04 - val_accuracy: 0.7635 - val_loss: 1.8889\n",
      "Epoch 147/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0229\n",
      "Epoch 147: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0241 - val_accuracy: 0.7236 - val_loss: 1.9896\n",
      "Epoch 148/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0325\n",
      "Epoch 148: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0325 - val_accuracy: 0.7565 - val_loss: 1.7517\n",
      "Epoch 149/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0152\n",
      "Epoch 149: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0151 - val_accuracy: 0.7545 - val_loss: 1.9092\n",
      "Epoch 150/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0083\n",
      "Epoch 150: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0083 - val_accuracy: 0.7465 - val_loss: 1.9141\n",
      "Epoch 151/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0068\n",
      "Epoch 151: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0068 - val_accuracy: 0.7345 - val_loss: 1.8957\n",
      "Epoch 152/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0054\n",
      "Epoch 152: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.7465 - val_loss: 1.9268\n",
      "Epoch 153/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0297\n",
      "Epoch 153: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0296 - val_accuracy: 0.7475 - val_loss: 1.8489\n",
      "Epoch 154/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0121\n",
      "Epoch 154: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0121 - val_accuracy: 0.7285 - val_loss: 2.0886\n",
      "Epoch 155/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0183\n",
      "Epoch 155: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0183 - val_accuracy: 0.7455 - val_loss: 2.2006\n",
      "Epoch 156/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0139\n",
      "Epoch 156: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0139 - val_accuracy: 0.7345 - val_loss: 2.0151\n",
      "Epoch 157/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0043\n",
      "Epoch 157: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.7425 - val_loss: 1.8616\n",
      "Epoch 158/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0103\n",
      "Epoch 158: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0103 - val_accuracy: 0.7156 - val_loss: 2.2255\n",
      "Epoch 159/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0158\n",
      "Epoch 159: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0157 - val_accuracy: 0.7385 - val_loss: 2.0189\n",
      "Epoch 160/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0125\n",
      "Epoch 160: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.7365 - val_loss: 2.0240\n",
      "Epoch 161/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0126\n",
      "Epoch 161: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.7545 - val_loss: 1.9016\n",
      "Epoch 162/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0057\n",
      "Epoch 162: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 0.7485 - val_loss: 1.8814\n",
      "Epoch 163/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0091\n",
      "Epoch 163: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0091 - val_accuracy: 0.7026 - val_loss: 2.3246\n",
      "Epoch 164/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0129\n",
      "Epoch 164: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0129 - val_accuracy: 0.7375 - val_loss: 2.0372\n",
      "Epoch 165/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0026\n",
      "Epoch 165: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.7485 - val_loss: 1.9710\n",
      "Epoch 166/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0027\n",
      "Epoch 166: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.7275 - val_loss: 2.0881\n",
      "Epoch 167/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0251\n",
      "Epoch 167: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0252 - val_accuracy: 0.7136 - val_loss: 2.7062\n",
      "Epoch 168/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0221\n",
      "Epoch 168: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0220 - val_accuracy: 0.7495 - val_loss: 1.9369\n",
      "Epoch 169/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0048\n",
      "Epoch 169: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.7575 - val_loss: 2.1467\n",
      "Epoch 170/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0088\n",
      "Epoch 170: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0088 - val_accuracy: 0.7275 - val_loss: 2.0058\n",
      "Epoch 171/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0055\n",
      "Epoch 171: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.7465 - val_loss: 1.9749\n",
      "Epoch 172/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.8897e-04\n",
      "Epoch 172: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.8976e-04 - val_accuracy: 0.7345 - val_loss: 2.0378\n",
      "Epoch 173/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.3757e-04\n",
      "Epoch 173: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.3494e-04 - val_accuracy: 0.7485 - val_loss: 2.0025\n",
      "Epoch 174/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.9314e-04\n",
      "Epoch 174: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.9346e-04 - val_accuracy: 0.7415 - val_loss: 1.9978\n",
      "Epoch 175/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 8.6647e-04\n",
      "Epoch 175: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 8.9841e-04 - val_accuracy: 0.7515 - val_loss: 2.1246\n",
      "Epoch 176/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0465\n",
      "Epoch 176: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0465 - val_accuracy: 0.7335 - val_loss: 2.2077\n",
      "Epoch 177/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0236\n",
      "Epoch 177: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0235 - val_accuracy: 0.7505 - val_loss: 2.0239\n",
      "Epoch 178/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0074\n",
      "Epoch 178: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.7455 - val_loss: 1.9412\n",
      "Epoch 179/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0045\n",
      "Epoch 179: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0045 - val_accuracy: 0.7435 - val_loss: 1.9619\n",
      "Epoch 180/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0028\n",
      "Epoch 180: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.7375 - val_loss: 2.2177\n",
      "Epoch 181/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0108\n",
      "Epoch 181: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0108 - val_accuracy: 0.7255 - val_loss: 2.1686\n",
      "Epoch 182/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0190\n",
      "Epoch 182: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0191 - val_accuracy: 0.7485 - val_loss: 1.9909\n",
      "Epoch 183/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0093\n",
      "Epoch 183: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0093 - val_accuracy: 0.7375 - val_loss: 2.0207\n",
      "Epoch 184/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0062\n",
      "Epoch 184: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.7355 - val_loss: 1.9975\n",
      "Epoch 185/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0020\n",
      "Epoch 185: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.6886 - val_loss: 2.3027\n",
      "Epoch 186/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0090\n",
      "Epoch 186: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.7505 - val_loss: 2.1045\n",
      "Epoch 187/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0110\n",
      "Epoch 187: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0110 - val_accuracy: 0.7285 - val_loss: 2.1923\n",
      "Epoch 188/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0144\n",
      "Epoch 188: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0143 - val_accuracy: 0.7505 - val_loss: 2.1194\n",
      "Epoch 189/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0078\n",
      "Epoch 189: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0079 - val_accuracy: 0.7575 - val_loss: 2.3632\n",
      "Epoch 190/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0088\n",
      "Epoch 190: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.7315 - val_loss: 2.0882\n",
      "Epoch 191/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0088\n",
      "Epoch 191: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0088 - val_accuracy: 0.7206 - val_loss: 2.2820\n",
      "Epoch 192/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0040\n",
      "Epoch 192: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0040 - val_accuracy: 0.7465 - val_loss: 2.2170\n",
      "Epoch 193/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0147\n",
      "Epoch 193: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0147 - val_accuracy: 0.7375 - val_loss: 2.1228\n",
      "Epoch 194/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0095\n",
      "Epoch 194: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0097 - val_accuracy: 0.7156 - val_loss: 2.2485\n",
      "Epoch 195/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0258\n",
      "Epoch 195: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0257 - val_accuracy: 0.7485 - val_loss: 2.1156\n",
      "Epoch 196/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0063\n",
      "Epoch 196: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0063 - val_accuracy: 0.7615 - val_loss: 2.0955\n",
      "Epoch 197/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0043\n",
      "Epoch 197: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0043 - val_accuracy: 0.7405 - val_loss: 2.0730\n",
      "Epoch 198/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0040\n",
      "Epoch 198: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.7395 - val_loss: 2.3568\n",
      "Epoch 199/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0067\n",
      "Epoch 199: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.6946 - val_loss: 2.4364\n",
      "Epoch 200/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0189\n",
      "Epoch 200: val_loss did not improve from 0.67925\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0189 - val_accuracy: 0.7176 - val_loss: 2.3153\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6450 - loss: 2.9353\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "model1 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6192 - loss: 1.1204\n",
      "Epoch 1: val_loss improved from inf to 1.39749, saving model to model_2/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6208 - loss: 1.1151 - val_accuracy: 0.6687 - val_loss: 1.3975\n",
      "Epoch 2/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7171 - loss: 0.7782\n",
      "Epoch 2: val_loss improved from 1.39749 to 0.89747, saving model to model_2/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7171 - loss: 0.7782 - val_accuracy: 0.6906 - val_loss: 0.8975\n",
      "Epoch 3/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7443 - loss: 0.7147\n",
      "Epoch 3: val_loss improved from 0.89747 to 0.80869, saving model to model_2/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7442 - loss: 0.7147 - val_accuracy: 0.6916 - val_loss: 0.8087\n",
      "Epoch 4/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7547 - loss: 0.6616\n",
      "Epoch 4: val_loss improved from 0.80869 to 0.79655, saving model to model_2/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7548 - loss: 0.6616 - val_accuracy: 0.6956 - val_loss: 0.7966\n",
      "Epoch 5/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7739 - loss: 0.6237\n",
      "Epoch 5: val_loss improved from 0.79655 to 0.79640, saving model to model_2/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7739 - loss: 0.6237 - val_accuracy: 0.7216 - val_loss: 0.7964\n",
      "Epoch 6/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7872 - loss: 0.5791\n",
      "Epoch 6: val_loss improved from 0.79640 to 0.76765, saving model to model_2/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7872 - loss: 0.5791 - val_accuracy: 0.7275 - val_loss: 0.7677\n",
      "Epoch 7/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8098 - loss: 0.5265\n",
      "Epoch 7: val_loss improved from 0.76765 to 0.75916, saving model to model_2/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8097 - loss: 0.5266 - val_accuracy: 0.7335 - val_loss: 0.7592\n",
      "Epoch 8/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8214 - loss: 0.5001\n",
      "Epoch 8: val_loss improved from 0.75916 to 0.74439, saving model to model_2/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8214 - loss: 0.5001 - val_accuracy: 0.7285 - val_loss: 0.7444\n",
      "Epoch 9/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8326 - loss: 0.4773\n",
      "Epoch 9: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8325 - loss: 0.4772 - val_accuracy: 0.7226 - val_loss: 0.7888\n",
      "Epoch 10/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8494 - loss: 0.4228\n",
      "Epoch 10: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8493 - loss: 0.4232 - val_accuracy: 0.7186 - val_loss: 0.8470\n",
      "Epoch 11/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8658 - loss: 0.3867\n",
      "Epoch 11: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8657 - loss: 0.3869 - val_accuracy: 0.7445 - val_loss: 0.7682\n",
      "Epoch 12/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.3647\n",
      "Epoch 12: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8780 - loss: 0.3648 - val_accuracy: 0.7275 - val_loss: 0.7683\n",
      "Epoch 13/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8804 - loss: 0.3385\n",
      "Epoch 13: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8803 - loss: 0.3387 - val_accuracy: 0.7146 - val_loss: 0.8235\n",
      "Epoch 14/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9004 - loss: 0.2957\n",
      "Epoch 14: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9003 - loss: 0.2960 - val_accuracy: 0.7405 - val_loss: 0.8635\n",
      "Epoch 15/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9013 - loss: 0.2876\n",
      "Epoch 15: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9012 - loss: 0.2877 - val_accuracy: 0.7285 - val_loss: 0.8376\n",
      "Epoch 16/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.2526\n",
      "Epoch 16: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9157 - loss: 0.2528 - val_accuracy: 0.7345 - val_loss: 0.9531\n",
      "Epoch 17/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9242 - loss: 0.2361\n",
      "Epoch 17: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9240 - loss: 0.2364 - val_accuracy: 0.7076 - val_loss: 1.0097\n",
      "Epoch 18/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 0.2177\n",
      "Epoch 18: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9272 - loss: 0.2178 - val_accuracy: 0.7166 - val_loss: 0.9155\n",
      "Epoch 19/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 0.1907\n",
      "Epoch 19: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9399 - loss: 0.1909 - val_accuracy: 0.7455 - val_loss: 1.0407\n",
      "Epoch 20/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9439 - loss: 0.1687\n",
      "Epoch 20: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9437 - loss: 0.1691 - val_accuracy: 0.7335 - val_loss: 1.1171\n",
      "Epoch 21/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9513 - loss: 0.1471\n",
      "Epoch 21: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.1473 - val_accuracy: 0.7265 - val_loss: 1.1329\n",
      "Epoch 22/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1378\n",
      "Epoch 22: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1378 - val_accuracy: 0.6996 - val_loss: 1.1413\n",
      "Epoch 23/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9606 - loss: 0.1249\n",
      "Epoch 23: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9606 - loss: 0.1250 - val_accuracy: 0.7335 - val_loss: 1.0780\n",
      "Epoch 24/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9672 - loss: 0.1144\n",
      "Epoch 24: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9671 - loss: 0.1144 - val_accuracy: 0.7405 - val_loss: 1.0939\n",
      "Epoch 25/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9641 - loss: 0.1062\n",
      "Epoch 25: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9641 - loss: 0.1064 - val_accuracy: 0.7016 - val_loss: 1.1646\n",
      "Epoch 26/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9737 - loss: 0.0914\n",
      "Epoch 26: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9737 - loss: 0.0914 - val_accuracy: 0.7335 - val_loss: 1.1562\n",
      "Epoch 27/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9712 - loss: 0.0927\n",
      "Epoch 27: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9712 - loss: 0.0927 - val_accuracy: 0.7485 - val_loss: 1.1624\n",
      "Epoch 28/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9782 - loss: 0.0760\n",
      "Epoch 28: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9782 - loss: 0.0760 - val_accuracy: 0.7505 - val_loss: 1.2497\n",
      "Epoch 29/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.0797\n",
      "Epoch 29: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0797 - val_accuracy: 0.7455 - val_loss: 1.3282\n",
      "Epoch 30/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.0631\n",
      "Epoch 30: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9815 - loss: 0.0632 - val_accuracy: 0.7275 - val_loss: 1.3738\n",
      "Epoch 31/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9784 - loss: 0.0705\n",
      "Epoch 31: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.0706 - val_accuracy: 0.7026 - val_loss: 1.3868\n",
      "Epoch 32/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0488\n",
      "Epoch 32: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0489 - val_accuracy: 0.7355 - val_loss: 1.5694\n",
      "Epoch 33/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9810 - loss: 0.0596\n",
      "Epoch 33: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9810 - loss: 0.0596 - val_accuracy: 0.7246 - val_loss: 1.3958\n",
      "Epoch 34/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9790 - loss: 0.0676\n",
      "Epoch 34: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0676 - val_accuracy: 0.7375 - val_loss: 1.4174\n",
      "Epoch 35/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9819 - loss: 0.0555\n",
      "Epoch 35: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9819 - loss: 0.0555 - val_accuracy: 0.7635 - val_loss: 1.3893\n",
      "Epoch 36/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0418\n",
      "Epoch 36: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0418 - val_accuracy: 0.7305 - val_loss: 1.5066\n",
      "Epoch 37/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0355\n",
      "Epoch 37: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0356 - val_accuracy: 0.7166 - val_loss: 1.4198\n",
      "Epoch 38/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0363\n",
      "Epoch 38: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0364 - val_accuracy: 0.7216 - val_loss: 1.4725\n",
      "Epoch 39/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0427\n",
      "Epoch 39: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0428 - val_accuracy: 0.7295 - val_loss: 1.4930\n",
      "Epoch 40/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0429\n",
      "Epoch 40: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0428 - val_accuracy: 0.7385 - val_loss: 1.5572\n",
      "Epoch 41/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0433\n",
      "Epoch 41: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0433 - val_accuracy: 0.7415 - val_loss: 1.5174\n",
      "Epoch 42/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0330\n",
      "Epoch 42: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0332 - val_accuracy: 0.7285 - val_loss: 1.7122\n",
      "Epoch 43/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9898 - loss: 0.0314\n",
      "Epoch 43: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0314 - val_accuracy: 0.7255 - val_loss: 1.5337\n",
      "Epoch 44/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0484\n",
      "Epoch 44: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0485 - val_accuracy: 0.7385 - val_loss: 1.5389\n",
      "Epoch 45/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0341\n",
      "Epoch 45: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0340 - val_accuracy: 0.7116 - val_loss: 1.6237\n",
      "Epoch 46/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0267\n",
      "Epoch 46: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0267 - val_accuracy: 0.6886 - val_loss: 1.7554\n",
      "Epoch 47/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0367\n",
      "Epoch 47: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0367 - val_accuracy: 0.7425 - val_loss: 1.5519\n",
      "Epoch 48/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0404\n",
      "Epoch 48: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0402 - val_accuracy: 0.7285 - val_loss: 1.6274\n",
      "Epoch 49/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0413\n",
      "Epoch 49: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9865 - loss: 0.0413 - val_accuracy: 0.7345 - val_loss: 1.7320\n",
      "Epoch 50/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0299\n",
      "Epoch 50: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0299 - val_accuracy: 0.7445 - val_loss: 1.7065\n",
      "Epoch 51/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0255\n",
      "Epoch 51: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0255 - val_accuracy: 0.7275 - val_loss: 1.9073\n",
      "Epoch 52/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9864 - loss: 0.0386\n",
      "Epoch 52: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0386 - val_accuracy: 0.7445 - val_loss: 1.5819\n",
      "Epoch 53/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0205\n",
      "Epoch 53: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0206 - val_accuracy: 0.7385 - val_loss: 1.8984\n",
      "Epoch 54/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0415\n",
      "Epoch 54: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0414 - val_accuracy: 0.7196 - val_loss: 1.7095\n",
      "Epoch 55/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0154\n",
      "Epoch 55: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0154 - val_accuracy: 0.7275 - val_loss: 1.7228\n",
      "Epoch 56/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0182\n",
      "Epoch 56: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0184 - val_accuracy: 0.7435 - val_loss: 1.8521\n",
      "Epoch 57/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0237\n",
      "Epoch 57: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0238 - val_accuracy: 0.7355 - val_loss: 1.6933\n",
      "Epoch 58/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0207\n",
      "Epoch 58: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0208 - val_accuracy: 0.7325 - val_loss: 1.6409\n",
      "Epoch 59/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9927 - loss: 0.0286\n",
      "Epoch 59: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0286 - val_accuracy: 0.6826 - val_loss: 1.8676\n",
      "Epoch 60/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0331\n",
      "Epoch 60: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0331 - val_accuracy: 0.7365 - val_loss: 1.7034\n",
      "Epoch 61/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0206\n",
      "Epoch 61: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0206 - val_accuracy: 0.7485 - val_loss: 1.7653\n",
      "Epoch 62/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0394\n",
      "Epoch 62: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0394 - val_accuracy: 0.7335 - val_loss: 1.8827\n",
      "Epoch 63/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0238\n",
      "Epoch 63: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0238 - val_accuracy: 0.7126 - val_loss: 1.9503\n",
      "Epoch 64/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0139\n",
      "Epoch 64: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0139 - val_accuracy: 0.7525 - val_loss: 1.9457\n",
      "Epoch 65/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9913 - loss: 0.0310\n",
      "Epoch 65: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0309 - val_accuracy: 0.7425 - val_loss: 1.9508\n",
      "Epoch 66/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0167\n",
      "Epoch 66: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0167 - val_accuracy: 0.7335 - val_loss: 1.8694\n",
      "Epoch 67/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0215\n",
      "Epoch 67: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0215 - val_accuracy: 0.7335 - val_loss: 2.0363\n",
      "Epoch 68/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0241\n",
      "Epoch 68: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0240 - val_accuracy: 0.6856 - val_loss: 2.0359\n",
      "Epoch 69/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9881 - loss: 0.0322\n",
      "Epoch 69: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0322 - val_accuracy: 0.7635 - val_loss: 1.7490\n",
      "Epoch 70/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0173\n",
      "Epoch 70: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.7435 - val_loss: 1.7209\n",
      "Epoch 71/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0147\n",
      "Epoch 71: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0149 - val_accuracy: 0.7166 - val_loss: 1.9496\n",
      "Epoch 72/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0269\n",
      "Epoch 72: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0269 - val_accuracy: 0.7535 - val_loss: 2.1900\n",
      "Epoch 73/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0183\n",
      "Epoch 73: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0183 - val_accuracy: 0.7435 - val_loss: 1.7599\n",
      "Epoch 74/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0118\n",
      "Epoch 74: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0118 - val_accuracy: 0.7355 - val_loss: 2.2886\n",
      "Epoch 75/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0249\n",
      "Epoch 75: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0250 - val_accuracy: 0.7455 - val_loss: 1.8155\n",
      "Epoch 76/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0212\n",
      "Epoch 76: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0212 - val_accuracy: 0.7365 - val_loss: 2.0021\n",
      "Epoch 77/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0246\n",
      "Epoch 77: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0246 - val_accuracy: 0.7206 - val_loss: 1.8189\n",
      "Epoch 78/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0201\n",
      "Epoch 78: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0201 - val_accuracy: 0.7435 - val_loss: 2.0173\n",
      "Epoch 79/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0122\n",
      "Epoch 79: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0122 - val_accuracy: 0.7186 - val_loss: 1.9319\n",
      "Epoch 80/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0191\n",
      "Epoch 80: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0193 - val_accuracy: 0.7395 - val_loss: 1.8937\n",
      "Epoch 81/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0225\n",
      "Epoch 81: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0226 - val_accuracy: 0.7545 - val_loss: 2.0307\n",
      "Epoch 82/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0213\n",
      "Epoch 82: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0213 - val_accuracy: 0.7465 - val_loss: 1.8328\n",
      "Epoch 83/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0196\n",
      "Epoch 83: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0196 - val_accuracy: 0.7176 - val_loss: 2.7849\n",
      "Epoch 84/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0131\n",
      "Epoch 84: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0131 - val_accuracy: 0.7156 - val_loss: 1.9552\n",
      "Epoch 85/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 0.0223\n",
      "Epoch 85: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0223 - val_accuracy: 0.7345 - val_loss: 1.9954\n",
      "Epoch 86/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0289\n",
      "Epoch 86: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0288 - val_accuracy: 0.7335 - val_loss: 2.0054\n",
      "Epoch 87/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0191\n",
      "Epoch 87: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0190 - val_accuracy: 0.7375 - val_loss: 1.9159\n",
      "Epoch 88/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0120\n",
      "Epoch 88: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0120 - val_accuracy: 0.7505 - val_loss: 1.8423\n",
      "Epoch 89/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0026\n",
      "Epoch 89: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.7575 - val_loss: 1.8642\n",
      "Epoch 90/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0022\n",
      "Epoch 90: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.7475 - val_loss: 1.8634\n",
      "Epoch 91/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0051\n",
      "Epoch 91: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.7236 - val_loss: 2.8239\n",
      "Epoch 92/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.0807\n",
      "Epoch 92: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.0808 - val_accuracy: 0.7146 - val_loss: 1.8221\n",
      "Epoch 93/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0210\n",
      "Epoch 93: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0208 - val_accuracy: 0.7295 - val_loss: 1.9753\n",
      "Epoch 94/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 94: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.7555 - val_loss: 1.7211\n",
      "Epoch 95/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0042\n",
      "Epoch 95: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.7445 - val_loss: 2.0092\n",
      "Epoch 96/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0159\n",
      "Epoch 96: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0158 - val_accuracy: 0.7186 - val_loss: 1.8159\n",
      "Epoch 97/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0169\n",
      "Epoch 97: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0170 - val_accuracy: 0.6886 - val_loss: 2.3963\n",
      "Epoch 98/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0293\n",
      "Epoch 98: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0293 - val_accuracy: 0.7176 - val_loss: 1.9815\n",
      "Epoch 99/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0180\n",
      "Epoch 99: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0181 - val_accuracy: 0.7086 - val_loss: 2.0192\n",
      "Epoch 100/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0185\n",
      "Epoch 100: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0184 - val_accuracy: 0.7625 - val_loss: 1.7427\n",
      "Epoch 101/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0066\n",
      "Epoch 101: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0066 - val_accuracy: 0.7495 - val_loss: 2.1847\n",
      "Epoch 102/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0111\n",
      "Epoch 102: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0111 - val_accuracy: 0.7305 - val_loss: 2.1854\n",
      "Epoch 103/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0161\n",
      "Epoch 103: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.7475 - val_loss: 2.1128\n",
      "Epoch 104/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0145\n",
      "Epoch 104: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0145 - val_accuracy: 0.7305 - val_loss: 1.8113\n",
      "Epoch 105/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0106\n",
      "Epoch 105: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0108 - val_accuracy: 0.7136 - val_loss: 2.1543\n",
      "Epoch 106/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0263\n",
      "Epoch 106: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0264 - val_accuracy: 0.7275 - val_loss: 2.1160\n",
      "Epoch 107/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0268\n",
      "Epoch 107: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0266 - val_accuracy: 0.7345 - val_loss: 2.0334\n",
      "Epoch 108/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0080\n",
      "Epoch 108: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0080 - val_accuracy: 0.7445 - val_loss: 1.9607\n",
      "Epoch 109/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0068\n",
      "Epoch 109: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.7565 - val_loss: 1.8793\n",
      "Epoch 110/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9941 - loss: 0.0179\n",
      "Epoch 110: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0182 - val_accuracy: 0.7385 - val_loss: 2.3434\n",
      "Epoch 111/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0253\n",
      "Epoch 111: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0254 - val_accuracy: 0.7355 - val_loss: 2.0654\n",
      "Epoch 112/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0178\n",
      "Epoch 112: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0178 - val_accuracy: 0.7355 - val_loss: 2.0125\n",
      "Epoch 113/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0076\n",
      "Epoch 113: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 0.7475 - val_loss: 2.1521\n",
      "Epoch 114/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0078\n",
      "Epoch 114: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0078 - val_accuracy: 0.7275 - val_loss: 2.5348\n",
      "Epoch 115/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0221\n",
      "Epoch 115: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0220 - val_accuracy: 0.7555 - val_loss: 2.0795\n",
      "Epoch 116/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0145\n",
      "Epoch 116: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0145 - val_accuracy: 0.7435 - val_loss: 1.9721\n",
      "Epoch 117/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0124\n",
      "Epoch 117: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0124 - val_accuracy: 0.7465 - val_loss: 2.2606\n",
      "Epoch 118/200\n",
      "\u001b[1m273/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0065\n",
      "Epoch 118: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.7495 - val_loss: 2.0137\n",
      "Epoch 119/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0074\n",
      "Epoch 119: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0074 - val_accuracy: 0.7385 - val_loss: 2.0121\n",
      "Epoch 120/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0229\n",
      "Epoch 120: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0230 - val_accuracy: 0.7475 - val_loss: 2.3160\n",
      "Epoch 121/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0311\n",
      "Epoch 121: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0310 - val_accuracy: 0.7435 - val_loss: 2.7210\n",
      "Epoch 122/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0076\n",
      "Epoch 122: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0076 - val_accuracy: 0.7375 - val_loss: 1.9862\n",
      "Epoch 123/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0030\n",
      "Epoch 123: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.7375 - val_loss: 2.0051\n",
      "Epoch 124/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 124: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7535 - val_loss: 1.9650\n",
      "Epoch 125/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.4024e-04\n",
      "Epoch 125: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4051e-04 - val_accuracy: 0.7545 - val_loss: 1.9662\n",
      "Epoch 126/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.2874e-04\n",
      "Epoch 126: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.2893e-04 - val_accuracy: 0.7535 - val_loss: 2.0415\n",
      "Epoch 127/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.6269e-04\n",
      "Epoch 127: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.6646e-04 - val_accuracy: 0.7555 - val_loss: 2.0000\n",
      "Epoch 128/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0023\n",
      "Epoch 128: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.6946 - val_loss: 2.4590\n",
      "Epoch 129/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9629 - loss: 0.1256\n",
      "Epoch 129: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.1245 - val_accuracy: 0.7425 - val_loss: 1.8917\n",
      "Epoch 130/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0132\n",
      "Epoch 130: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0131 - val_accuracy: 0.7555 - val_loss: 1.7271\n",
      "Epoch 131/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0096\n",
      "Epoch 131: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.7505 - val_loss: 1.9216\n",
      "Epoch 132/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0071\n",
      "Epoch 132: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0071 - val_accuracy: 0.7555 - val_loss: 2.1363\n",
      "Epoch 133/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0039\n",
      "Epoch 133: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.7535 - val_loss: 2.0155\n",
      "Epoch 134/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0024\n",
      "Epoch 134: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.7565 - val_loss: 1.9748\n",
      "Epoch 135/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0073\n",
      "Epoch 135: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0074 - val_accuracy: 0.7615 - val_loss: 2.2012\n",
      "Epoch 136/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9841 - loss: 0.0459\n",
      "Epoch 136: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0464 - val_accuracy: 0.7096 - val_loss: 2.2621\n",
      "Epoch 137/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0149\n",
      "Epoch 137: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0149 - val_accuracy: 0.7565 - val_loss: 1.9607\n",
      "Epoch 138/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0161\n",
      "Epoch 138: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0161 - val_accuracy: 0.7405 - val_loss: 2.0459\n",
      "Epoch 139/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0095\n",
      "Epoch 139: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0095 - val_accuracy: 0.7565 - val_loss: 2.0591\n",
      "Epoch 140/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0069\n",
      "Epoch 140: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0069 - val_accuracy: 0.7335 - val_loss: 1.9780\n",
      "Epoch 141/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0021\n",
      "Epoch 141: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.7495 - val_loss: 2.1986\n",
      "Epoch 142/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0052\n",
      "Epoch 142: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.7325 - val_loss: 2.1700\n",
      "Epoch 143/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0130\n",
      "Epoch 143: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0132 - val_accuracy: 0.7425 - val_loss: 2.5203\n",
      "Epoch 144/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0323\n",
      "Epoch 144: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0322 - val_accuracy: 0.7345 - val_loss: 2.1394\n",
      "Epoch 145/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0183\n",
      "Epoch 145: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0183 - val_accuracy: 0.7365 - val_loss: 1.9993\n",
      "Epoch 146/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0112\n",
      "Epoch 146: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0112 - val_accuracy: 0.7365 - val_loss: 2.1984\n",
      "Epoch 147/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0223\n",
      "Epoch 147: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0221 - val_accuracy: 0.7505 - val_loss: 2.0624\n",
      "Epoch 148/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0088\n",
      "Epoch 148: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0088 - val_accuracy: 0.7415 - val_loss: 1.9490\n",
      "Epoch 149/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0107\n",
      "Epoch 149: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0107 - val_accuracy: 0.7595 - val_loss: 2.0151\n",
      "Epoch 150/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0119\n",
      "Epoch 150: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0120 - val_accuracy: 0.7365 - val_loss: 2.1386\n",
      "Epoch 151/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0107\n",
      "Epoch 151: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0107 - val_accuracy: 0.7535 - val_loss: 2.2396\n",
      "Epoch 152/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0034\n",
      "Epoch 152: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0034 - val_accuracy: 0.7415 - val_loss: 2.0668\n",
      "Epoch 153/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0039\n",
      "Epoch 153: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0039 - val_accuracy: 0.7525 - val_loss: 2.1860\n",
      "Epoch 154/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 154: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7525 - val_loss: 2.1371\n",
      "Epoch 155/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.6389e-04\n",
      "Epoch 155: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.6476e-04 - val_accuracy: 0.7535 - val_loss: 2.1437\n",
      "Epoch 156/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.8780e-04\n",
      "Epoch 156: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.8772e-04 - val_accuracy: 0.7545 - val_loss: 2.1478\n",
      "Epoch 157/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0184\n",
      "Epoch 157: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0193 - val_accuracy: 0.7325 - val_loss: 2.2192\n",
      "Epoch 158/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9839 - loss: 0.0460\n",
      "Epoch 158: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0453 - val_accuracy: 0.7425 - val_loss: 1.9193\n",
      "Epoch 159/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0047\n",
      "Epoch 159: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0048 - val_accuracy: 0.7515 - val_loss: 2.0360\n",
      "Epoch 160/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0074\n",
      "Epoch 160: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0074 - val_accuracy: 0.7395 - val_loss: 2.4520\n",
      "Epoch 161/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0051\n",
      "Epoch 161: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.7405 - val_loss: 2.1495\n",
      "Epoch 162/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0117\n",
      "Epoch 162: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0118 - val_accuracy: 0.7425 - val_loss: 2.1270\n",
      "Epoch 163/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0068\n",
      "Epoch 163: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 0.7325 - val_loss: 2.0652\n",
      "Epoch 164/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0050\n",
      "Epoch 164: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0049 - val_accuracy: 0.7535 - val_loss: 2.1495\n",
      "Epoch 165/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.5903e-04\n",
      "Epoch 165: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.5953e-04 - val_accuracy: 0.7565 - val_loss: 2.1792\n",
      "Epoch 166/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0016\n",
      "Epoch 166: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.7595 - val_loss: 2.1595\n",
      "Epoch 167/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.7887e-04\n",
      "Epoch 167: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.8069e-04 - val_accuracy: 0.7555 - val_loss: 2.1904\n",
      "Epoch 168/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0310\n",
      "Epoch 168: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 0.0314 - val_accuracy: 0.7305 - val_loss: 2.2879\n",
      "Epoch 169/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0255\n",
      "Epoch 169: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0254 - val_accuracy: 0.7435 - val_loss: 2.0220\n",
      "Epoch 170/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0051\n",
      "Epoch 170: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.7445 - val_loss: 2.1244\n",
      "Epoch 171/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0021\n",
      "Epoch 171: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.7505 - val_loss: 2.4363\n",
      "Epoch 172/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0020\n",
      "Epoch 172: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.7515 - val_loss: 2.1646\n",
      "Epoch 173/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0020\n",
      "Epoch 173: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0020 - val_accuracy: 0.7435 - val_loss: 2.1953\n",
      "Epoch 174/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0041\n",
      "Epoch 174: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.7385 - val_loss: 2.5925\n",
      "Epoch 175/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0346\n",
      "Epoch 175: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0346 - val_accuracy: 0.7375 - val_loss: 2.2178\n",
      "Epoch 176/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0191\n",
      "Epoch 176: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0191 - val_accuracy: 0.7585 - val_loss: 2.0694\n",
      "Epoch 177/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0062\n",
      "Epoch 177: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0062 - val_accuracy: 0.7295 - val_loss: 2.2914\n",
      "Epoch 178/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0029\n",
      "Epoch 178: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.7545 - val_loss: 2.1264\n",
      "Epoch 179/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0018\n",
      "Epoch 179: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.7575 - val_loss: 2.0704\n",
      "Epoch 180/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0042\n",
      "Epoch 180: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.7246 - val_loss: 2.4526\n",
      "Epoch 181/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9867 - loss: 0.0326\n",
      "Epoch 181: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0325 - val_accuracy: 0.7475 - val_loss: 2.4635\n",
      "Epoch 182/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0088\n",
      "Epoch 182: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.7535 - val_loss: 2.2407\n",
      "Epoch 183/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0063\n",
      "Epoch 183: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.7345 - val_loss: 2.0954\n",
      "Epoch 184/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0045\n",
      "Epoch 184: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.7475 - val_loss: 2.1006\n",
      "Epoch 185/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0157\n",
      "Epoch 185: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0158 - val_accuracy: 0.7315 - val_loss: 2.1111\n",
      "Epoch 186/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0237\n",
      "Epoch 186: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0235 - val_accuracy: 0.7655 - val_loss: 2.1868\n",
      "Epoch 187/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0024\n",
      "Epoch 187: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.7625 - val_loss: 2.0429\n",
      "Epoch 188/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0022\n",
      "Epoch 188: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.7565 - val_loss: 2.0671\n",
      "Epoch 189/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.0277e-04\n",
      "Epoch 189: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.0080e-04 - val_accuracy: 0.7455 - val_loss: 2.1462\n",
      "Epoch 190/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0032\n",
      "Epoch 190: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0032 - val_accuracy: 0.7495 - val_loss: 2.1617\n",
      "Epoch 191/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0061\n",
      "Epoch 191: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.7375 - val_loss: 3.1106\n",
      "Epoch 192/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0515\n",
      "Epoch 192: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0514 - val_accuracy: 0.7455 - val_loss: 2.1568\n",
      "Epoch 193/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0090\n",
      "Epoch 193: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 0.7445 - val_loss: 2.1516\n",
      "Epoch 194/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0030\n",
      "Epoch 194: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0030 - val_accuracy: 0.7565 - val_loss: 2.0354\n",
      "Epoch 195/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.1665e-04\n",
      "Epoch 195: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.1684e-04 - val_accuracy: 0.7625 - val_loss: 2.0766\n",
      "Epoch 196/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.7761e-04\n",
      "Epoch 196: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.7819e-04 - val_accuracy: 0.7665 - val_loss: 2.0801\n",
      "Epoch 197/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0119\n",
      "Epoch 197: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0121 - val_accuracy: 0.7285 - val_loss: 2.2573\n",
      "Epoch 198/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0396\n",
      "Epoch 198: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0393 - val_accuracy: 0.7305 - val_loss: 2.8822\n",
      "Epoch 199/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0091\n",
      "Epoch 199: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0091 - val_accuracy: 0.7615 - val_loss: 2.2415\n",
      "Epoch 200/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0032\n",
      "Epoch 200: val_loss did not improve from 0.74439\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.7475 - val_loss: 2.3844\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 4.0156\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "model2 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6548 - loss: 1.0272\n",
      "Epoch 1: val_loss improved from inf to 1.22441, saving model to model_3/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.6556 - loss: 1.0238 - val_accuracy: 0.6697 - val_loss: 1.2244\n",
      "Epoch 2/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7157 - loss: 0.7943\n",
      "Epoch 2: val_loss improved from 1.22441 to 0.81861, saving model to model_3/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7158 - loss: 0.7941 - val_accuracy: 0.6986 - val_loss: 0.8186\n",
      "Epoch 3/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7325 - loss: 0.7323\n",
      "Epoch 3: val_loss improved from 0.81861 to 0.80509, saving model to model_3/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7325 - loss: 0.7322 - val_accuracy: 0.6956 - val_loss: 0.8051\n",
      "Epoch 4/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7528 - loss: 0.6868\n",
      "Epoch 4: val_loss improved from 0.80509 to 0.80085, saving model to model_3/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7528 - loss: 0.6866 - val_accuracy: 0.7026 - val_loss: 0.8009\n",
      "Epoch 5/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7747 - loss: 0.6296\n",
      "Epoch 5: val_loss improved from 0.80085 to 0.75453, saving model to model_3/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7746 - loss: 0.6296 - val_accuracy: 0.7246 - val_loss: 0.7545\n",
      "Epoch 6/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7783 - loss: 0.5956\n",
      "Epoch 6: val_loss improved from 0.75453 to 0.72863, saving model to model_3/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7785 - loss: 0.5957 - val_accuracy: 0.7345 - val_loss: 0.7286\n",
      "Epoch 7/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8010 - loss: 0.5470\n",
      "Epoch 7: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8009 - loss: 0.5472 - val_accuracy: 0.6836 - val_loss: 0.8051\n",
      "Epoch 8/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7983 - loss: 0.5327\n",
      "Epoch 8: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7983 - loss: 0.5326 - val_accuracy: 0.6707 - val_loss: 0.8649\n",
      "Epoch 9/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8299 - loss: 0.4759\n",
      "Epoch 9: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8297 - loss: 0.4762 - val_accuracy: 0.7016 - val_loss: 0.7471\n",
      "Epoch 10/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8363 - loss: 0.4557\n",
      "Epoch 10: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8363 - loss: 0.4558 - val_accuracy: 0.6876 - val_loss: 0.8449\n",
      "Epoch 11/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8549 - loss: 0.4110\n",
      "Epoch 11: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8548 - loss: 0.4112 - val_accuracy: 0.7425 - val_loss: 0.7590\n",
      "Epoch 12/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8570 - loss: 0.3887\n",
      "Epoch 12: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8570 - loss: 0.3887 - val_accuracy: 0.7275 - val_loss: 0.7539\n",
      "Epoch 13/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8728 - loss: 0.3622\n",
      "Epoch 13: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8728 - loss: 0.3622 - val_accuracy: 0.7166 - val_loss: 0.7488\n",
      "Epoch 14/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8884 - loss: 0.3136\n",
      "Epoch 14: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8883 - loss: 0.3137 - val_accuracy: 0.7166 - val_loss: 0.7814\n",
      "Epoch 15/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8994 - loss: 0.2945\n",
      "Epoch 15: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8993 - loss: 0.2945 - val_accuracy: 0.6986 - val_loss: 0.9362\n",
      "Epoch 16/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9113 - loss: 0.2633\n",
      "Epoch 16: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9112 - loss: 0.2637 - val_accuracy: 0.7285 - val_loss: 0.8699\n",
      "Epoch 17/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9171 - loss: 0.2515\n",
      "Epoch 17: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9169 - loss: 0.2516 - val_accuracy: 0.7066 - val_loss: 0.9490\n",
      "Epoch 18/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9321 - loss: 0.2115\n",
      "Epoch 18: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9320 - loss: 0.2118 - val_accuracy: 0.7255 - val_loss: 1.0012\n",
      "Epoch 19/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9348 - loss: 0.1922\n",
      "Epoch 19: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9348 - loss: 0.1924 - val_accuracy: 0.7475 - val_loss: 0.8709\n",
      "Epoch 20/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9524 - loss: 0.1621\n",
      "Epoch 20: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9522 - loss: 0.1625 - val_accuracy: 0.7305 - val_loss: 0.9465\n",
      "Epoch 21/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.1655\n",
      "Epoch 21: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.1655 - val_accuracy: 0.7265 - val_loss: 0.9905\n",
      "Epoch 22/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9603 - loss: 0.1340\n",
      "Epoch 22: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9601 - loss: 0.1343 - val_accuracy: 0.5988 - val_loss: 1.5332\n",
      "Epoch 23/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9538 - loss: 0.1364\n",
      "Epoch 23: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9539 - loss: 0.1364 - val_accuracy: 0.7246 - val_loss: 1.0384\n",
      "Epoch 24/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9675 - loss: 0.1094\n",
      "Epoch 24: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9674 - loss: 0.1095 - val_accuracy: 0.7186 - val_loss: 1.1709\n",
      "Epoch 25/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9602 - loss: 0.1121\n",
      "Epoch 25: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9602 - loss: 0.1122 - val_accuracy: 0.7295 - val_loss: 1.1371\n",
      "Epoch 26/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9754 - loss: 0.0883\n",
      "Epoch 26: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0883 - val_accuracy: 0.7485 - val_loss: 1.1587\n",
      "Epoch 27/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9695 - loss: 0.0941\n",
      "Epoch 27: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9695 - loss: 0.0942 - val_accuracy: 0.7106 - val_loss: 1.3192\n",
      "Epoch 28/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0801\n",
      "Epoch 28: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9755 - loss: 0.0801 - val_accuracy: 0.7255 - val_loss: 1.3354\n",
      "Epoch 29/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0698\n",
      "Epoch 29: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9798 - loss: 0.0699 - val_accuracy: 0.7375 - val_loss: 1.2245\n",
      "Epoch 30/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9819 - loss: 0.0652\n",
      "Epoch 30: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9819 - loss: 0.0651 - val_accuracy: 0.7435 - val_loss: 1.2921\n",
      "Epoch 31/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9866 - loss: 0.0515\n",
      "Epoch 31: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9865 - loss: 0.0516 - val_accuracy: 0.7226 - val_loss: 1.4000\n",
      "Epoch 32/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9804 - loss: 0.0654\n",
      "Epoch 32: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9804 - loss: 0.0654 - val_accuracy: 0.7275 - val_loss: 1.4185\n",
      "Epoch 33/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0641\n",
      "Epoch 33: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0642 - val_accuracy: 0.7455 - val_loss: 1.3454\n",
      "Epoch 34/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0532\n",
      "Epoch 34: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9814 - loss: 0.0532 - val_accuracy: 0.7435 - val_loss: 1.3365\n",
      "Epoch 35/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9875 - loss: 0.0512\n",
      "Epoch 35: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9875 - loss: 0.0512 - val_accuracy: 0.7425 - val_loss: 1.5327\n",
      "Epoch 36/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0531\n",
      "Epoch 36: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0531 - val_accuracy: 0.7415 - val_loss: 1.4632\n",
      "Epoch 37/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 0.0352\n",
      "Epoch 37: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0353 - val_accuracy: 0.7305 - val_loss: 1.5248\n",
      "Epoch 38/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0419\n",
      "Epoch 38: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0418 - val_accuracy: 0.7216 - val_loss: 1.5680\n",
      "Epoch 39/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0307\n",
      "Epoch 39: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0307 - val_accuracy: 0.6737 - val_loss: 1.9186\n",
      "Epoch 40/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9842 - loss: 0.0531\n",
      "Epoch 40: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9843 - loss: 0.0530 - val_accuracy: 0.7315 - val_loss: 1.4972\n",
      "Epoch 41/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9879 - loss: 0.0372\n",
      "Epoch 41: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0372 - val_accuracy: 0.7186 - val_loss: 1.5946\n",
      "Epoch 42/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0335\n",
      "Epoch 42: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0336 - val_accuracy: 0.7395 - val_loss: 1.5186\n",
      "Epoch 43/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0490\n",
      "Epoch 43: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0490 - val_accuracy: 0.7435 - val_loss: 1.7889\n",
      "Epoch 44/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.0658\n",
      "Epoch 44: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9779 - loss: 0.0657 - val_accuracy: 0.7465 - val_loss: 1.6191\n",
      "Epoch 45/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 0.0336\n",
      "Epoch 45: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0335 - val_accuracy: 0.7345 - val_loss: 1.5311\n",
      "Epoch 46/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0289\n",
      "Epoch 46: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0289 - val_accuracy: 0.7275 - val_loss: 1.5466\n",
      "Epoch 47/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0351\n",
      "Epoch 47: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0351 - val_accuracy: 0.7355 - val_loss: 1.5471\n",
      "Epoch 48/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0580\n",
      "Epoch 48: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9813 - loss: 0.0577 - val_accuracy: 0.7076 - val_loss: 1.5361\n",
      "Epoch 49/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0214\n",
      "Epoch 49: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0215 - val_accuracy: 0.7495 - val_loss: 1.5461\n",
      "Epoch 50/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0363\n",
      "Epoch 50: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0363 - val_accuracy: 0.7435 - val_loss: 1.5502\n",
      "Epoch 51/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0155\n",
      "Epoch 51: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0155 - val_accuracy: 0.7395 - val_loss: 1.7132\n",
      "Epoch 52/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0224\n",
      "Epoch 52: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0225 - val_accuracy: 0.7305 - val_loss: 1.8844\n",
      "Epoch 53/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.0471\n",
      "Epoch 53: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0473 - val_accuracy: 0.7096 - val_loss: 1.7406\n",
      "Epoch 54/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0252\n",
      "Epoch 54: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0252 - val_accuracy: 0.7495 - val_loss: 1.6558\n",
      "Epoch 55/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0184\n",
      "Epoch 55: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0185 - val_accuracy: 0.7425 - val_loss: 1.6818\n",
      "Epoch 56/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0194\n",
      "Epoch 56: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0193 - val_accuracy: 0.7236 - val_loss: 1.7356\n",
      "Epoch 57/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0370\n",
      "Epoch 57: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0370 - val_accuracy: 0.7246 - val_loss: 1.7546\n",
      "Epoch 58/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9860 - loss: 0.0389\n",
      "Epoch 58: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9860 - loss: 0.0390 - val_accuracy: 0.7455 - val_loss: 1.9154\n",
      "Epoch 59/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0343\n",
      "Epoch 59: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0341 - val_accuracy: 0.7475 - val_loss: 1.7622\n",
      "Epoch 60/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0180\n",
      "Epoch 60: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0180 - val_accuracy: 0.7236 - val_loss: 1.9355\n",
      "Epoch 61/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0155\n",
      "Epoch 61: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0155 - val_accuracy: 0.7255 - val_loss: 1.9227\n",
      "Epoch 62/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.0462\n",
      "Epoch 62: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.0463 - val_accuracy: 0.7186 - val_loss: 1.7042\n",
      "Epoch 63/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0317\n",
      "Epoch 63: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0316 - val_accuracy: 0.7435 - val_loss: 1.8625\n",
      "Epoch 64/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0100\n",
      "Epoch 64: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.7305 - val_loss: 1.7227\n",
      "Epoch 65/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0056\n",
      "Epoch 65: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0056 - val_accuracy: 0.7136 - val_loss: 2.0047\n",
      "Epoch 66/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.0274\n",
      "Epoch 66: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.0275 - val_accuracy: 0.7196 - val_loss: 2.3244\n",
      "Epoch 67/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0409\n",
      "Epoch 67: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0408 - val_accuracy: 0.7405 - val_loss: 1.8632\n",
      "Epoch 68/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0208\n",
      "Epoch 68: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0208 - val_accuracy: 0.7335 - val_loss: 2.0794\n",
      "Epoch 69/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0292\n",
      "Epoch 69: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0290 - val_accuracy: 0.7345 - val_loss: 1.7010\n",
      "Epoch 70/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0128\n",
      "Epoch 70: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0128 - val_accuracy: 0.7206 - val_loss: 1.6546\n",
      "Epoch 71/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0094\n",
      "Epoch 71: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0094 - val_accuracy: 0.7345 - val_loss: 1.7929\n",
      "Epoch 72/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0088\n",
      "Epoch 72: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0089 - val_accuracy: 0.7066 - val_loss: 1.9884\n",
      "Epoch 73/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9815 - loss: 0.0565\n",
      "Epoch 73: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9815 - loss: 0.0565 - val_accuracy: 0.7375 - val_loss: 2.1023\n",
      "Epoch 74/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0400\n",
      "Epoch 74: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0400 - val_accuracy: 0.7355 - val_loss: 1.8201\n",
      "Epoch 75/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0329\n",
      "Epoch 75: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0329 - val_accuracy: 0.7236 - val_loss: 1.5513\n",
      "Epoch 76/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0120\n",
      "Epoch 76: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0120 - val_accuracy: 0.7465 - val_loss: 1.8198\n",
      "Epoch 77/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0080\n",
      "Epoch 77: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0080 - val_accuracy: 0.7465 - val_loss: 1.9736\n",
      "Epoch 78/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0100\n",
      "Epoch 78: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0101 - val_accuracy: 0.7295 - val_loss: 2.0273\n",
      "Epoch 79/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0257\n",
      "Epoch 79: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0255 - val_accuracy: 0.7285 - val_loss: 1.8493\n",
      "Epoch 80/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0147\n",
      "Epoch 80: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0147 - val_accuracy: 0.7265 - val_loss: 1.7545\n",
      "Epoch 81/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9927 - loss: 0.0251\n",
      "Epoch 81: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.0251 - val_accuracy: 0.7226 - val_loss: 2.4867\n",
      "Epoch 82/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.0340\n",
      "Epoch 82: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9882 - loss: 0.0339 - val_accuracy: 0.7186 - val_loss: 1.9766\n",
      "Epoch 83/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0146\n",
      "Epoch 83: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0146 - val_accuracy: 0.7425 - val_loss: 1.7264\n",
      "Epoch 84/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0151\n",
      "Epoch 84: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0151 - val_accuracy: 0.7455 - val_loss: 1.9781\n",
      "Epoch 85/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0192\n",
      "Epoch 85: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0192 - val_accuracy: 0.7146 - val_loss: 2.0909\n",
      "Epoch 86/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9908 - loss: 0.0252\n",
      "Epoch 86: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9908 - loss: 0.0253 - val_accuracy: 0.7395 - val_loss: 1.8584\n",
      "Epoch 87/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0159\n",
      "Epoch 87: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0161 - val_accuracy: 0.7226 - val_loss: 1.8709\n",
      "Epoch 88/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0114\n",
      "Epoch 88: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0113 - val_accuracy: 0.7425 - val_loss: 1.8218\n",
      "Epoch 89/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0085\n",
      "Epoch 89: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0085 - val_accuracy: 0.7445 - val_loss: 2.0077\n",
      "Epoch 90/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0080\n",
      "Epoch 90: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0080 - val_accuracy: 0.7385 - val_loss: 1.9591\n",
      "Epoch 91/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0220\n",
      "Epoch 91: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0220 - val_accuracy: 0.7485 - val_loss: 1.8990\n",
      "Epoch 92/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0207\n",
      "Epoch 92: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0207 - val_accuracy: 0.7455 - val_loss: 1.7475\n",
      "Epoch 93/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0211\n",
      "Epoch 93: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0211 - val_accuracy: 0.7216 - val_loss: 1.8882\n",
      "Epoch 94/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0214\n",
      "Epoch 94: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0215 - val_accuracy: 0.7405 - val_loss: 1.9121\n",
      "Epoch 95/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0203\n",
      "Epoch 95: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0202 - val_accuracy: 0.7575 - val_loss: 1.6937\n",
      "Epoch 96/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0106\n",
      "Epoch 96: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 0.7435 - val_loss: 1.8350\n",
      "Epoch 97/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0096\n",
      "Epoch 97: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0097 - val_accuracy: 0.7066 - val_loss: 1.9056\n",
      "Epoch 98/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9927 - loss: 0.0206\n",
      "Epoch 98: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9927 - loss: 0.0207 - val_accuracy: 0.7445 - val_loss: 2.1619\n",
      "Epoch 99/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0245\n",
      "Epoch 99: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0243 - val_accuracy: 0.7345 - val_loss: 1.9437\n",
      "Epoch 100/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0123\n",
      "Epoch 100: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0123 - val_accuracy: 0.7036 - val_loss: 2.0274\n",
      "Epoch 101/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0211\n",
      "Epoch 101: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0211 - val_accuracy: 0.7275 - val_loss: 1.8920\n",
      "Epoch 102/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0091\n",
      "Epoch 102: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0091 - val_accuracy: 0.7385 - val_loss: 1.8621\n",
      "Epoch 103/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0132\n",
      "Epoch 103: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0133 - val_accuracy: 0.7365 - val_loss: 1.9906\n",
      "Epoch 104/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0338\n",
      "Epoch 104: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0337 - val_accuracy: 0.7465 - val_loss: 1.8698\n",
      "Epoch 105/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0129\n",
      "Epoch 105: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0128 - val_accuracy: 0.7315 - val_loss: 1.7329\n",
      "Epoch 106/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0053\n",
      "Epoch 106: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0053 - val_accuracy: 0.7505 - val_loss: 1.9486\n",
      "Epoch 107/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9959 - loss: 0.0107\n",
      "Epoch 107: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0108 - val_accuracy: 0.7365 - val_loss: 2.1784\n",
      "Epoch 108/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.0283\n",
      "Epoch 108: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0283 - val_accuracy: 0.6687 - val_loss: 2.1332\n",
      "Epoch 109/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0253\n",
      "Epoch 109: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0252 - val_accuracy: 0.7255 - val_loss: 2.0225\n",
      "Epoch 110/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0049\n",
      "Epoch 110: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0050 - val_accuracy: 0.7385 - val_loss: 1.8164\n",
      "Epoch 111/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0202\n",
      "Epoch 111: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9903 - loss: 0.0202 - val_accuracy: 0.7345 - val_loss: 1.8797\n",
      "Epoch 112/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0071\n",
      "Epoch 112: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0071 - val_accuracy: 0.7395 - val_loss: 2.1088\n",
      "Epoch 113/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0031\n",
      "Epoch 113: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.7445 - val_loss: 2.0407\n",
      "Epoch 114/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0297\n",
      "Epoch 114: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9907 - loss: 0.0298 - val_accuracy: 0.7186 - val_loss: 2.4436\n",
      "Epoch 115/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0256\n",
      "Epoch 115: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0255 - val_accuracy: 0.7285 - val_loss: 2.0761\n",
      "Epoch 116/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0126\n",
      "Epoch 116: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0126 - val_accuracy: 0.7445 - val_loss: 2.0788\n",
      "Epoch 117/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0133\n",
      "Epoch 117: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0132 - val_accuracy: 0.7325 - val_loss: 1.9593\n",
      "Epoch 118/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0038\n",
      "Epoch 118: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0038 - val_accuracy: 0.7226 - val_loss: 2.0733\n",
      "Epoch 119/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0110\n",
      "Epoch 119: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0110 - val_accuracy: 0.7116 - val_loss: 1.9522\n",
      "Epoch 120/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0219\n",
      "Epoch 120: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9913 - loss: 0.0220 - val_accuracy: 0.7066 - val_loss: 2.0787\n",
      "Epoch 121/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0327\n",
      "Epoch 121: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0326 - val_accuracy: 0.7315 - val_loss: 2.0035\n",
      "Epoch 122/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0106\n",
      "Epoch 122: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0106 - val_accuracy: 0.7295 - val_loss: 1.9448\n",
      "Epoch 123/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0063\n",
      "Epoch 123: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0063 - val_accuracy: 0.7445 - val_loss: 1.9648\n",
      "Epoch 124/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0034\n",
      "Epoch 124: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.7495 - val_loss: 2.0148\n",
      "Epoch 125/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0027\n",
      "Epoch 125: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0027 - val_accuracy: 0.7345 - val_loss: 1.8849\n",
      "Epoch 126/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0094\n",
      "Epoch 126: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.7255 - val_loss: 2.1917\n",
      "Epoch 127/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0470\n",
      "Epoch 127: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9854 - loss: 0.0469 - val_accuracy: 0.7265 - val_loss: 2.0495\n",
      "Epoch 128/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0211\n",
      "Epoch 128: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0210 - val_accuracy: 0.7275 - val_loss: 2.1156\n",
      "Epoch 129/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0075\n",
      "Epoch 129: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.7435 - val_loss: 1.9193\n",
      "Epoch 130/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0058\n",
      "Epoch 130: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0059 - val_accuracy: 0.7335 - val_loss: 1.9545\n",
      "Epoch 131/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0121\n",
      "Epoch 131: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0121 - val_accuracy: 0.7345 - val_loss: 1.8655\n",
      "Epoch 132/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0032\n",
      "Epoch 132: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.7495 - val_loss: 1.8190\n",
      "Epoch 133/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0045\n",
      "Epoch 133: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.7176 - val_loss: 2.0419\n",
      "Epoch 134/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0274\n",
      "Epoch 134: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0274 - val_accuracy: 0.7226 - val_loss: 2.5594\n",
      "Epoch 135/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0270\n",
      "Epoch 135: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0270 - val_accuracy: 0.7285 - val_loss: 2.2717\n",
      "Epoch 136/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0294\n",
      "Epoch 136: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.0292 - val_accuracy: 0.7425 - val_loss: 2.0557\n",
      "Epoch 137/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0067\n",
      "Epoch 137: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 0.7475 - val_loss: 2.1844\n",
      "Epoch 138/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0207\n",
      "Epoch 138: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0206 - val_accuracy: 0.7475 - val_loss: 1.9017\n",
      "Epoch 139/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0041\n",
      "Epoch 139: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.7475 - val_loss: 1.9378\n",
      "Epoch 140/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0025\n",
      "Epoch 140: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.7196 - val_loss: 2.1841\n",
      "Epoch 141/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0224\n",
      "Epoch 141: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9915 - loss: 0.0224 - val_accuracy: 0.7196 - val_loss: 1.9083\n",
      "Epoch 142/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0130\n",
      "Epoch 142: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0130 - val_accuracy: 0.7335 - val_loss: 2.1803\n",
      "Epoch 143/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0218\n",
      "Epoch 143: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0217 - val_accuracy: 0.7405 - val_loss: 1.9174\n",
      "Epoch 144/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0082\n",
      "Epoch 144: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.7275 - val_loss: 2.1449\n",
      "Epoch 145/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0131\n",
      "Epoch 145: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0131 - val_accuracy: 0.7425 - val_loss: 2.0040\n",
      "Epoch 146/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0125\n",
      "Epoch 146: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0125 - val_accuracy: 0.7186 - val_loss: 1.9696\n",
      "Epoch 147/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0112\n",
      "Epoch 147: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0112 - val_accuracy: 0.7275 - val_loss: 2.6409\n",
      "Epoch 148/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0086\n",
      "Epoch 148: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0086 - val_accuracy: 0.7375 - val_loss: 2.1920\n",
      "Epoch 149/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0022\n",
      "Epoch 149: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.7435 - val_loss: 2.0905\n",
      "Epoch 150/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.7083e-04\n",
      "Epoch 150: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 6.7848e-04 - val_accuracy: 0.7405 - val_loss: 2.0304\n",
      "Epoch 151/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 151: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.7465 - val_loss: 2.0899\n",
      "Epoch 152/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0067\n",
      "Epoch 152: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0069 - val_accuracy: 0.7325 - val_loss: 2.0054\n",
      "Epoch 153/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0535\n",
      "Epoch 153: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0531 - val_accuracy: 0.7275 - val_loss: 1.7315\n",
      "Epoch 154/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0112\n",
      "Epoch 154: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0112 - val_accuracy: 0.7236 - val_loss: 1.8982\n",
      "Epoch 155/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0029\n",
      "Epoch 155: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0029 - val_accuracy: 0.7405 - val_loss: 1.8582\n",
      "Epoch 156/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0078\n",
      "Epoch 156: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.6926 - val_loss: 2.3238\n",
      "Epoch 157/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0133\n",
      "Epoch 157: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0133 - val_accuracy: 0.7395 - val_loss: 2.1863\n",
      "Epoch 158/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0058\n",
      "Epoch 158: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.7585 - val_loss: 2.0948\n",
      "Epoch 159/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0046\n",
      "Epoch 159: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.7206 - val_loss: 2.1412\n",
      "Epoch 160/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0152\n",
      "Epoch 160: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0152 - val_accuracy: 0.7345 - val_loss: 2.0280\n",
      "Epoch 161/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0102\n",
      "Epoch 161: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0102 - val_accuracy: 0.7106 - val_loss: 2.0256\n",
      "Epoch 162/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0101\n",
      "Epoch 162: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0101 - val_accuracy: 0.7445 - val_loss: 2.1729\n",
      "Epoch 163/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0049\n",
      "Epoch 163: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0049 - val_accuracy: 0.7345 - val_loss: 1.9519\n",
      "Epoch 164/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0042\n",
      "Epoch 164: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0042 - val_accuracy: 0.7625 - val_loss: 2.0450\n",
      "Epoch 165/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0159\n",
      "Epoch 165: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9946 - loss: 0.0160 - val_accuracy: 0.6806 - val_loss: 2.3161\n",
      "Epoch 166/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0297\n",
      "Epoch 166: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0297 - val_accuracy: 0.7375 - val_loss: 2.1435\n",
      "Epoch 167/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0090\n",
      "Epoch 167: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0089 - val_accuracy: 0.7415 - val_loss: 1.8358\n",
      "Epoch 168/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0023\n",
      "Epoch 168: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.7395 - val_loss: 1.9480\n",
      "Epoch 169/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0018\n",
      "Epoch 169: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 0.7425 - val_loss: 1.9096\n",
      "Epoch 170/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0025\n",
      "Epoch 170: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.7495 - val_loss: 2.0226\n",
      "Epoch 171/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0073\n",
      "Epoch 171: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 0.7206 - val_loss: 2.1605\n",
      "Epoch 172/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 0.0262\n",
      "Epoch 172: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0261 - val_accuracy: 0.7325 - val_loss: 2.1197\n",
      "Epoch 173/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0138\n",
      "Epoch 173: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0138 - val_accuracy: 0.7166 - val_loss: 2.0466\n",
      "Epoch 174/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0110\n",
      "Epoch 174: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0110 - val_accuracy: 0.7355 - val_loss: 1.9225\n",
      "Epoch 175/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0060\n",
      "Epoch 175: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0060 - val_accuracy: 0.7495 - val_loss: 1.9627\n",
      "Epoch 176/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0054\n",
      "Epoch 176: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0054 - val_accuracy: 0.7475 - val_loss: 1.9451\n",
      "Epoch 177/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0129\n",
      "Epoch 177: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0130 - val_accuracy: 0.7355 - val_loss: 2.0433\n",
      "Epoch 178/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0283\n",
      "Epoch 178: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0282 - val_accuracy: 0.7295 - val_loss: 1.9811\n",
      "Epoch 179/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0049\n",
      "Epoch 179: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0049 - val_accuracy: 0.7355 - val_loss: 1.9708\n",
      "Epoch 180/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0181\n",
      "Epoch 180: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0180 - val_accuracy: 0.7275 - val_loss: 1.9448\n",
      "Epoch 181/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0052\n",
      "Epoch 181: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.7475 - val_loss: 1.9435\n",
      "Epoch 182/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0022\n",
      "Epoch 182: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.7475 - val_loss: 2.0796\n",
      "Epoch 183/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0034\n",
      "Epoch 183: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.7255 - val_loss: 2.2465\n",
      "Epoch 184/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9858 - loss: 0.0376\n",
      "Epoch 184: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0376 - val_accuracy: 0.7345 - val_loss: 1.9678\n",
      "Epoch 185/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0067\n",
      "Epoch 185: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0067 - val_accuracy: 0.7515 - val_loss: 1.9622\n",
      "Epoch 186/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0018\n",
      "Epoch 186: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.7425 - val_loss: 1.8820\n",
      "Epoch 187/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0024\n",
      "Epoch 187: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.7495 - val_loss: 1.9285\n",
      "Epoch 188/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 7.9916e-04\n",
      "Epoch 188: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 8.0093e-04 - val_accuracy: 0.7355 - val_loss: 1.8470\n",
      "Epoch 189/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0025\n",
      "Epoch 189: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.7475 - val_loss: 2.3428\n",
      "Epoch 190/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0452\n",
      "Epoch 190: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0452 - val_accuracy: 0.7315 - val_loss: 1.9885\n",
      "Epoch 191/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0129\n",
      "Epoch 191: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0129 - val_accuracy: 0.7375 - val_loss: 1.8604\n",
      "Epoch 192/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0030\n",
      "Epoch 192: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.7475 - val_loss: 1.9626\n",
      "Epoch 193/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0014\n",
      "Epoch 193: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.7385 - val_loss: 1.9812\n",
      "Epoch 194/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 194: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7525 - val_loss: 2.2285\n",
      "Epoch 195/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0012\n",
      "Epoch 195: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0012 - val_accuracy: 0.7465 - val_loss: 1.9961\n",
      "Epoch 196/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 4.8931e-04\n",
      "Epoch 196: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 4.9806e-04 - val_accuracy: 0.7325 - val_loss: 2.1513\n",
      "Epoch 197/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0183\n",
      "Epoch 197: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0183 - val_accuracy: 0.7275 - val_loss: 1.9968\n",
      "Epoch 198/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0293\n",
      "Epoch 198: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0293 - val_accuracy: 0.7505 - val_loss: 1.9898\n",
      "Epoch 199/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0050\n",
      "Epoch 199: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 0.7545 - val_loss: 2.0040\n",
      "Epoch 200/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0026\n",
      "Epoch 200: val_loss did not improve from 0.72863\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.7495 - val_loss: 1.9050\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6233 - loss: 3.1329\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "model3 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6525 - loss: 1.0541\n",
      "Epoch 1: val_loss improved from inf to 1.62693, saving model to model_4/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6529 - loss: 1.0522 - val_accuracy: 0.3743 - val_loss: 1.6269\n",
      "Epoch 2/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7172 - loss: 0.8040\n",
      "Epoch 2: val_loss improved from 1.62693 to 1.09617, saving model to model_4/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7173 - loss: 0.8038 - val_accuracy: 0.6437 - val_loss: 1.0962\n",
      "Epoch 3/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 0.7254\n",
      "Epoch 3: val_loss improved from 1.09617 to 0.76216, saving model to model_4/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7377 - loss: 0.7254 - val_accuracy: 0.7106 - val_loss: 0.7622\n",
      "Epoch 4/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7491 - loss: 0.6780\n",
      "Epoch 4: val_loss improved from 0.76216 to 0.73645, saving model to model_4/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7492 - loss: 0.6779 - val_accuracy: 0.7226 - val_loss: 0.7365\n",
      "Epoch 5/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7659 - loss: 0.6356\n",
      "Epoch 5: val_loss did not improve from 0.73645\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7659 - loss: 0.6354 - val_accuracy: 0.7295 - val_loss: 0.7508\n",
      "Epoch 6/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7924 - loss: 0.5623\n",
      "Epoch 6: val_loss improved from 0.73645 to 0.73091, saving model to model_4/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7922 - loss: 0.5627 - val_accuracy: 0.7395 - val_loss: 0.7309\n",
      "Epoch 7/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8053 - loss: 0.5395\n",
      "Epoch 7: val_loss did not improve from 0.73091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8052 - loss: 0.5395 - val_accuracy: 0.5639 - val_loss: 1.0997\n",
      "Epoch 8/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8191 - loss: 0.5025\n",
      "Epoch 8: val_loss improved from 0.73091 to 0.68483, saving model to model_4/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8190 - loss: 0.5025 - val_accuracy: 0.7495 - val_loss: 0.6848\n",
      "Epoch 9/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8405 - loss: 0.4540\n",
      "Epoch 9: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8404 - loss: 0.4541 - val_accuracy: 0.6866 - val_loss: 0.8606\n",
      "Epoch 10/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8487 - loss: 0.4296\n",
      "Epoch 10: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8485 - loss: 0.4297 - val_accuracy: 0.7196 - val_loss: 0.9456\n",
      "Epoch 11/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8634 - loss: 0.3857\n",
      "Epoch 11: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8633 - loss: 0.3857 - val_accuracy: 0.7515 - val_loss: 0.7420\n",
      "Epoch 12/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8812 - loss: 0.3521\n",
      "Epoch 12: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8811 - loss: 0.3523 - val_accuracy: 0.7166 - val_loss: 0.8603\n",
      "Epoch 13/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8781 - loss: 0.3371\n",
      "Epoch 13: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8781 - loss: 0.3372 - val_accuracy: 0.7375 - val_loss: 0.8200\n",
      "Epoch 14/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8935 - loss: 0.3043\n",
      "Epoch 14: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8935 - loss: 0.3043 - val_accuracy: 0.7365 - val_loss: 0.8140\n",
      "Epoch 15/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9102 - loss: 0.2685\n",
      "Epoch 15: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2686 - val_accuracy: 0.7236 - val_loss: 0.7892\n",
      "Epoch 16/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9140 - loss: 0.2501\n",
      "Epoch 16: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9139 - loss: 0.2505 - val_accuracy: 0.7106 - val_loss: 1.1233\n",
      "Epoch 17/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9282 - loss: 0.2184\n",
      "Epoch 17: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9281 - loss: 0.2185 - val_accuracy: 0.7465 - val_loss: 0.8897\n",
      "Epoch 18/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.1963\n",
      "Epoch 18: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9361 - loss: 0.1965 - val_accuracy: 0.7216 - val_loss: 0.8663\n",
      "Epoch 19/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.1875\n",
      "Epoch 19: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9406 - loss: 0.1876 - val_accuracy: 0.7405 - val_loss: 0.9218\n",
      "Epoch 20/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1563\n",
      "Epoch 20: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9530 - loss: 0.1563 - val_accuracy: 0.7226 - val_loss: 1.0424\n",
      "Epoch 21/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1439\n",
      "Epoch 21: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.1441 - val_accuracy: 0.7066 - val_loss: 1.0116\n",
      "Epoch 22/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9658 - loss: 0.1254\n",
      "Epoch 22: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9657 - loss: 0.1254 - val_accuracy: 0.7265 - val_loss: 1.2385\n",
      "Epoch 23/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9645 - loss: 0.1155\n",
      "Epoch 23: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9644 - loss: 0.1157 - val_accuracy: 0.7216 - val_loss: 1.0640\n",
      "Epoch 24/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.1019\n",
      "Epoch 24: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.1020 - val_accuracy: 0.6916 - val_loss: 1.1660\n",
      "Epoch 25/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9724 - loss: 0.0959\n",
      "Epoch 25: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9724 - loss: 0.0959 - val_accuracy: 0.7196 - val_loss: 1.2357\n",
      "Epoch 26/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0799\n",
      "Epoch 26: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.0798 - val_accuracy: 0.7136 - val_loss: 1.1495\n",
      "Epoch 27/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0657\n",
      "Epoch 27: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0658 - val_accuracy: 0.7076 - val_loss: 1.3164\n",
      "Epoch 28/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9707 - loss: 0.0867\n",
      "Epoch 28: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9707 - loss: 0.0867 - val_accuracy: 0.6896 - val_loss: 1.2751\n",
      "Epoch 29/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0633\n",
      "Epoch 29: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0635 - val_accuracy: 0.7246 - val_loss: 1.3994\n",
      "Epoch 30/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0605\n",
      "Epoch 30: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.0606 - val_accuracy: 0.7216 - val_loss: 1.3989\n",
      "Epoch 31/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0561\n",
      "Epoch 31: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0563 - val_accuracy: 0.7146 - val_loss: 1.2677\n",
      "Epoch 32/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9801 - loss: 0.0594\n",
      "Epoch 32: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.0595 - val_accuracy: 0.6916 - val_loss: 1.3547\n",
      "Epoch 33/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.0563\n",
      "Epoch 33: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0561 - val_accuracy: 0.7246 - val_loss: 1.4357\n",
      "Epoch 34/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0345\n",
      "Epoch 34: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0345 - val_accuracy: 0.7176 - val_loss: 1.3652\n",
      "Epoch 35/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0529\n",
      "Epoch 35: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0530 - val_accuracy: 0.7106 - val_loss: 1.4776\n",
      "Epoch 36/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9809 - loss: 0.0585\n",
      "Epoch 36: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9809 - loss: 0.0585 - val_accuracy: 0.7226 - val_loss: 1.3929\n",
      "Epoch 37/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.0436\n",
      "Epoch 37: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0436 - val_accuracy: 0.6966 - val_loss: 1.4271\n",
      "Epoch 38/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0487\n",
      "Epoch 38: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0487 - val_accuracy: 0.7255 - val_loss: 1.4569\n",
      "Epoch 39/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0328\n",
      "Epoch 39: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0327 - val_accuracy: 0.7196 - val_loss: 1.6459\n",
      "Epoch 40/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0274\n",
      "Epoch 40: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0274 - val_accuracy: 0.7036 - val_loss: 1.4856\n",
      "Epoch 41/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0260\n",
      "Epoch 41: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0261 - val_accuracy: 0.6956 - val_loss: 1.5557\n",
      "Epoch 42/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.0562\n",
      "Epoch 42: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0563 - val_accuracy: 0.7236 - val_loss: 1.4987\n",
      "Epoch 43/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0367\n",
      "Epoch 43: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0366 - val_accuracy: 0.7265 - val_loss: 1.5734\n",
      "Epoch 44/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0378\n",
      "Epoch 44: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0378 - val_accuracy: 0.7146 - val_loss: 1.6386\n",
      "Epoch 45/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0228\n",
      "Epoch 45: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0228 - val_accuracy: 0.7106 - val_loss: 1.6115\n",
      "Epoch 46/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0184\n",
      "Epoch 46: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0184 - val_accuracy: 0.7255 - val_loss: 1.5817\n",
      "Epoch 47/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0101\n",
      "Epoch 47: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0102 - val_accuracy: 0.7226 - val_loss: 1.7775\n",
      "Epoch 48/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0357\n",
      "Epoch 48: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0358 - val_accuracy: 0.7096 - val_loss: 1.6587\n",
      "Epoch 49/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9829 - loss: 0.0534\n",
      "Epoch 49: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0534 - val_accuracy: 0.7226 - val_loss: 1.7077\n",
      "Epoch 50/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0448\n",
      "Epoch 50: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0447 - val_accuracy: 0.7006 - val_loss: 1.6911\n",
      "Epoch 51/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0162\n",
      "Epoch 51: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0162 - val_accuracy: 0.7335 - val_loss: 1.7358\n",
      "Epoch 52/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0131\n",
      "Epoch 52: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0131 - val_accuracy: 0.7295 - val_loss: 1.7160\n",
      "Epoch 53/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0062\n",
      "Epoch 53: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0062 - val_accuracy: 0.7385 - val_loss: 1.9605\n",
      "Epoch 54/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0273\n",
      "Epoch 54: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0275 - val_accuracy: 0.6946 - val_loss: 2.1727\n",
      "Epoch 55/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0717\n",
      "Epoch 55: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9747 - loss: 0.0716 - val_accuracy: 0.7226 - val_loss: 1.5796\n",
      "Epoch 56/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0201\n",
      "Epoch 56: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0202 - val_accuracy: 0.7365 - val_loss: 1.5396\n",
      "Epoch 57/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0222\n",
      "Epoch 57: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0221 - val_accuracy: 0.7295 - val_loss: 1.7052\n",
      "Epoch 58/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0186\n",
      "Epoch 58: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0186 - val_accuracy: 0.7176 - val_loss: 1.7922\n",
      "Epoch 59/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9875 - loss: 0.0355\n",
      "Epoch 59: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0354 - val_accuracy: 0.7285 - val_loss: 1.8618\n",
      "Epoch 60/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9872 - loss: 0.0330\n",
      "Epoch 60: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0332 - val_accuracy: 0.7255 - val_loss: 1.6747\n",
      "Epoch 61/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0223\n",
      "Epoch 61: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0226 - val_accuracy: 0.6946 - val_loss: 2.0148\n",
      "Epoch 62/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0216\n",
      "Epoch 62: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0216 - val_accuracy: 0.7156 - val_loss: 1.8046\n",
      "Epoch 63/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0174\n",
      "Epoch 63: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0174 - val_accuracy: 0.7335 - val_loss: 1.8242\n",
      "Epoch 64/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0139\n",
      "Epoch 64: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 0.7166 - val_loss: 1.7276\n",
      "Epoch 65/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0077\n",
      "Epoch 65: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0077 - val_accuracy: 0.7126 - val_loss: 1.8832\n",
      "Epoch 66/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0232\n",
      "Epoch 66: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0234 - val_accuracy: 0.7236 - val_loss: 1.7993\n",
      "Epoch 67/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0436\n",
      "Epoch 67: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0435 - val_accuracy: 0.7086 - val_loss: 1.9061\n",
      "Epoch 68/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0289\n",
      "Epoch 68: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0289 - val_accuracy: 0.7275 - val_loss: 1.9837\n",
      "Epoch 69/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0133\n",
      "Epoch 69: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0133 - val_accuracy: 0.7136 - val_loss: 1.8467\n",
      "Epoch 70/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9938 - loss: 0.0191\n",
      "Epoch 70: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0191 - val_accuracy: 0.7096 - val_loss: 2.0066\n",
      "Epoch 71/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0145\n",
      "Epoch 71: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0146 - val_accuracy: 0.7136 - val_loss: 2.1228\n",
      "Epoch 72/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0253\n",
      "Epoch 72: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0251 - val_accuracy: 0.7285 - val_loss: 1.7979\n",
      "Epoch 73/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0267\n",
      "Epoch 73: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0267 - val_accuracy: 0.7036 - val_loss: 1.8731\n",
      "Epoch 74/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0127\n",
      "Epoch 74: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0127 - val_accuracy: 0.6936 - val_loss: 2.0277\n",
      "Epoch 75/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0152\n",
      "Epoch 75: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0152 - val_accuracy: 0.7325 - val_loss: 1.8172\n",
      "Epoch 76/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0079\n",
      "Epoch 76: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0080 - val_accuracy: 0.7006 - val_loss: 2.0252\n",
      "Epoch 77/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0181\n",
      "Epoch 77: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0181 - val_accuracy: 0.6816 - val_loss: 2.2108\n",
      "Epoch 78/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0337\n",
      "Epoch 78: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0337 - val_accuracy: 0.7375 - val_loss: 1.8910\n",
      "Epoch 79/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0397\n",
      "Epoch 79: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0396 - val_accuracy: 0.7246 - val_loss: 1.8593\n",
      "Epoch 80/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0161\n",
      "Epoch 80: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.7265 - val_loss: 1.9176\n",
      "Epoch 81/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0051\n",
      "Epoch 81: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0051 - val_accuracy: 0.7385 - val_loss: 1.7214\n",
      "Epoch 82/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0093\n",
      "Epoch 82: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0095 - val_accuracy: 0.7006 - val_loss: 2.1935\n",
      "Epoch 83/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0228\n",
      "Epoch 83: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0228 - val_accuracy: 0.7186 - val_loss: 1.8209\n",
      "Epoch 84/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0128\n",
      "Epoch 84: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0128 - val_accuracy: 0.7196 - val_loss: 2.2947\n",
      "Epoch 85/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0171\n",
      "Epoch 85: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0170 - val_accuracy: 0.7265 - val_loss: 1.9075\n",
      "Epoch 86/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0041\n",
      "Epoch 86: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0041 - val_accuracy: 0.7246 - val_loss: 1.8044\n",
      "Epoch 87/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0052\n",
      "Epoch 87: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.7146 - val_loss: 1.9129\n",
      "Epoch 88/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0240\n",
      "Epoch 88: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0241 - val_accuracy: 0.6717 - val_loss: 2.0872\n",
      "Epoch 89/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9849 - loss: 0.0406\n",
      "Epoch 89: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0406 - val_accuracy: 0.7136 - val_loss: 1.9156\n",
      "Epoch 90/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0120\n",
      "Epoch 90: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0120 - val_accuracy: 0.7186 - val_loss: 1.9579\n",
      "Epoch 91/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0044\n",
      "Epoch 91: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0044 - val_accuracy: 0.7345 - val_loss: 1.9546\n",
      "Epoch 92/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0080\n",
      "Epoch 92: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0082 - val_accuracy: 0.7186 - val_loss: 1.9242\n",
      "Epoch 93/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0274\n",
      "Epoch 93: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0275 - val_accuracy: 0.7216 - val_loss: 1.9247\n",
      "Epoch 94/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0199\n",
      "Epoch 94: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0199 - val_accuracy: 0.7325 - val_loss: 1.8226\n",
      "Epoch 95/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0126\n",
      "Epoch 95: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.7345 - val_loss: 2.2815\n",
      "Epoch 96/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0070\n",
      "Epoch 96: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0070 - val_accuracy: 0.7345 - val_loss: 1.8385\n",
      "Epoch 97/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0039\n",
      "Epoch 97: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0039 - val_accuracy: 0.7255 - val_loss: 1.9432\n",
      "Epoch 98/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0029\n",
      "Epoch 98: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.7136 - val_loss: 2.9962\n",
      "Epoch 99/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0489\n",
      "Epoch 99: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0488 - val_accuracy: 0.7196 - val_loss: 1.9507\n",
      "Epoch 100/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0175\n",
      "Epoch 100: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0175 - val_accuracy: 0.7285 - val_loss: 1.7796\n",
      "Epoch 101/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0219\n",
      "Epoch 101: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0219 - val_accuracy: 0.7345 - val_loss: 1.9068\n",
      "Epoch 102/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9953 - loss: 0.0170\n",
      "Epoch 102: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0170 - val_accuracy: 0.7036 - val_loss: 1.8075\n",
      "Epoch 103/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0076\n",
      "Epoch 103: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0075 - val_accuracy: 0.7236 - val_loss: 1.8661\n",
      "Epoch 104/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0013\n",
      "Epoch 104: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7295 - val_loss: 1.7912\n",
      "Epoch 105/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0029\n",
      "Epoch 105: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.7086 - val_loss: 1.9331\n",
      "Epoch 106/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0072\n",
      "Epoch 106: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.7236 - val_loss: 2.2530\n",
      "Epoch 107/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0542\n",
      "Epoch 107: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.0544 - val_accuracy: 0.7096 - val_loss: 2.0645\n",
      "Epoch 108/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9898 - loss: 0.0305\n",
      "Epoch 108: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0302 - val_accuracy: 0.7395 - val_loss: 1.7609\n",
      "Epoch 109/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0131\n",
      "Epoch 109: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0131 - val_accuracy: 0.7325 - val_loss: 2.0199\n",
      "Epoch 110/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0072\n",
      "Epoch 110: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0072 - val_accuracy: 0.7096 - val_loss: 1.8268\n",
      "Epoch 111/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0036\n",
      "Epoch 111: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0036 - val_accuracy: 0.7295 - val_loss: 1.8079\n",
      "Epoch 112/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0018\n",
      "Epoch 112: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0018 - val_accuracy: 0.7345 - val_loss: 1.8731\n",
      "Epoch 113/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0136\n",
      "Epoch 113: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0139 - val_accuracy: 0.7076 - val_loss: 2.1939\n",
      "Epoch 114/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0469\n",
      "Epoch 114: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0468 - val_accuracy: 0.7196 - val_loss: 2.1752\n",
      "Epoch 115/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0123\n",
      "Epoch 115: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0123 - val_accuracy: 0.7285 - val_loss: 1.7990\n",
      "Epoch 116/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0047\n",
      "Epoch 116: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.7116 - val_loss: 1.8665\n",
      "Epoch 117/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0021\n",
      "Epoch 117: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0021 - val_accuracy: 0.7236 - val_loss: 1.9576\n",
      "Epoch 118/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0031\n",
      "Epoch 118: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.6816 - val_loss: 2.3543\n",
      "Epoch 119/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0291\n",
      "Epoch 119: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0291 - val_accuracy: 0.7236 - val_loss: 1.9693\n",
      "Epoch 120/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0238\n",
      "Epoch 120: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0237 - val_accuracy: 0.7305 - val_loss: 1.8524\n",
      "Epoch 121/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0122\n",
      "Epoch 121: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0122 - val_accuracy: 0.7355 - val_loss: 1.9363\n",
      "Epoch 122/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0222\n",
      "Epoch 122: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0221 - val_accuracy: 0.7086 - val_loss: 1.8538\n",
      "Epoch 123/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0092\n",
      "Epoch 123: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0092 - val_accuracy: 0.7246 - val_loss: 1.9795\n",
      "Epoch 124/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0054\n",
      "Epoch 124: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.7455 - val_loss: 2.0107\n",
      "Epoch 125/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0123\n",
      "Epoch 125: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0124 - val_accuracy: 0.7375 - val_loss: 2.2599\n",
      "Epoch 126/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0172\n",
      "Epoch 126: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0171 - val_accuracy: 0.7305 - val_loss: 1.8894\n",
      "Epoch 127/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0196\n",
      "Epoch 127: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0199 - val_accuracy: 0.7226 - val_loss: 1.9752\n",
      "Epoch 128/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0087\n",
      "Epoch 128: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.7405 - val_loss: 1.9814\n",
      "Epoch 129/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0034\n",
      "Epoch 129: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.7305 - val_loss: 1.9006\n",
      "Epoch 130/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0017\n",
      "Epoch 130: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0017 - val_accuracy: 0.7385 - val_loss: 2.0930\n",
      "Epoch 131/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 9.3053e-04\n",
      "Epoch 131: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 9.6126e-04 - val_accuracy: 0.7385 - val_loss: 2.2425\n",
      "Epoch 132/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0214\n",
      "Epoch 132: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0215 - val_accuracy: 0.7026 - val_loss: 2.1689\n",
      "Epoch 133/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0184\n",
      "Epoch 133: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0184 - val_accuracy: 0.7315 - val_loss: 1.9792\n",
      "Epoch 134/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0096\n",
      "Epoch 134: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0096 - val_accuracy: 0.7305 - val_loss: 1.9044\n",
      "Epoch 135/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0120\n",
      "Epoch 135: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0120 - val_accuracy: 0.7385 - val_loss: 2.0701\n",
      "Epoch 136/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0156\n",
      "Epoch 136: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0157 - val_accuracy: 0.7216 - val_loss: 1.9950\n",
      "Epoch 137/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0087\n",
      "Epoch 137: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0087 - val_accuracy: 0.7425 - val_loss: 1.8456\n",
      "Epoch 138/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0025\n",
      "Epoch 138: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.7275 - val_loss: 2.0878\n",
      "Epoch 139/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0094\n",
      "Epoch 139: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0094 - val_accuracy: 0.7435 - val_loss: 2.2499\n",
      "Epoch 140/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0237\n",
      "Epoch 140: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0240 - val_accuracy: 0.7216 - val_loss: 2.1756\n",
      "Epoch 141/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0227\n",
      "Epoch 141: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0226 - val_accuracy: 0.7465 - val_loss: 2.0079\n",
      "Epoch 142/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0052\n",
      "Epoch 142: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0052 - val_accuracy: 0.7375 - val_loss: 2.1098\n",
      "Epoch 143/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0029\n",
      "Epoch 143: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.7265 - val_loss: 2.0058\n",
      "Epoch 144/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0042\n",
      "Epoch 144: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0042 - val_accuracy: 0.7325 - val_loss: 2.1857\n",
      "Epoch 145/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0117\n",
      "Epoch 145: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0115 - val_accuracy: 0.7285 - val_loss: 2.0278\n",
      "Epoch 146/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0158\n",
      "Epoch 146: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0158 - val_accuracy: 0.7246 - val_loss: 2.3761\n",
      "Epoch 147/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0318\n",
      "Epoch 147: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0317 - val_accuracy: 0.7305 - val_loss: 2.3723\n",
      "Epoch 148/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0070\n",
      "Epoch 148: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.7196 - val_loss: 2.0606\n",
      "Epoch 149/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0034\n",
      "Epoch 149: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.7275 - val_loss: 1.9812\n",
      "Epoch 150/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0022\n",
      "Epoch 150: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.7325 - val_loss: 1.9839\n",
      "Epoch 151/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0035\n",
      "Epoch 151: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.6906 - val_loss: 2.1535\n",
      "Epoch 152/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0419\n",
      "Epoch 152: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0417 - val_accuracy: 0.7385 - val_loss: 1.9059\n",
      "Epoch 153/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0120\n",
      "Epoch 153: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0120 - val_accuracy: 0.7186 - val_loss: 1.9478\n",
      "Epoch 154/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0048\n",
      "Epoch 154: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.7335 - val_loss: 1.9388\n",
      "Epoch 155/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0021\n",
      "Epoch 155: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.7435 - val_loss: 2.1371\n",
      "Epoch 156/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 7.0711e-04\n",
      "Epoch 156: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 7.0903e-04 - val_accuracy: 0.7275 - val_loss: 2.0602\n",
      "Epoch 157/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0017\n",
      "Epoch 157: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.7425 - val_loss: 2.0297\n",
      "Epoch 158/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0099\n",
      "Epoch 158: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.7036 - val_loss: 2.4363\n",
      "Epoch 159/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0438\n",
      "Epoch 159: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9872 - loss: 0.0438 - val_accuracy: 0.7086 - val_loss: 2.3321\n",
      "Epoch 160/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0127\n",
      "Epoch 160: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0127 - val_accuracy: 0.7545 - val_loss: 1.9885\n",
      "Epoch 161/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0025\n",
      "Epoch 161: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 0.7465 - val_loss: 2.0574\n",
      "Epoch 162/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0031\n",
      "Epoch 162: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.7196 - val_loss: 2.0355\n",
      "Epoch 163/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0075\n",
      "Epoch 163: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0075 - val_accuracy: 0.7365 - val_loss: 2.2496\n",
      "Epoch 164/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0145\n",
      "Epoch 164: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0146 - val_accuracy: 0.7335 - val_loss: 2.0024\n",
      "Epoch 165/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0106\n",
      "Epoch 165: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0106 - val_accuracy: 0.7265 - val_loss: 2.0889\n",
      "Epoch 166/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0045\n",
      "Epoch 166: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0045 - val_accuracy: 0.7265 - val_loss: 1.9967\n",
      "Epoch 167/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.8110e-04\n",
      "Epoch 167: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.8300e-04 - val_accuracy: 0.7375 - val_loss: 2.0657\n",
      "Epoch 168/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 6.9272e-04\n",
      "Epoch 168: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 6.9701e-04 - val_accuracy: 0.7355 - val_loss: 2.1408\n",
      "Epoch 169/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0117\n",
      "Epoch 169: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0118 - val_accuracy: 0.7226 - val_loss: 2.2812\n",
      "Epoch 170/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.0262\n",
      "Epoch 170: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9914 - loss: 0.0262 - val_accuracy: 0.7295 - val_loss: 2.1074\n",
      "Epoch 171/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0195\n",
      "Epoch 171: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0195 - val_accuracy: 0.7315 - val_loss: 2.5057\n",
      "Epoch 172/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0122\n",
      "Epoch 172: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0121 - val_accuracy: 0.7415 - val_loss: 2.1148\n",
      "Epoch 173/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0026\n",
      "Epoch 173: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.7265 - val_loss: 2.0134\n",
      "Epoch 174/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0023\n",
      "Epoch 174: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.7196 - val_loss: 1.9519\n",
      "Epoch 175/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0016\n",
      "Epoch 175: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.7315 - val_loss: 1.9979\n",
      "Epoch 176/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 8.0582e-04\n",
      "Epoch 176: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 8.0819e-04 - val_accuracy: 0.7265 - val_loss: 2.0481\n",
      "Epoch 177/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 6.3715e-04\n",
      "Epoch 177: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 6.4345e-04 - val_accuracy: 0.7285 - val_loss: 2.0638\n",
      "Epoch 178/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0344\n",
      "Epoch 178: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0344 - val_accuracy: 0.7265 - val_loss: 1.9811\n",
      "Epoch 179/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0189\n",
      "Epoch 179: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0188 - val_accuracy: 0.7285 - val_loss: 1.8965\n",
      "Epoch 180/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0030\n",
      "Epoch 180: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.7375 - val_loss: 2.0151\n",
      "Epoch 181/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0028\n",
      "Epoch 181: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.7315 - val_loss: 2.1491\n",
      "Epoch 182/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0026\n",
      "Epoch 182: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.7285 - val_loss: 1.9729\n",
      "Epoch 183/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0069\n",
      "Epoch 183: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0069 - val_accuracy: 0.7295 - val_loss: 2.0163\n",
      "Epoch 184/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0033\n",
      "Epoch 184: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.7136 - val_loss: 2.2779\n",
      "Epoch 185/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0135\n",
      "Epoch 185: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0137 - val_accuracy: 0.7275 - val_loss: 2.2043\n",
      "Epoch 186/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0161\n",
      "Epoch 186: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.7036 - val_loss: 2.3201\n",
      "Epoch 187/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0298\n",
      "Epoch 187: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0297 - val_accuracy: 0.7315 - val_loss: 2.0608\n",
      "Epoch 188/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0079\n",
      "Epoch 188: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0079 - val_accuracy: 0.7365 - val_loss: 2.1941\n",
      "Epoch 189/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0054\n",
      "Epoch 189: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 0.7335 - val_loss: 2.1065\n",
      "Epoch 190/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0010\n",
      "Epoch 190: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7156 - val_loss: 2.0324\n",
      "Epoch 191/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0038\n",
      "Epoch 191: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.7325 - val_loss: 2.2053\n",
      "Epoch 192/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0152\n",
      "Epoch 192: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0152 - val_accuracy: 0.7186 - val_loss: 2.1261\n",
      "Epoch 193/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0301\n",
      "Epoch 193: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0300 - val_accuracy: 0.7305 - val_loss: 2.4105\n",
      "Epoch 194/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0055\n",
      "Epoch 194: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0055 - val_accuracy: 0.7186 - val_loss: 2.0500\n",
      "Epoch 195/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0020\n",
      "Epoch 195: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0020 - val_accuracy: 0.7455 - val_loss: 2.2060\n",
      "Epoch 196/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0016\n",
      "Epoch 196: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.7465 - val_loss: 2.0957\n",
      "Epoch 197/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.8661e-04\n",
      "Epoch 197: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.8559e-04 - val_accuracy: 0.7395 - val_loss: 2.0975\n",
      "Epoch 198/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0041\n",
      "Epoch 198: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.7036 - val_loss: 2.4125\n",
      "Epoch 199/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0295\n",
      "Epoch 199: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0295 - val_accuracy: 0.7285 - val_loss: 2.1606\n",
      "Epoch 200/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0062\n",
      "Epoch 200: val_loss did not improve from 0.68483\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0062 - val_accuracy: 0.7445 - val_loss: 2.0301\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5772 - loss: 3.6658\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "model4 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6459 - loss: 1.0846\n",
      "Epoch 1: val_loss improved from inf to 1.47829, saving model to model_5/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6460 - loss: 1.0841 - val_accuracy: 0.5305 - val_loss: 1.4783\n",
      "Epoch 2/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7189 - loss: 0.7842\n",
      "Epoch 2: val_loss improved from 1.47829 to 1.06452, saving model to model_5/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7190 - loss: 0.7840 - val_accuracy: 0.6134 - val_loss: 1.0645\n",
      "Epoch 3/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7383 - loss: 0.7131\n",
      "Epoch 3: val_loss did not improve from 1.06452\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7384 - loss: 0.7129 - val_accuracy: 0.6753 - val_loss: 1.2334\n",
      "Epoch 4/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7663 - loss: 0.6527\n",
      "Epoch 4: val_loss improved from 1.06452 to 0.77059, saving model to model_5/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7663 - loss: 0.6527 - val_accuracy: 0.7263 - val_loss: 0.7706\n",
      "Epoch 5/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7767 - loss: 0.6163\n",
      "Epoch 5: val_loss improved from 0.77059 to 0.73157, saving model to model_5/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7767 - loss: 0.6162 - val_accuracy: 0.7373 - val_loss: 0.7316\n",
      "Epoch 6/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7974 - loss: 0.5716\n",
      "Epoch 6: val_loss did not improve from 0.73157\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7973 - loss: 0.5715 - val_accuracy: 0.7203 - val_loss: 0.8208\n",
      "Epoch 7/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8099 - loss: 0.5193\n",
      "Epoch 7: val_loss did not improve from 0.73157\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8098 - loss: 0.5195 - val_accuracy: 0.7223 - val_loss: 0.8610\n",
      "Epoch 8/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8264 - loss: 0.4765\n",
      "Epoch 8: val_loss did not improve from 0.73157\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8263 - loss: 0.4770 - val_accuracy: 0.6653 - val_loss: 0.8338\n",
      "Epoch 9/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8375 - loss: 0.4607\n",
      "Epoch 9: val_loss improved from 0.73157 to 0.72126, saving model to model_5/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8374 - loss: 0.4606 - val_accuracy: 0.7582 - val_loss: 0.7213\n",
      "Epoch 10/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8560 - loss: 0.4046\n",
      "Epoch 10: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8559 - loss: 0.4048 - val_accuracy: 0.6953 - val_loss: 0.7947\n",
      "Epoch 11/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8709 - loss: 0.3742\n",
      "Epoch 11: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8707 - loss: 0.3746 - val_accuracy: 0.7013 - val_loss: 0.8483\n",
      "Epoch 12/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8862 - loss: 0.3363\n",
      "Epoch 12: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.3363 - val_accuracy: 0.7343 - val_loss: 0.7853\n",
      "Epoch 13/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8972 - loss: 0.3029\n",
      "Epoch 13: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8970 - loss: 0.3033 - val_accuracy: 0.6384 - val_loss: 1.0208\n",
      "Epoch 14/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9032 - loss: 0.2833\n",
      "Epoch 14: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9032 - loss: 0.2833 - val_accuracy: 0.7393 - val_loss: 0.8782\n",
      "Epoch 15/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2523\n",
      "Epoch 15: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9156 - loss: 0.2523 - val_accuracy: 0.7293 - val_loss: 1.1313\n",
      "Epoch 16/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9158 - loss: 0.2494\n",
      "Epoch 16: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9158 - loss: 0.2494 - val_accuracy: 0.7423 - val_loss: 0.8619\n",
      "Epoch 17/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9338 - loss: 0.2043\n",
      "Epoch 17: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9338 - loss: 0.2043 - val_accuracy: 0.7113 - val_loss: 0.9040\n",
      "Epoch 18/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.1834\n",
      "Epoch 18: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9400 - loss: 0.1836 - val_accuracy: 0.7283 - val_loss: 0.9159\n",
      "Epoch 19/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9467 - loss: 0.1642\n",
      "Epoch 19: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9467 - loss: 0.1643 - val_accuracy: 0.7193 - val_loss: 1.0117\n",
      "Epoch 20/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.1442\n",
      "Epoch 20: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9518 - loss: 0.1442 - val_accuracy: 0.6793 - val_loss: 1.1368\n",
      "Epoch 21/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9626 - loss: 0.1181\n",
      "Epoch 21: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9624 - loss: 0.1185 - val_accuracy: 0.7353 - val_loss: 1.2254\n",
      "Epoch 22/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9696 - loss: 0.1052\n",
      "Epoch 22: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9695 - loss: 0.1053 - val_accuracy: 0.7243 - val_loss: 1.1475\n",
      "Epoch 23/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9705 - loss: 0.0982\n",
      "Epoch 23: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9705 - loss: 0.0983 - val_accuracy: 0.7263 - val_loss: 1.1277\n",
      "Epoch 24/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9723 - loss: 0.0900\n",
      "Epoch 24: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9722 - loss: 0.0904 - val_accuracy: 0.7143 - val_loss: 1.3511\n",
      "Epoch 25/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9753 - loss: 0.0859\n",
      "Epoch 25: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9753 - loss: 0.0858 - val_accuracy: 0.7133 - val_loss: 1.2552\n",
      "Epoch 26/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0783\n",
      "Epoch 26: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0784 - val_accuracy: 0.6983 - val_loss: 1.2796\n",
      "Epoch 27/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.0687\n",
      "Epoch 27: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9815 - loss: 0.0687 - val_accuracy: 0.7013 - val_loss: 1.4434\n",
      "Epoch 28/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0565\n",
      "Epoch 28: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0565 - val_accuracy: 0.7323 - val_loss: 1.2983\n",
      "Epoch 29/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.0567\n",
      "Epoch 29: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.0568 - val_accuracy: 0.7253 - val_loss: 1.3214\n",
      "Epoch 30/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0554\n",
      "Epoch 30: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0555 - val_accuracy: 0.7043 - val_loss: 1.4706\n",
      "Epoch 31/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0547\n",
      "Epoch 31: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0549 - val_accuracy: 0.7313 - val_loss: 1.3360\n",
      "Epoch 32/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0455\n",
      "Epoch 32: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0455 - val_accuracy: 0.6933 - val_loss: 1.4777\n",
      "Epoch 33/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0480\n",
      "Epoch 33: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0480 - val_accuracy: 0.7093 - val_loss: 1.4473\n",
      "Epoch 34/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0429\n",
      "Epoch 34: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0430 - val_accuracy: 0.7163 - val_loss: 2.0433\n",
      "Epoch 35/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0514\n",
      "Epoch 35: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0515 - val_accuracy: 0.7303 - val_loss: 1.4414\n",
      "Epoch 36/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0335\n",
      "Epoch 36: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0336 - val_accuracy: 0.7153 - val_loss: 1.4463\n",
      "Epoch 37/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0318\n",
      "Epoch 37: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0318 - val_accuracy: 0.7223 - val_loss: 1.9619\n",
      "Epoch 38/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0338\n",
      "Epoch 38: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0338 - val_accuracy: 0.7143 - val_loss: 1.6489\n",
      "Epoch 39/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0325\n",
      "Epoch 39: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0326 - val_accuracy: 0.7093 - val_loss: 1.7299\n",
      "Epoch 40/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0527\n",
      "Epoch 40: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0529 - val_accuracy: 0.6843 - val_loss: 1.6715\n",
      "Epoch 41/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0408\n",
      "Epoch 41: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9840 - loss: 0.0407 - val_accuracy: 0.7213 - val_loss: 1.6972\n",
      "Epoch 42/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9943 - loss: 0.0223\n",
      "Epoch 42: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0223 - val_accuracy: 0.7323 - val_loss: 1.5223\n",
      "Epoch 43/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0225\n",
      "Epoch 43: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0225 - val_accuracy: 0.7173 - val_loss: 1.9959\n",
      "Epoch 44/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0539\n",
      "Epoch 44: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0539 - val_accuracy: 0.7103 - val_loss: 1.7372\n",
      "Epoch 45/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0352\n",
      "Epoch 45: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0352 - val_accuracy: 0.6743 - val_loss: 1.8669\n",
      "Epoch 46/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9885 - loss: 0.0304\n",
      "Epoch 46: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0304 - val_accuracy: 0.7263 - val_loss: 1.5893\n",
      "Epoch 47/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0216\n",
      "Epoch 47: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0216 - val_accuracy: 0.7303 - val_loss: 1.7563\n",
      "Epoch 48/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0383\n",
      "Epoch 48: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0382 - val_accuracy: 0.7273 - val_loss: 1.5267\n",
      "Epoch 49/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0202\n",
      "Epoch 49: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0202 - val_accuracy: 0.7383 - val_loss: 1.6120\n",
      "Epoch 50/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0095\n",
      "Epoch 50: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0096 - val_accuracy: 0.7293 - val_loss: 1.6925\n",
      "Epoch 51/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0365\n",
      "Epoch 51: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0366 - val_accuracy: 0.6993 - val_loss: 1.8095\n",
      "Epoch 52/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0333\n",
      "Epoch 52: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0331 - val_accuracy: 0.7113 - val_loss: 1.7092\n",
      "Epoch 53/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0173\n",
      "Epoch 53: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0173 - val_accuracy: 0.6513 - val_loss: 2.2863\n",
      "Epoch 54/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0151\n",
      "Epoch 54: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0152 - val_accuracy: 0.7363 - val_loss: 1.8034\n",
      "Epoch 55/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9883 - loss: 0.0377\n",
      "Epoch 55: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0377 - val_accuracy: 0.7093 - val_loss: 1.8410\n",
      "Epoch 56/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0486\n",
      "Epoch 56: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.0486 - val_accuracy: 0.7263 - val_loss: 1.7408\n",
      "Epoch 57/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0128\n",
      "Epoch 57: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0128 - val_accuracy: 0.7253 - val_loss: 1.7913\n",
      "Epoch 58/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0120\n",
      "Epoch 58: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0121 - val_accuracy: 0.7343 - val_loss: 1.7357\n",
      "Epoch 59/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0183\n",
      "Epoch 59: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0185 - val_accuracy: 0.7253 - val_loss: 1.9583\n",
      "Epoch 60/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0213\n",
      "Epoch 60: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0215 - val_accuracy: 0.7103 - val_loss: 1.8604\n",
      "Epoch 61/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0211\n",
      "Epoch 61: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0212 - val_accuracy: 0.7063 - val_loss: 1.7057\n",
      "Epoch 62/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0148\n",
      "Epoch 62: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0148 - val_accuracy: 0.7493 - val_loss: 1.8512\n",
      "Epoch 63/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0347\n",
      "Epoch 63: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0347 - val_accuracy: 0.7053 - val_loss: 1.9188\n",
      "Epoch 64/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 0.0391\n",
      "Epoch 64: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0390 - val_accuracy: 0.6963 - val_loss: 2.0179\n",
      "Epoch 65/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0283\n",
      "Epoch 65: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0282 - val_accuracy: 0.7183 - val_loss: 1.8922\n",
      "Epoch 66/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 66: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0103 - val_accuracy: 0.7353 - val_loss: 1.9398\n",
      "Epoch 67/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0135\n",
      "Epoch 67: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0135 - val_accuracy: 0.7273 - val_loss: 1.8025\n",
      "Epoch 68/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0087\n",
      "Epoch 68: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0087 - val_accuracy: 0.6623 - val_loss: 2.3094\n",
      "Epoch 69/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0408\n",
      "Epoch 69: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0408 - val_accuracy: 0.7373 - val_loss: 1.7506\n",
      "Epoch 70/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0221\n",
      "Epoch 70: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0220 - val_accuracy: 0.7133 - val_loss: 1.9091\n",
      "Epoch 71/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0092\n",
      "Epoch 71: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 0.7343 - val_loss: 1.8489\n",
      "Epoch 72/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0115\n",
      "Epoch 72: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0116 - val_accuracy: 0.7123 - val_loss: 2.5771\n",
      "Epoch 73/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0368\n",
      "Epoch 73: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0366 - val_accuracy: 0.7353 - val_loss: 1.9191\n",
      "Epoch 74/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0240\n",
      "Epoch 74: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0240 - val_accuracy: 0.6903 - val_loss: 2.1315\n",
      "Epoch 75/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0116\n",
      "Epoch 75: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0116 - val_accuracy: 0.7263 - val_loss: 1.8612\n",
      "Epoch 76/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0216\n",
      "Epoch 76: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0214 - val_accuracy: 0.7383 - val_loss: 1.8154\n",
      "Epoch 77/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0071\n",
      "Epoch 77: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0073 - val_accuracy: 0.6813 - val_loss: 2.2275\n",
      "Epoch 78/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0245\n",
      "Epoch 78: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0248 - val_accuracy: 0.7073 - val_loss: 1.8539\n",
      "Epoch 79/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0247\n",
      "Epoch 79: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0247 - val_accuracy: 0.7233 - val_loss: 2.0401\n",
      "Epoch 80/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0162\n",
      "Epoch 80: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0163 - val_accuracy: 0.6813 - val_loss: 2.3840\n",
      "Epoch 81/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0178\n",
      "Epoch 81: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0177 - val_accuracy: 0.7393 - val_loss: 1.9500\n",
      "Epoch 82/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0030\n",
      "Epoch 82: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0030 - val_accuracy: 0.7323 - val_loss: 1.9669\n",
      "Epoch 83/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0214\n",
      "Epoch 83: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0217 - val_accuracy: 0.7283 - val_loss: 2.0948\n",
      "Epoch 84/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0449\n",
      "Epoch 84: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0450 - val_accuracy: 0.7063 - val_loss: 1.8887\n",
      "Epoch 85/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9954 - loss: 0.0162\n",
      "Epoch 85: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0162 - val_accuracy: 0.7223 - val_loss: 1.7884\n",
      "Epoch 86/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0069\n",
      "Epoch 86: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0068 - val_accuracy: 0.7443 - val_loss: 1.8638\n",
      "Epoch 87/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0030\n",
      "Epoch 87: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.7253 - val_loss: 1.8588\n",
      "Epoch 88/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9952 - loss: 0.0151\n",
      "Epoch 88: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0152 - val_accuracy: 0.7093 - val_loss: 1.8118\n",
      "Epoch 89/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0435\n",
      "Epoch 89: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0433 - val_accuracy: 0.7243 - val_loss: 2.2500\n",
      "Epoch 90/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0118\n",
      "Epoch 90: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0117 - val_accuracy: 0.7373 - val_loss: 1.7707\n",
      "Epoch 91/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0026\n",
      "Epoch 91: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.7293 - val_loss: 1.8789\n",
      "Epoch 92/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0085\n",
      "Epoch 92: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0086 - val_accuracy: 0.7393 - val_loss: 1.9631\n",
      "Epoch 93/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9895 - loss: 0.0281\n",
      "Epoch 93: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0282 - val_accuracy: 0.7253 - val_loss: 2.0181\n",
      "Epoch 94/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9888 - loss: 0.0284\n",
      "Epoch 94: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0284 - val_accuracy: 0.7443 - val_loss: 1.9064\n",
      "Epoch 95/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0126\n",
      "Epoch 95: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0125 - val_accuracy: 0.7463 - val_loss: 1.8575\n",
      "Epoch 96/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0064\n",
      "Epoch 96: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.7253 - val_loss: 1.9740\n",
      "Epoch 97/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0074\n",
      "Epoch 97: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0074 - val_accuracy: 0.7213 - val_loss: 2.0002\n",
      "Epoch 98/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0069\n",
      "Epoch 98: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.7233 - val_loss: 2.0303\n",
      "Epoch 99/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0357\n",
      "Epoch 99: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0359 - val_accuracy: 0.7133 - val_loss: 2.0226\n",
      "Epoch 100/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0186\n",
      "Epoch 100: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0186 - val_accuracy: 0.7532 - val_loss: 1.9282\n",
      "Epoch 101/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0069\n",
      "Epoch 101: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0069 - val_accuracy: 0.7383 - val_loss: 1.9276\n",
      "Epoch 102/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0137\n",
      "Epoch 102: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0138 - val_accuracy: 0.7413 - val_loss: 2.4762\n",
      "Epoch 103/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0221\n",
      "Epoch 103: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0219 - val_accuracy: 0.7213 - val_loss: 1.9153\n",
      "Epoch 104/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0055\n",
      "Epoch 104: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 0.7193 - val_loss: 2.0894\n",
      "Epoch 105/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0152\n",
      "Epoch 105: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0152 - val_accuracy: 0.7403 - val_loss: 2.2070\n",
      "Epoch 106/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0221\n",
      "Epoch 106: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0221 - val_accuracy: 0.7413 - val_loss: 1.8558\n",
      "Epoch 107/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0060\n",
      "Epoch 107: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0060 - val_accuracy: 0.7473 - val_loss: 1.9658\n",
      "Epoch 108/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0090\n",
      "Epoch 108: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0091 - val_accuracy: 0.7133 - val_loss: 2.0360\n",
      "Epoch 109/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0334\n",
      "Epoch 109: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0333 - val_accuracy: 0.7163 - val_loss: 2.2127\n",
      "Epoch 110/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0064\n",
      "Epoch 110: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0064 - val_accuracy: 0.7512 - val_loss: 1.9989\n",
      "Epoch 111/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0050\n",
      "Epoch 111: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0050 - val_accuracy: 0.7423 - val_loss: 2.1115\n",
      "Epoch 112/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9958 - loss: 0.0121\n",
      "Epoch 112: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0122 - val_accuracy: 0.7273 - val_loss: 2.2677\n",
      "Epoch 113/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0229\n",
      "Epoch 113: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0229 - val_accuracy: 0.7353 - val_loss: 1.9224\n",
      "Epoch 114/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0248\n",
      "Epoch 114: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0249 - val_accuracy: 0.7303 - val_loss: 2.0226\n",
      "Epoch 115/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0082\n",
      "Epoch 115: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0082 - val_accuracy: 0.7193 - val_loss: 2.3980\n",
      "Epoch 116/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0042\n",
      "Epoch 116: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.7443 - val_loss: 1.9563\n",
      "Epoch 117/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0028\n",
      "Epoch 117: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.7323 - val_loss: 1.9710\n",
      "Epoch 118/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0055\n",
      "Epoch 118: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.7433 - val_loss: 2.0053\n",
      "Epoch 119/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0175\n",
      "Epoch 119: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0178 - val_accuracy: 0.6863 - val_loss: 2.2962\n",
      "Epoch 120/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0439\n",
      "Epoch 120: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0436 - val_accuracy: 0.6933 - val_loss: 2.3916\n",
      "Epoch 121/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0323\n",
      "Epoch 121: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9898 - loss: 0.0321 - val_accuracy: 0.7473 - val_loss: 1.9716\n",
      "Epoch 122/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0077\n",
      "Epoch 122: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.7233 - val_loss: 2.0388\n",
      "Epoch 123/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0044\n",
      "Epoch 123: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.7253 - val_loss: 2.0439\n",
      "Epoch 124/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0030\n",
      "Epoch 124: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.7463 - val_loss: 2.0103\n",
      "Epoch 125/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.9825e-04\n",
      "Epoch 125: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.9705e-04 - val_accuracy: 0.7383 - val_loss: 2.0623\n",
      "Epoch 126/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0011\n",
      "Epoch 126: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0011 - val_accuracy: 0.7443 - val_loss: 2.1230\n",
      "Epoch 127/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0048\n",
      "Epoch 127: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.7473 - val_loss: 2.1465\n",
      "Epoch 128/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0468\n",
      "Epoch 128: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0470 - val_accuracy: 0.7253 - val_loss: 1.9777\n",
      "Epoch 129/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0134\n",
      "Epoch 129: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0134 - val_accuracy: 0.7303 - val_loss: 2.1691\n",
      "Epoch 130/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0075\n",
      "Epoch 130: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0075 - val_accuracy: 0.7233 - val_loss: 2.1271\n",
      "Epoch 131/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0080\n",
      "Epoch 131: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.7203 - val_loss: 2.1027\n",
      "Epoch 132/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0070\n",
      "Epoch 132: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.7133 - val_loss: 2.0513\n",
      "Epoch 133/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0162\n",
      "Epoch 133: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0162 - val_accuracy: 0.7393 - val_loss: 2.0760\n",
      "Epoch 134/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0076\n",
      "Epoch 134: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0076 - val_accuracy: 0.7363 - val_loss: 1.9931\n",
      "Epoch 135/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0204\n",
      "Epoch 135: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0205 - val_accuracy: 0.6344 - val_loss: 2.7683\n",
      "Epoch 136/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0228\n",
      "Epoch 136: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0228 - val_accuracy: 0.7602 - val_loss: 2.0494\n",
      "Epoch 137/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0072\n",
      "Epoch 137: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.7532 - val_loss: 1.8467\n",
      "Epoch 138/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0014\n",
      "Epoch 138: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0014 - val_accuracy: 0.7542 - val_loss: 1.9327\n",
      "Epoch 139/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.3663e-04\n",
      "Epoch 139: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.3915e-04 - val_accuracy: 0.7393 - val_loss: 2.0220\n",
      "Epoch 140/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 8.7881e-04\n",
      "Epoch 140: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 8.8091e-04 - val_accuracy: 0.7023 - val_loss: 2.2728\n",
      "Epoch 141/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0251\n",
      "Epoch 141: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0253 - val_accuracy: 0.7093 - val_loss: 2.5838\n",
      "Epoch 142/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0299\n",
      "Epoch 142: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0297 - val_accuracy: 0.7373 - val_loss: 2.2290\n",
      "Epoch 143/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0114\n",
      "Epoch 143: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0114 - val_accuracy: 0.7483 - val_loss: 1.9782\n",
      "Epoch 144/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0031\n",
      "Epoch 144: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.7483 - val_loss: 2.1210\n",
      "Epoch 145/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0080\n",
      "Epoch 145: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0080 - val_accuracy: 0.7183 - val_loss: 2.2175\n",
      "Epoch 146/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0025\n",
      "Epoch 146: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.7363 - val_loss: 2.1354\n",
      "Epoch 147/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0030\n",
      "Epoch 147: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.7393 - val_loss: 2.0896\n",
      "Epoch 148/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0232\n",
      "Epoch 148: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0232 - val_accuracy: 0.7483 - val_loss: 2.2005\n",
      "Epoch 149/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0273\n",
      "Epoch 149: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0273 - val_accuracy: 0.7203 - val_loss: 2.4704\n",
      "Epoch 150/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0220\n",
      "Epoch 150: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0220 - val_accuracy: 0.7433 - val_loss: 2.3012\n",
      "Epoch 151/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0096\n",
      "Epoch 151: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0096 - val_accuracy: 0.7353 - val_loss: 1.9752\n",
      "Epoch 152/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0026\n",
      "Epoch 152: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.7323 - val_loss: 2.0474\n",
      "Epoch 153/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.6451e-04\n",
      "Epoch 153: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.7247e-04 - val_accuracy: 0.7303 - val_loss: 2.6355\n",
      "Epoch 154/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0095\n",
      "Epoch 154: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0096 - val_accuracy: 0.7313 - val_loss: 2.0570\n",
      "Epoch 155/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9963 - loss: 0.0120\n",
      "Epoch 155: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0121 - val_accuracy: 0.7353 - val_loss: 1.9982\n",
      "Epoch 156/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0148\n",
      "Epoch 156: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0148 - val_accuracy: 0.7253 - val_loss: 2.0571\n",
      "Epoch 157/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0076\n",
      "Epoch 157: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.7173 - val_loss: 2.4671\n",
      "Epoch 158/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0047\n",
      "Epoch 158: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.7073 - val_loss: 2.2537\n",
      "Epoch 159/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 159: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7493 - val_loss: 2.0937\n",
      "Epoch 160/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0043\n",
      "Epoch 160: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.7233 - val_loss: 2.3035\n",
      "Epoch 161/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0232\n",
      "Epoch 161: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0232 - val_accuracy: 0.7453 - val_loss: 2.1430\n",
      "Epoch 162/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0172\n",
      "Epoch 162: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0172 - val_accuracy: 0.7413 - val_loss: 2.2832\n",
      "Epoch 163/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0098\n",
      "Epoch 163: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0098 - val_accuracy: 0.7033 - val_loss: 2.2904\n",
      "Epoch 164/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0097\n",
      "Epoch 164: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0097 - val_accuracy: 0.6953 - val_loss: 2.4784\n",
      "Epoch 165/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0062\n",
      "Epoch 165: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0062 - val_accuracy: 0.7343 - val_loss: 2.1100\n",
      "Epoch 166/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0115\n",
      "Epoch 166: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.6933 - val_loss: 2.6206\n",
      "Epoch 167/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0252\n",
      "Epoch 167: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0252 - val_accuracy: 0.7123 - val_loss: 2.4949\n",
      "Epoch 168/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0100\n",
      "Epoch 168: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0100 - val_accuracy: 0.7083 - val_loss: 2.2816\n",
      "Epoch 169/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0036\n",
      "Epoch 169: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.7502 - val_loss: 2.2895\n",
      "Epoch 170/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0110\n",
      "Epoch 170: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0109 - val_accuracy: 0.7562 - val_loss: 2.2160\n",
      "Epoch 171/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0030\n",
      "Epoch 171: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0030 - val_accuracy: 0.7622 - val_loss: 2.0701\n",
      "Epoch 172/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0013\n",
      "Epoch 172: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.7532 - val_loss: 2.1020\n",
      "Epoch 173/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0020\n",
      "Epoch 173: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.6813 - val_loss: 2.6842\n",
      "Epoch 174/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0225\n",
      "Epoch 174: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0229 - val_accuracy: 0.6813 - val_loss: 2.3792\n",
      "Epoch 175/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0285\n",
      "Epoch 175: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0283 - val_accuracy: 0.7223 - val_loss: 2.2275\n",
      "Epoch 176/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0036\n",
      "Epoch 176: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.7413 - val_loss: 2.0406\n",
      "Epoch 177/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0061\n",
      "Epoch 177: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.7403 - val_loss: 2.1884\n",
      "Epoch 178/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.6486e-04\n",
      "Epoch 178: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.6098e-04 - val_accuracy: 0.7443 - val_loss: 2.1944\n",
      "Epoch 179/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.3508e-04\n",
      "Epoch 179: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.3535e-04 - val_accuracy: 0.7473 - val_loss: 2.2127\n",
      "Epoch 180/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.5784e-04\n",
      "Epoch 180: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.7578e-04 - val_accuracy: 0.7433 - val_loss: 2.2580\n",
      "Epoch 181/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0214\n",
      "Epoch 181: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0215 - val_accuracy: 0.7143 - val_loss: 2.1822\n",
      "Epoch 182/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0196\n",
      "Epoch 182: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0195 - val_accuracy: 0.7313 - val_loss: 2.3796\n",
      "Epoch 183/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0081\n",
      "Epoch 183: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0080 - val_accuracy: 0.7153 - val_loss: 2.1685\n",
      "Epoch 184/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9990 - loss: 0.0040\n",
      "Epoch 184: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.7383 - val_loss: 2.1388\n",
      "Epoch 185/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0034\n",
      "Epoch 185: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0034 - val_accuracy: 0.7183 - val_loss: 2.2802\n",
      "Epoch 186/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0031\n",
      "Epoch 186: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0031 - val_accuracy: 0.7443 - val_loss: 2.1299\n",
      "Epoch 187/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0023\n",
      "Epoch 187: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 0.7153 - val_loss: 2.2434\n",
      "Epoch 188/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0169\n",
      "Epoch 188: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0169 - val_accuracy: 0.7233 - val_loss: 2.1391\n",
      "Epoch 189/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0118\n",
      "Epoch 189: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0118 - val_accuracy: 0.7273 - val_loss: 2.1280\n",
      "Epoch 190/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0125\n",
      "Epoch 190: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.7283 - val_loss: 2.2521\n",
      "Epoch 191/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.0277\n",
      "Epoch 191: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0277 - val_accuracy: 0.7353 - val_loss: 2.1320\n",
      "Epoch 192/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0034\n",
      "Epoch 192: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.7393 - val_loss: 2.1514\n",
      "Epoch 193/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0034\n",
      "Epoch 193: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.7453 - val_loss: 2.3388\n",
      "Epoch 194/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0031\n",
      "Epoch 194: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.7443 - val_loss: 2.1914\n",
      "Epoch 195/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 8.8769e-04\n",
      "Epoch 195: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 8.9329e-04 - val_accuracy: 0.7542 - val_loss: 2.1649\n",
      "Epoch 196/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.5833e-04\n",
      "Epoch 196: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 8.5623e-04 - val_accuracy: 0.7423 - val_loss: 2.1661\n",
      "Epoch 197/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.9097e-04\n",
      "Epoch 197: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.9101e-04 - val_accuracy: 0.7473 - val_loss: 2.1551\n",
      "Epoch 198/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9897 - loss: 0.0341\n",
      "Epoch 198: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0342 - val_accuracy: 0.6983 - val_loss: 2.2836\n",
      "Epoch 199/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9942 - loss: 0.0192\n",
      "Epoch 199: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0191 - val_accuracy: 0.7403 - val_loss: 2.1220\n",
      "Epoch 200/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0025\n",
      "Epoch 200: val_loss did not improve from 0.72126\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.7433 - val_loss: 2.0916\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6115 - loss: 3.4922\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "model5 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6359 - loss: 1.0768\n",
      "Epoch 1: val_loss improved from inf to 1.74553, saving model to model_6/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6361 - loss: 1.0763 - val_accuracy: 0.2188 - val_loss: 1.7455\n",
      "Epoch 2/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7221 - loss: 0.7835\n",
      "Epoch 2: val_loss improved from 1.74553 to 0.91598, saving model to model_6/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7221 - loss: 0.7834 - val_accuracy: 0.6713 - val_loss: 0.9160\n",
      "Epoch 3/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7343 - loss: 0.7313\n",
      "Epoch 3: val_loss improved from 0.91598 to 0.83207, saving model to model_6/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7345 - loss: 0.7311 - val_accuracy: 0.7073 - val_loss: 0.8321\n",
      "Epoch 4/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7575 - loss: 0.6891\n",
      "Epoch 4: val_loss did not improve from 0.83207\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7575 - loss: 0.6891 - val_accuracy: 0.6923 - val_loss: 0.8355\n",
      "Epoch 5/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7778 - loss: 0.6247\n",
      "Epoch 5: val_loss improved from 0.83207 to 0.80222, saving model to model_6/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7777 - loss: 0.6247 - val_accuracy: 0.7003 - val_loss: 0.8022\n",
      "Epoch 6/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7832 - loss: 0.5907\n",
      "Epoch 6: val_loss did not improve from 0.80222\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7831 - loss: 0.5907 - val_accuracy: 0.6993 - val_loss: 0.9233\n",
      "Epoch 7/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8070 - loss: 0.5390\n",
      "Epoch 7: val_loss improved from 0.80222 to 0.76829, saving model to model_6/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8070 - loss: 0.5391 - val_accuracy: 0.7163 - val_loss: 0.7683\n",
      "Epoch 8/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8172 - loss: 0.4959\n",
      "Epoch 8: val_loss improved from 0.76829 to 0.69945, saving model to model_6/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8171 - loss: 0.4962 - val_accuracy: 0.7443 - val_loss: 0.6994\n",
      "Epoch 9/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8289 - loss: 0.4751\n",
      "Epoch 9: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8289 - loss: 0.4751 - val_accuracy: 0.7153 - val_loss: 0.7448\n",
      "Epoch 10/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 0.4376\n",
      "Epoch 10: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 0.4378 - val_accuracy: 0.7253 - val_loss: 0.8604\n",
      "Epoch 11/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8541 - loss: 0.4154\n",
      "Epoch 11: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8541 - loss: 0.4154 - val_accuracy: 0.7183 - val_loss: 0.9225\n",
      "Epoch 12/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8659 - loss: 0.3787\n",
      "Epoch 12: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8659 - loss: 0.3788 - val_accuracy: 0.7363 - val_loss: 0.7613\n",
      "Epoch 13/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8858 - loss: 0.3431\n",
      "Epoch 13: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8857 - loss: 0.3431 - val_accuracy: 0.7073 - val_loss: 0.8418\n",
      "Epoch 14/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.3159\n",
      "Epoch 14: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8920 - loss: 0.3160 - val_accuracy: 0.7163 - val_loss: 0.8337\n",
      "Epoch 15/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8989 - loss: 0.2970\n",
      "Epoch 15: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8989 - loss: 0.2971 - val_accuracy: 0.7393 - val_loss: 0.7879\n",
      "Epoch 16/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9122 - loss: 0.2598\n",
      "Epoch 16: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9122 - loss: 0.2598 - val_accuracy: 0.6833 - val_loss: 0.9629\n",
      "Epoch 17/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9180 - loss: 0.2378\n",
      "Epoch 17: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2379 - val_accuracy: 0.7323 - val_loss: 0.9003\n",
      "Epoch 18/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9389 - loss: 0.2018\n",
      "Epoch 18: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9386 - loss: 0.2022 - val_accuracy: 0.7003 - val_loss: 0.9737\n",
      "Epoch 19/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9389 - loss: 0.1947\n",
      "Epoch 19: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9388 - loss: 0.1948 - val_accuracy: 0.7373 - val_loss: 0.8994\n",
      "Epoch 20/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9519 - loss: 0.1619\n",
      "Epoch 20: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9517 - loss: 0.1622 - val_accuracy: 0.7283 - val_loss: 0.9752\n",
      "Epoch 21/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.1685\n",
      "Epoch 21: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9440 - loss: 0.1686 - val_accuracy: 0.7313 - val_loss: 0.9798\n",
      "Epoch 22/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9615 - loss: 0.1278\n",
      "Epoch 22: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9615 - loss: 0.1278 - val_accuracy: 0.7223 - val_loss: 1.4616\n",
      "Epoch 23/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9552 - loss: 0.1353\n",
      "Epoch 23: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.1353 - val_accuracy: 0.7213 - val_loss: 1.3072\n",
      "Epoch 24/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9667 - loss: 0.1109\n",
      "Epoch 24: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9665 - loss: 0.1112 - val_accuracy: 0.7263 - val_loss: 1.0967\n",
      "Epoch 25/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9676 - loss: 0.1069\n",
      "Epoch 25: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9676 - loss: 0.1069 - val_accuracy: 0.7353 - val_loss: 1.0874\n",
      "Epoch 26/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9716 - loss: 0.0928\n",
      "Epoch 26: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9716 - loss: 0.0928 - val_accuracy: 0.7423 - val_loss: 1.2591\n",
      "Epoch 27/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0795\n",
      "Epoch 27: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9795 - loss: 0.0796 - val_accuracy: 0.7373 - val_loss: 1.3149\n",
      "Epoch 28/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0675\n",
      "Epoch 28: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0676 - val_accuracy: 0.7373 - val_loss: 1.2567\n",
      "Epoch 29/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.0860\n",
      "Epoch 29: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9726 - loss: 0.0861 - val_accuracy: 0.7183 - val_loss: 1.4180\n",
      "Epoch 30/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0661\n",
      "Epoch 30: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9799 - loss: 0.0663 - val_accuracy: 0.7293 - val_loss: 1.3210\n",
      "Epoch 31/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0600\n",
      "Epoch 31: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9814 - loss: 0.0600 - val_accuracy: 0.7183 - val_loss: 1.4345\n",
      "Epoch 32/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.0643\n",
      "Epoch 32: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0647 - val_accuracy: 0.7293 - val_loss: 1.2438\n",
      "Epoch 33/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9881 - loss: 0.0458\n",
      "Epoch 33: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0457 - val_accuracy: 0.7093 - val_loss: 1.3730\n",
      "Epoch 34/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0505\n",
      "Epoch 34: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0508 - val_accuracy: 0.7343 - val_loss: 1.3422\n",
      "Epoch 35/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0495\n",
      "Epoch 35: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9848 - loss: 0.0495 - val_accuracy: 0.7203 - val_loss: 1.5910\n",
      "Epoch 36/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9874 - loss: 0.0408\n",
      "Epoch 36: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0408 - val_accuracy: 0.7323 - val_loss: 1.4527\n",
      "Epoch 37/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9876 - loss: 0.0408\n",
      "Epoch 37: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 0.0408 - val_accuracy: 0.7223 - val_loss: 1.5222\n",
      "Epoch 38/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0344\n",
      "Epoch 38: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0345 - val_accuracy: 0.7363 - val_loss: 1.7921\n",
      "Epoch 39/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9774 - loss: 0.0664\n",
      "Epoch 39: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.0662 - val_accuracy: 0.7313 - val_loss: 1.4727\n",
      "Epoch 40/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9848 - loss: 0.0470\n",
      "Epoch 40: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9848 - loss: 0.0469 - val_accuracy: 0.7093 - val_loss: 2.1746\n",
      "Epoch 41/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0310\n",
      "Epoch 41: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0312 - val_accuracy: 0.7133 - val_loss: 1.5086\n",
      "Epoch 42/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9864 - loss: 0.0398\n",
      "Epoch 42: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0397 - val_accuracy: 0.7323 - val_loss: 1.5081\n",
      "Epoch 43/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0283\n",
      "Epoch 43: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0283 - val_accuracy: 0.7343 - val_loss: 1.5805\n",
      "Epoch 44/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.0343\n",
      "Epoch 44: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0345 - val_accuracy: 0.7273 - val_loss: 1.6148\n",
      "Epoch 45/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0313\n",
      "Epoch 45: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0314 - val_accuracy: 0.7273 - val_loss: 1.6459\n",
      "Epoch 46/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0408\n",
      "Epoch 46: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0408 - val_accuracy: 0.7083 - val_loss: 1.6155\n",
      "Epoch 47/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0301\n",
      "Epoch 47: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9898 - loss: 0.0301 - val_accuracy: 0.7173 - val_loss: 2.1421\n",
      "Epoch 48/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0270\n",
      "Epoch 48: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0269 - val_accuracy: 0.7473 - val_loss: 1.7333\n",
      "Epoch 49/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0309\n",
      "Epoch 49: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0310 - val_accuracy: 0.7233 - val_loss: 1.7685\n",
      "Epoch 50/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9838 - loss: 0.0475\n",
      "Epoch 50: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0474 - val_accuracy: 0.7373 - val_loss: 1.6774\n",
      "Epoch 51/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9909 - loss: 0.0246\n",
      "Epoch 51: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0246 - val_accuracy: 0.7373 - val_loss: 1.8061\n",
      "Epoch 52/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0164\n",
      "Epoch 52: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0163 - val_accuracy: 0.7363 - val_loss: 1.6538\n",
      "Epoch 53/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0206\n",
      "Epoch 53: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0206 - val_accuracy: 0.7153 - val_loss: 1.6981\n",
      "Epoch 54/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.0323\n",
      "Epoch 54: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0323 - val_accuracy: 0.7393 - val_loss: 1.8721\n",
      "Epoch 55/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9864 - loss: 0.0370\n",
      "Epoch 55: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0370 - val_accuracy: 0.7093 - val_loss: 1.8410\n",
      "Epoch 56/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0395\n",
      "Epoch 56: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0393 - val_accuracy: 0.7283 - val_loss: 1.6718\n",
      "Epoch 57/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0284\n",
      "Epoch 57: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0282 - val_accuracy: 0.7383 - val_loss: 1.8345\n",
      "Epoch 58/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0150\n",
      "Epoch 58: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0151 - val_accuracy: 0.7273 - val_loss: 1.7260\n",
      "Epoch 59/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0100\n",
      "Epoch 59: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0100 - val_accuracy: 0.7223 - val_loss: 2.0730\n",
      "Epoch 60/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0311\n",
      "Epoch 60: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0311 - val_accuracy: 0.7193 - val_loss: 1.8758\n",
      "Epoch 61/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9885 - loss: 0.0351\n",
      "Epoch 61: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9885 - loss: 0.0352 - val_accuracy: 0.7163 - val_loss: 2.1744\n",
      "Epoch 62/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0358\n",
      "Epoch 62: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9865 - loss: 0.0358 - val_accuracy: 0.7113 - val_loss: 1.8290\n",
      "Epoch 63/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0311\n",
      "Epoch 63: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9893 - loss: 0.0310 - val_accuracy: 0.7343 - val_loss: 1.6047\n",
      "Epoch 64/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0069\n",
      "Epoch 64: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0069 - val_accuracy: 0.7592 - val_loss: 1.7680\n",
      "Epoch 65/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0080\n",
      "Epoch 65: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0081 - val_accuracy: 0.7403 - val_loss: 1.8413\n",
      "Epoch 66/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0106\n",
      "Epoch 66: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0107 - val_accuracy: 0.7233 - val_loss: 1.9490\n",
      "Epoch 67/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0304\n",
      "Epoch 67: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0305 - val_accuracy: 0.7183 - val_loss: 2.0265\n",
      "Epoch 68/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9840 - loss: 0.0445\n",
      "Epoch 68: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0446 - val_accuracy: 0.7303 - val_loss: 2.5877\n",
      "Epoch 69/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0445\n",
      "Epoch 69: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0444 - val_accuracy: 0.7173 - val_loss: 1.9181\n",
      "Epoch 70/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0123\n",
      "Epoch 70: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0123 - val_accuracy: 0.7333 - val_loss: 1.8496\n",
      "Epoch 71/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0057\n",
      "Epoch 71: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0057 - val_accuracy: 0.7363 - val_loss: 1.7913\n",
      "Epoch 72/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0065\n",
      "Epoch 72: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 0.7433 - val_loss: 1.9207\n",
      "Epoch 73/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0146\n",
      "Epoch 73: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9954 - loss: 0.0146 - val_accuracy: 0.7313 - val_loss: 1.9333\n",
      "Epoch 74/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0212\n",
      "Epoch 74: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0213 - val_accuracy: 0.6953 - val_loss: 2.0548\n",
      "Epoch 75/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0467\n",
      "Epoch 75: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0465 - val_accuracy: 0.7253 - val_loss: 2.0808\n",
      "Epoch 76/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0179\n",
      "Epoch 76: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0179 - val_accuracy: 0.7233 - val_loss: 1.9587\n",
      "Epoch 77/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0112\n",
      "Epoch 77: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0112 - val_accuracy: 0.7113 - val_loss: 3.0234\n",
      "Epoch 78/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 0.0518\n",
      "Epoch 78: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0516 - val_accuracy: 0.7333 - val_loss: 1.8264\n",
      "Epoch 79/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0221\n",
      "Epoch 79: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0221 - val_accuracy: 0.7273 - val_loss: 2.2955\n",
      "Epoch 80/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9924 - loss: 0.0227\n",
      "Epoch 80: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0227 - val_accuracy: 0.7063 - val_loss: 1.9590\n",
      "Epoch 81/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0148\n",
      "Epoch 81: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0148 - val_accuracy: 0.7463 - val_loss: 1.7713\n",
      "Epoch 82/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0055\n",
      "Epoch 82: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.7193 - val_loss: 2.1018\n",
      "Epoch 83/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0291\n",
      "Epoch 83: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0292 - val_accuracy: 0.7313 - val_loss: 1.9114\n",
      "Epoch 84/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0196\n",
      "Epoch 84: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0196 - val_accuracy: 0.7293 - val_loss: 1.9304\n",
      "Epoch 85/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0185\n",
      "Epoch 85: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0188 - val_accuracy: 0.7323 - val_loss: 2.4806\n",
      "Epoch 86/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9906 - loss: 0.0310\n",
      "Epoch 86: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0309 - val_accuracy: 0.7343 - val_loss: 1.9331\n",
      "Epoch 87/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0114\n",
      "Epoch 87: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0114 - val_accuracy: 0.7313 - val_loss: 2.1417\n",
      "Epoch 88/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0218\n",
      "Epoch 88: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0218 - val_accuracy: 0.7233 - val_loss: 1.9444\n",
      "Epoch 89/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9933 - loss: 0.0191\n",
      "Epoch 89: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0191 - val_accuracy: 0.7253 - val_loss: 1.9517\n",
      "Epoch 90/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0099\n",
      "Epoch 90: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0099 - val_accuracy: 0.7423 - val_loss: 2.0203\n",
      "Epoch 91/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0090\n",
      "Epoch 91: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0090 - val_accuracy: 0.7233 - val_loss: 2.1431\n",
      "Epoch 92/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0235\n",
      "Epoch 92: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0233 - val_accuracy: 0.7403 - val_loss: 2.0091\n",
      "Epoch 93/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0165\n",
      "Epoch 93: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0165 - val_accuracy: 0.7283 - val_loss: 2.2479\n",
      "Epoch 94/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0176\n",
      "Epoch 94: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0175 - val_accuracy: 0.7043 - val_loss: 2.2034\n",
      "Epoch 95/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0098\n",
      "Epoch 95: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0098 - val_accuracy: 0.7173 - val_loss: 2.0351\n",
      "Epoch 96/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0325\n",
      "Epoch 96: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0323 - val_accuracy: 0.7343 - val_loss: 1.9816\n",
      "Epoch 97/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0084\n",
      "Epoch 97: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0084 - val_accuracy: 0.7353 - val_loss: 2.0413\n",
      "Epoch 98/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0081\n",
      "Epoch 98: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0082 - val_accuracy: 0.7283 - val_loss: 2.1151\n",
      "Epoch 99/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0179\n",
      "Epoch 99: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0181 - val_accuracy: 0.7453 - val_loss: 1.9692\n",
      "Epoch 100/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0317\n",
      "Epoch 100: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0316 - val_accuracy: 0.7253 - val_loss: 2.2266\n",
      "Epoch 101/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0079\n",
      "Epoch 101: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0078 - val_accuracy: 0.7303 - val_loss: 2.0563\n",
      "Epoch 102/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0070\n",
      "Epoch 102: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.7443 - val_loss: 1.8619\n",
      "Epoch 103/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9967 - loss: 0.0106\n",
      "Epoch 103: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0107 - val_accuracy: 0.6953 - val_loss: 2.9229\n",
      "Epoch 104/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0429\n",
      "Epoch 104: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0428 - val_accuracy: 0.7373 - val_loss: 1.9610\n",
      "Epoch 105/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0081\n",
      "Epoch 105: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0081 - val_accuracy: 0.7303 - val_loss: 1.8657\n",
      "Epoch 106/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0076\n",
      "Epoch 106: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.7443 - val_loss: 1.8050\n",
      "Epoch 107/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0053\n",
      "Epoch 107: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0054 - val_accuracy: 0.7393 - val_loss: 2.2087\n",
      "Epoch 108/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0322\n",
      "Epoch 108: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0322 - val_accuracy: 0.7093 - val_loss: 1.9917\n",
      "Epoch 109/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0248\n",
      "Epoch 109: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0248 - val_accuracy: 0.7413 - val_loss: 2.4338\n",
      "Epoch 110/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0074\n",
      "Epoch 110: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.7423 - val_loss: 2.1682\n",
      "Epoch 111/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0107\n",
      "Epoch 111: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0107 - val_accuracy: 0.7383 - val_loss: 1.9490\n",
      "Epoch 112/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0053\n",
      "Epoch 112: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0053 - val_accuracy: 0.7363 - val_loss: 2.2708\n",
      "Epoch 113/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0170\n",
      "Epoch 113: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9940 - loss: 0.0169 - val_accuracy: 0.7403 - val_loss: 2.1831\n",
      "Epoch 114/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0127\n",
      "Epoch 114: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0129 - val_accuracy: 0.7323 - val_loss: 1.9623\n",
      "Epoch 115/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0143\n",
      "Epoch 115: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0144 - val_accuracy: 0.7502 - val_loss: 1.9953\n",
      "Epoch 116/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0077\n",
      "Epoch 116: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0077 - val_accuracy: 0.7113 - val_loss: 2.0556\n",
      "Epoch 117/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0236\n",
      "Epoch 117: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0236 - val_accuracy: 0.7383 - val_loss: 2.4159\n",
      "Epoch 118/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0117\n",
      "Epoch 118: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0116 - val_accuracy: 0.7423 - val_loss: 1.9651\n",
      "Epoch 119/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0028\n",
      "Epoch 119: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.7453 - val_loss: 2.1840\n",
      "Epoch 120/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0069\n",
      "Epoch 120: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0069 - val_accuracy: 0.7363 - val_loss: 2.5666\n",
      "Epoch 121/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9903 - loss: 0.0298\n",
      "Epoch 121: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0300 - val_accuracy: 0.7043 - val_loss: 2.0295\n",
      "Epoch 122/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9910 - loss: 0.0268\n",
      "Epoch 122: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0267 - val_accuracy: 0.7123 - val_loss: 2.0801\n",
      "Epoch 123/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0061\n",
      "Epoch 123: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.7293 - val_loss: 2.0037\n",
      "Epoch 124/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0051\n",
      "Epoch 124: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0052 - val_accuracy: 0.7413 - val_loss: 2.0689\n",
      "Epoch 125/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0042\n",
      "Epoch 125: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.7293 - val_loss: 2.2950\n",
      "Epoch 126/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0250\n",
      "Epoch 126: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9914 - loss: 0.0250 - val_accuracy: 0.7093 - val_loss: 2.3316\n",
      "Epoch 127/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0127\n",
      "Epoch 127: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0126 - val_accuracy: 0.7393 - val_loss: 2.1404\n",
      "Epoch 128/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0085\n",
      "Epoch 128: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0084 - val_accuracy: 0.7393 - val_loss: 1.9956\n",
      "Epoch 129/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0100\n",
      "Epoch 129: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.7223 - val_loss: 2.5572\n",
      "Epoch 130/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0222\n",
      "Epoch 130: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0222 - val_accuracy: 0.7143 - val_loss: 2.0745\n",
      "Epoch 131/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0212\n",
      "Epoch 131: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0213 - val_accuracy: 0.6993 - val_loss: 2.1699\n",
      "Epoch 132/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9935 - loss: 0.0217\n",
      "Epoch 132: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0216 - val_accuracy: 0.7143 - val_loss: 2.2566\n",
      "Epoch 133/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0032\n",
      "Epoch 133: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.7353 - val_loss: 1.9344\n",
      "Epoch 134/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 134: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.7493 - val_loss: 2.2554\n",
      "Epoch 135/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0063\n",
      "Epoch 135: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0064 - val_accuracy: 0.7353 - val_loss: 2.3112\n",
      "Epoch 136/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0198\n",
      "Epoch 136: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0198 - val_accuracy: 0.7293 - val_loss: 2.1767\n",
      "Epoch 137/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0222\n",
      "Epoch 137: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9928 - loss: 0.0222 - val_accuracy: 0.7293 - val_loss: 1.9863\n",
      "Epoch 138/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0241\n",
      "Epoch 138: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0239 - val_accuracy: 0.7193 - val_loss: 2.3006\n",
      "Epoch 139/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0032\n",
      "Epoch 139: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0033 - val_accuracy: 0.7283 - val_loss: 2.1924\n",
      "Epoch 140/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0052\n",
      "Epoch 140: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 0.7453 - val_loss: 2.2049\n",
      "Epoch 141/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0030\n",
      "Epoch 141: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.7393 - val_loss: 2.0845\n",
      "Epoch 142/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011\n",
      "Epoch 142: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7453 - val_loss: 2.1765\n",
      "Epoch 143/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 6.9241e-04\n",
      "Epoch 143: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 7.0003e-04 - val_accuracy: 0.7383 - val_loss: 2.1033\n",
      "Epoch 144/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 144: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.6683 - val_loss: 3.1731\n",
      "Epoch 145/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9708 - loss: 0.0865\n",
      "Epoch 145: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9709 - loss: 0.0863 - val_accuracy: 0.7133 - val_loss: 2.2037\n",
      "Epoch 146/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0188\n",
      "Epoch 146: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0187 - val_accuracy: 0.7413 - val_loss: 2.2030\n",
      "Epoch 147/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0085\n",
      "Epoch 147: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0084 - val_accuracy: 0.7433 - val_loss: 2.2663\n",
      "Epoch 148/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0018\n",
      "Epoch 148: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0018 - val_accuracy: 0.7333 - val_loss: 2.2513\n",
      "Epoch 149/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0043\n",
      "Epoch 149: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.7023 - val_loss: 2.3990\n",
      "Epoch 150/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0168\n",
      "Epoch 150: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0168 - val_accuracy: 0.7303 - val_loss: 2.2658\n",
      "Epoch 151/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0074\n",
      "Epoch 151: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0074 - val_accuracy: 0.7343 - val_loss: 2.1711\n",
      "Epoch 152/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9975 - loss: 0.0067\n",
      "Epoch 152: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0067 - val_accuracy: 0.7433 - val_loss: 2.2553\n",
      "Epoch 153/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0073\n",
      "Epoch 153: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0073 - val_accuracy: 0.7373 - val_loss: 2.6681\n",
      "Epoch 154/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0090\n",
      "Epoch 154: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0093 - val_accuracy: 0.7033 - val_loss: 2.9369\n",
      "Epoch 155/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0282\n",
      "Epoch 155: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0281 - val_accuracy: 0.7313 - val_loss: 2.1983\n",
      "Epoch 156/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0111\n",
      "Epoch 156: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.7243 - val_loss: 2.1363\n",
      "Epoch 157/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0088\n",
      "Epoch 157: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0087 - val_accuracy: 0.7512 - val_loss: 2.0976\n",
      "Epoch 158/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 158: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.7233 - val_loss: 2.1516\n",
      "Epoch 159/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0194\n",
      "Epoch 159: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9933 - loss: 0.0195 - val_accuracy: 0.7233 - val_loss: 2.4420\n",
      "Epoch 160/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0283\n",
      "Epoch 160: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0281 - val_accuracy: 0.7193 - val_loss: 2.1718\n",
      "Epoch 161/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9976 - loss: 0.0082\n",
      "Epoch 161: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0081 - val_accuracy: 0.7473 - val_loss: 2.2780\n",
      "Epoch 162/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0117\n",
      "Epoch 162: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.7532 - val_loss: 2.2380\n",
      "Epoch 163/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0079\n",
      "Epoch 163: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.7333 - val_loss: 2.1618\n",
      "Epoch 164/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 164: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7453 - val_loss: 2.1744\n",
      "Epoch 165/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0029\n",
      "Epoch 165: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.7073 - val_loss: 2.3170\n",
      "Epoch 166/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0403\n",
      "Epoch 166: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0404 - val_accuracy: 0.7373 - val_loss: 2.1728\n",
      "Epoch 167/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0175\n",
      "Epoch 167: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0175 - val_accuracy: 0.7502 - val_loss: 2.0614\n",
      "Epoch 168/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0091\n",
      "Epoch 168: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0090 - val_accuracy: 0.7453 - val_loss: 2.2311\n",
      "Epoch 169/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0068\n",
      "Epoch 169: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0068 - val_accuracy: 0.7263 - val_loss: 2.2397\n",
      "Epoch 170/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9972 - loss: 0.0092\n",
      "Epoch 170: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0090 - val_accuracy: 0.7393 - val_loss: 2.0781\n",
      "Epoch 171/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0041\n",
      "Epoch 171: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.7393 - val_loss: 2.0270\n",
      "Epoch 172/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0030\n",
      "Epoch 172: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.7483 - val_loss: 2.2926\n",
      "Epoch 173/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0120\n",
      "Epoch 173: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0122 - val_accuracy: 0.7253 - val_loss: 2.5247\n",
      "Epoch 174/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9920 - loss: 0.0215\n",
      "Epoch 174: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0214 - val_accuracy: 0.7373 - val_loss: 2.2738\n",
      "Epoch 175/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0054\n",
      "Epoch 175: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.7343 - val_loss: 2.1979\n",
      "Epoch 176/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0025\n",
      "Epoch 176: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.7413 - val_loss: 2.2828\n",
      "Epoch 177/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0090\n",
      "Epoch 177: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0094 - val_accuracy: 0.7013 - val_loss: 2.4478\n",
      "Epoch 178/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9885 - loss: 0.0276\n",
      "Epoch 178: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0274 - val_accuracy: 0.7273 - val_loss: 2.1589\n",
      "Epoch 179/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9977 - loss: 0.0086\n",
      "Epoch 179: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0086 - val_accuracy: 0.7463 - val_loss: 2.0528\n",
      "Epoch 180/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0040\n",
      "Epoch 180: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.7463 - val_loss: 2.1173\n",
      "Epoch 181/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0024\n",
      "Epoch 181: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0024 - val_accuracy: 0.7493 - val_loss: 2.0496\n",
      "Epoch 182/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 8.6157e-04\n",
      "Epoch 182: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 8.6954e-04 - val_accuracy: 0.7453 - val_loss: 2.1921\n",
      "Epoch 183/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 0.0013\n",
      "Epoch 183: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.7373 - val_loss: 2.4111\n",
      "Epoch 184/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0039\n",
      "Epoch 184: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.6783 - val_loss: 2.6698\n",
      "Epoch 185/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9894 - loss: 0.0347\n",
      "Epoch 185: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0345 - val_accuracy: 0.7343 - val_loss: 1.9294\n",
      "Epoch 186/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0101\n",
      "Epoch 186: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.7333 - val_loss: 1.9353\n",
      "Epoch 187/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0090\n",
      "Epoch 187: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0090 - val_accuracy: 0.7363 - val_loss: 1.9445\n",
      "Epoch 188/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0113\n",
      "Epoch 188: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0113 - val_accuracy: 0.7273 - val_loss: 2.3039\n",
      "Epoch 189/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0221\n",
      "Epoch 189: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9934 - loss: 0.0218 - val_accuracy: 0.7353 - val_loss: 1.9764\n",
      "Epoch 190/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0030\n",
      "Epoch 190: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0030 - val_accuracy: 0.7502 - val_loss: 2.0700\n",
      "Epoch 191/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0012\n",
      "Epoch 191: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.7393 - val_loss: 2.4389\n",
      "Epoch 192/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 192: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.7403 - val_loss: 2.0741\n",
      "Epoch 193/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.2445e-04\n",
      "Epoch 193: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.2529e-04 - val_accuracy: 0.7453 - val_loss: 2.1101\n",
      "Epoch 194/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0019\n",
      "Epoch 194: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.7113 - val_loss: 3.3031\n",
      "Epoch 195/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0486\n",
      "Epoch 195: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0484 - val_accuracy: 0.7023 - val_loss: 2.2122\n",
      "Epoch 196/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0277\n",
      "Epoch 196: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0276 - val_accuracy: 0.7413 - val_loss: 2.1888\n",
      "Epoch 197/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0089\n",
      "Epoch 197: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0089 - val_accuracy: 0.7393 - val_loss: 1.9850\n",
      "Epoch 198/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0023\n",
      "Epoch 198: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.7433 - val_loss: 2.0154\n",
      "Epoch 199/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0035\n",
      "Epoch 199: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0035 - val_accuracy: 0.7453 - val_loss: 2.0728\n",
      "Epoch 200/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0012\n",
      "Epoch 200: val_loss did not improve from 0.69945\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.7463 - val_loss: 2.1092\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5977 - loss: 3.5883\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "model6 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6154 - loss: 1.1684\n",
      "Epoch 1: val_loss improved from inf to 1.35072, saving model to model_7/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6167 - loss: 1.1634 - val_accuracy: 0.6703 - val_loss: 1.3507\n",
      "Epoch 2/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7157 - loss: 0.7684\n",
      "Epoch 2: val_loss improved from 1.35072 to 0.85571, saving model to model_7/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7156 - loss: 0.7685 - val_accuracy: 0.7093 - val_loss: 0.8557\n",
      "Epoch 3/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7261 - loss: 0.7368\n",
      "Epoch 3: val_loss improved from 0.85571 to 0.74087, saving model to model_7/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7262 - loss: 0.7367 - val_accuracy: 0.7443 - val_loss: 0.7409\n",
      "Epoch 4/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7575 - loss: 0.6706\n",
      "Epoch 4: val_loss did not improve from 0.74087\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7575 - loss: 0.6705 - val_accuracy: 0.7033 - val_loss: 0.8772\n",
      "Epoch 5/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.6255\n",
      "Epoch 5: val_loss did not improve from 0.74087\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.6252 - val_accuracy: 0.7253 - val_loss: 0.7452\n",
      "Epoch 6/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7860 - loss: 0.5815\n",
      "Epoch 6: val_loss did not improve from 0.74087\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7860 - loss: 0.5814 - val_accuracy: 0.7483 - val_loss: 0.7813\n",
      "Epoch 7/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8074 - loss: 0.5392\n",
      "Epoch 7: val_loss improved from 0.74087 to 0.69091, saving model to model_7/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8074 - loss: 0.5392 - val_accuracy: 0.7483 - val_loss: 0.6909\n",
      "Epoch 8/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8199 - loss: 0.4939\n",
      "Epoch 8: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8198 - loss: 0.4940 - val_accuracy: 0.7502 - val_loss: 0.7407\n",
      "Epoch 9/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 0.4613\n",
      "Epoch 9: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8310 - loss: 0.4614 - val_accuracy: 0.7453 - val_loss: 0.7289\n",
      "Epoch 10/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8503 - loss: 0.4215\n",
      "Epoch 10: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8501 - loss: 0.4220 - val_accuracy: 0.7552 - val_loss: 0.7248\n",
      "Epoch 11/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8519 - loss: 0.4147\n",
      "Epoch 11: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8520 - loss: 0.4145 - val_accuracy: 0.7602 - val_loss: 0.7464\n",
      "Epoch 12/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8746 - loss: 0.3681\n",
      "Epoch 12: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8745 - loss: 0.3683 - val_accuracy: 0.7502 - val_loss: 0.8477\n",
      "Epoch 13/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8758 - loss: 0.3399\n",
      "Epoch 13: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8758 - loss: 0.3400 - val_accuracy: 0.7303 - val_loss: 0.7896\n",
      "Epoch 14/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8938 - loss: 0.3058\n",
      "Epoch 14: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8938 - loss: 0.3058 - val_accuracy: 0.7672 - val_loss: 0.7747\n",
      "Epoch 15/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8956 - loss: 0.2881\n",
      "Epoch 15: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8956 - loss: 0.2882 - val_accuracy: 0.7373 - val_loss: 0.8735\n",
      "Epoch 16/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2526\n",
      "Epoch 16: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9157 - loss: 0.2526 - val_accuracy: 0.7642 - val_loss: 0.8650\n",
      "Epoch 17/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9217 - loss: 0.2323\n",
      "Epoch 17: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9217 - loss: 0.2324 - val_accuracy: 0.7193 - val_loss: 0.9285\n",
      "Epoch 18/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9269 - loss: 0.2223\n",
      "Epoch 18: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9269 - loss: 0.2223 - val_accuracy: 0.7273 - val_loss: 0.9068\n",
      "Epoch 19/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9377 - loss: 0.1945\n",
      "Epoch 19: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9376 - loss: 0.1947 - val_accuracy: 0.7642 - val_loss: 0.9525\n",
      "Epoch 20/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9442 - loss: 0.1718\n",
      "Epoch 20: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9441 - loss: 0.1720 - val_accuracy: 0.7403 - val_loss: 0.9134\n",
      "Epoch 21/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9542 - loss: 0.1496\n",
      "Epoch 21: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9542 - loss: 0.1497 - val_accuracy: 0.7592 - val_loss: 0.9768\n",
      "Epoch 22/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.1309\n",
      "Epoch 22: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9599 - loss: 0.1311 - val_accuracy: 0.7163 - val_loss: 1.0618\n",
      "Epoch 23/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9551 - loss: 0.1343\n",
      "Epoch 23: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9550 - loss: 0.1346 - val_accuracy: 0.7073 - val_loss: 1.0738\n",
      "Epoch 24/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9651 - loss: 0.1140\n",
      "Epoch 24: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9650 - loss: 0.1140 - val_accuracy: 0.7642 - val_loss: 0.9960\n",
      "Epoch 25/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9742 - loss: 0.0945\n",
      "Epoch 25: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9741 - loss: 0.0948 - val_accuracy: 0.7682 - val_loss: 0.9962\n",
      "Epoch 26/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0893\n",
      "Epoch 26: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.0894 - val_accuracy: 0.7572 - val_loss: 1.2218\n",
      "Epoch 27/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0839\n",
      "Epoch 27: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0840 - val_accuracy: 0.7562 - val_loss: 1.1890\n",
      "Epoch 28/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9752 - loss: 0.0830\n",
      "Epoch 28: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.0831 - val_accuracy: 0.7642 - val_loss: 1.2204\n",
      "Epoch 29/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9735 - loss: 0.0797\n",
      "Epoch 29: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9735 - loss: 0.0797 - val_accuracy: 0.7493 - val_loss: 1.1661\n",
      "Epoch 30/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9741 - loss: 0.0783\n",
      "Epoch 30: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9741 - loss: 0.0783 - val_accuracy: 0.7582 - val_loss: 1.4216\n",
      "Epoch 31/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9803 - loss: 0.0658\n",
      "Epoch 31: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9803 - loss: 0.0658 - val_accuracy: 0.7403 - val_loss: 1.4716\n",
      "Epoch 32/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9806 - loss: 0.0612\n",
      "Epoch 32: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0612 - val_accuracy: 0.7502 - val_loss: 1.2770\n",
      "Epoch 33/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0633\n",
      "Epoch 33: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0633 - val_accuracy: 0.7063 - val_loss: 1.4077\n",
      "Epoch 34/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0444\n",
      "Epoch 34: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0445 - val_accuracy: 0.7363 - val_loss: 1.4285\n",
      "Epoch 35/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0508\n",
      "Epoch 35: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0509 - val_accuracy: 0.7493 - val_loss: 1.3962\n",
      "Epoch 36/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9830 - loss: 0.0533\n",
      "Epoch 36: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0536 - val_accuracy: 0.7273 - val_loss: 1.3224\n",
      "Epoch 37/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0473\n",
      "Epoch 37: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0472 - val_accuracy: 0.7592 - val_loss: 1.3530\n",
      "Epoch 38/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9900 - loss: 0.0352\n",
      "Epoch 38: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9900 - loss: 0.0353 - val_accuracy: 0.7443 - val_loss: 1.5481\n",
      "Epoch 39/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0309\n",
      "Epoch 39: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0310 - val_accuracy: 0.7213 - val_loss: 1.5752\n",
      "Epoch 40/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9812 - loss: 0.0547\n",
      "Epoch 40: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0546 - val_accuracy: 0.7163 - val_loss: 1.4438\n",
      "Epoch 41/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0415\n",
      "Epoch 41: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0415 - val_accuracy: 0.7413 - val_loss: 1.4629\n",
      "Epoch 42/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9848 - loss: 0.0499\n",
      "Epoch 42: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9848 - loss: 0.0498 - val_accuracy: 0.7612 - val_loss: 1.4122\n",
      "Epoch 43/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0316\n",
      "Epoch 43: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0317 - val_accuracy: 0.7443 - val_loss: 1.6015\n",
      "Epoch 44/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9865 - loss: 0.0434\n",
      "Epoch 44: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9865 - loss: 0.0434 - val_accuracy: 0.7393 - val_loss: 1.4785\n",
      "Epoch 45/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0258\n",
      "Epoch 45: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0259 - val_accuracy: 0.7562 - val_loss: 1.6739\n",
      "Epoch 46/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0399\n",
      "Epoch 46: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0401 - val_accuracy: 0.7572 - val_loss: 1.5447\n",
      "Epoch 47/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0382\n",
      "Epoch 47: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0382 - val_accuracy: 0.6963 - val_loss: 1.7239\n",
      "Epoch 48/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0264\n",
      "Epoch 48: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0263 - val_accuracy: 0.7692 - val_loss: 1.6428\n",
      "Epoch 49/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0170\n",
      "Epoch 49: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0173 - val_accuracy: 0.7562 - val_loss: 1.7104\n",
      "Epoch 50/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9865 - loss: 0.0405\n",
      "Epoch 50: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0405 - val_accuracy: 0.6993 - val_loss: 1.7375\n",
      "Epoch 51/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9916 - loss: 0.0307\n",
      "Epoch 51: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0307 - val_accuracy: 0.7313 - val_loss: 1.4714\n",
      "Epoch 52/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0312\n",
      "Epoch 52: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0312 - val_accuracy: 0.7592 - val_loss: 1.6846\n",
      "Epoch 53/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0273\n",
      "Epoch 53: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0275 - val_accuracy: 0.7682 - val_loss: 1.6248\n",
      "Epoch 54/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0294\n",
      "Epoch 54: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0293 - val_accuracy: 0.7562 - val_loss: 1.4941\n",
      "Epoch 55/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0180\n",
      "Epoch 55: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0180 - val_accuracy: 0.7303 - val_loss: 1.7411\n",
      "Epoch 56/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0178\n",
      "Epoch 56: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0179 - val_accuracy: 0.7532 - val_loss: 1.5831\n",
      "Epoch 57/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9771 - loss: 0.0674\n",
      "Epoch 57: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9771 - loss: 0.0674 - val_accuracy: 0.7273 - val_loss: 1.9594\n",
      "Epoch 58/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.0492\n",
      "Epoch 58: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.0489 - val_accuracy: 0.7562 - val_loss: 1.4954\n",
      "Epoch 59/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0171\n",
      "Epoch 59: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - loss: 0.0172 - val_accuracy: 0.7592 - val_loss: 1.7049\n",
      "Epoch 60/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0125\n",
      "Epoch 60: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9974 - loss: 0.0125 - val_accuracy: 0.7702 - val_loss: 1.7589\n",
      "Epoch 61/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0087\n",
      "Epoch 61: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0087 - val_accuracy: 0.7572 - val_loss: 1.6443\n",
      "Epoch 62/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9927 - loss: 0.0217\n",
      "Epoch 62: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0221 - val_accuracy: 0.7632 - val_loss: 1.7574\n",
      "Epoch 63/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0475\n",
      "Epoch 63: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0476 - val_accuracy: 0.7323 - val_loss: 1.6978\n",
      "Epoch 64/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0262\n",
      "Epoch 64: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0262 - val_accuracy: 0.7602 - val_loss: 1.6327\n",
      "Epoch 65/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0099\n",
      "Epoch 65: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0100 - val_accuracy: 0.7652 - val_loss: 1.6349\n",
      "Epoch 66/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0096\n",
      "Epoch 66: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0096 - val_accuracy: 0.7423 - val_loss: 1.6404\n",
      "Epoch 67/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0081\n",
      "Epoch 67: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0084 - val_accuracy: 0.7363 - val_loss: 1.9047\n",
      "Epoch 68/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0448\n",
      "Epoch 68: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0448 - val_accuracy: 0.7403 - val_loss: 1.6790\n",
      "Epoch 69/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0317\n",
      "Epoch 69: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0317 - val_accuracy: 0.7672 - val_loss: 1.6705\n",
      "Epoch 70/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0149\n",
      "Epoch 70: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0149 - val_accuracy: 0.7522 - val_loss: 1.6429\n",
      "Epoch 71/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0167\n",
      "Epoch 71: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0168 - val_accuracy: 0.7552 - val_loss: 1.8625\n",
      "Epoch 72/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0467\n",
      "Epoch 72: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0466 - val_accuracy: 0.7582 - val_loss: 1.8464\n",
      "Epoch 73/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0167\n",
      "Epoch 73: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.0167 - val_accuracy: 0.7792 - val_loss: 1.5763\n",
      "Epoch 74/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0212\n",
      "Epoch 74: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0213 - val_accuracy: 0.7662 - val_loss: 1.7328\n",
      "Epoch 75/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0302\n",
      "Epoch 75: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0303 - val_accuracy: 0.7572 - val_loss: 1.9675\n",
      "Epoch 76/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0154\n",
      "Epoch 76: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0154 - val_accuracy: 0.7582 - val_loss: 1.6892\n",
      "Epoch 77/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0106\n",
      "Epoch 77: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0107 - val_accuracy: 0.7702 - val_loss: 1.8280\n",
      "Epoch 78/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0323\n",
      "Epoch 78: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0323 - val_accuracy: 0.7323 - val_loss: 1.9886\n",
      "Epoch 79/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0150\n",
      "Epoch 79: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0150 - val_accuracy: 0.7552 - val_loss: 2.0538\n",
      "Epoch 80/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0113\n",
      "Epoch 80: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0114 - val_accuracy: 0.7682 - val_loss: 1.8013\n",
      "Epoch 81/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0155\n",
      "Epoch 81: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0154 - val_accuracy: 0.7403 - val_loss: 1.8098\n",
      "Epoch 82/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0089\n",
      "Epoch 82: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0090 - val_accuracy: 0.7582 - val_loss: 1.8299\n",
      "Epoch 83/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0216\n",
      "Epoch 83: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0216 - val_accuracy: 0.7363 - val_loss: 2.0796\n",
      "Epoch 84/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0459\n",
      "Epoch 84: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0458 - val_accuracy: 0.7213 - val_loss: 1.7488\n",
      "Epoch 85/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0143\n",
      "Epoch 85: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0143 - val_accuracy: 0.7483 - val_loss: 1.7891\n",
      "Epoch 86/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9957 - loss: 0.0123\n",
      "Epoch 86: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0123 - val_accuracy: 0.7742 - val_loss: 1.6564\n",
      "Epoch 87/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9959 - loss: 0.0141\n",
      "Epoch 87: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0142 - val_accuracy: 0.7333 - val_loss: 1.9420\n",
      "Epoch 88/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0269\n",
      "Epoch 88: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0268 - val_accuracy: 0.7612 - val_loss: 1.9080\n",
      "Epoch 89/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0151\n",
      "Epoch 89: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0152 - val_accuracy: 0.7522 - val_loss: 1.8336\n",
      "Epoch 90/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9927 - loss: 0.0214\n",
      "Epoch 90: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0213 - val_accuracy: 0.7642 - val_loss: 1.6910\n",
      "Epoch 91/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0170\n",
      "Epoch 91: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0170 - val_accuracy: 0.7742 - val_loss: 1.7052\n",
      "Epoch 92/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0113\n",
      "Epoch 92: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0113 - val_accuracy: 0.7582 - val_loss: 1.8746\n",
      "Epoch 93/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0200\n",
      "Epoch 93: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0199 - val_accuracy: 0.7562 - val_loss: 2.0797\n",
      "Epoch 94/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0081\n",
      "Epoch 94: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0080 - val_accuracy: 0.7672 - val_loss: 1.9028\n",
      "Epoch 95/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0155\n",
      "Epoch 95: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0155 - val_accuracy: 0.7512 - val_loss: 2.1463\n",
      "Epoch 96/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9908 - loss: 0.0271\n",
      "Epoch 96: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0271 - val_accuracy: 0.7483 - val_loss: 1.9972\n",
      "Epoch 97/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.0337\n",
      "Epoch 97: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.0337 - val_accuracy: 0.7333 - val_loss: 2.1416\n",
      "Epoch 98/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0233\n",
      "Epoch 98: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0231 - val_accuracy: 0.7453 - val_loss: 1.8599\n",
      "Epoch 99/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0306\n",
      "Epoch 99: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.0306 - val_accuracy: 0.7602 - val_loss: 1.9396\n",
      "Epoch 100/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0134\n",
      "Epoch 100: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0134 - val_accuracy: 0.7542 - val_loss: 2.2162\n",
      "Epoch 101/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0104\n",
      "Epoch 101: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0104 - val_accuracy: 0.7702 - val_loss: 1.6968\n",
      "Epoch 102/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0026\n",
      "Epoch 102: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.7702 - val_loss: 1.8233\n",
      "Epoch 103/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 103: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7722 - val_loss: 1.8556\n",
      "Epoch 104/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0223\n",
      "Epoch 104: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0224 - val_accuracy: 0.7672 - val_loss: 1.7672\n",
      "Epoch 105/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0370\n",
      "Epoch 105: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0370 - val_accuracy: 0.7502 - val_loss: 2.3976\n",
      "Epoch 106/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0173\n",
      "Epoch 106: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0173 - val_accuracy: 0.7672 - val_loss: 1.9482\n",
      "Epoch 107/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0084\n",
      "Epoch 107: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0084 - val_accuracy: 0.7642 - val_loss: 1.9334\n",
      "Epoch 108/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0255\n",
      "Epoch 108: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0258 - val_accuracy: 0.7622 - val_loss: 1.9122\n",
      "Epoch 109/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0167\n",
      "Epoch 109: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0166 - val_accuracy: 0.7712 - val_loss: 1.6817\n",
      "Epoch 110/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0030\n",
      "Epoch 110: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.7822 - val_loss: 1.7708\n",
      "Epoch 111/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0025\n",
      "Epoch 111: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.7732 - val_loss: 1.9408\n",
      "Epoch 112/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 112: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.6983 - val_loss: 2.3194\n",
      "Epoch 113/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0371\n",
      "Epoch 113: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0371 - val_accuracy: 0.7582 - val_loss: 2.1578\n",
      "Epoch 114/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0358\n",
      "Epoch 114: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0357 - val_accuracy: 0.7522 - val_loss: 1.6845\n",
      "Epoch 115/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0068\n",
      "Epoch 115: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0067 - val_accuracy: 0.7912 - val_loss: 1.6119\n",
      "Epoch 116/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0022\n",
      "Epoch 116: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 0.7872 - val_loss: 1.6875\n",
      "Epoch 117/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0013\n",
      "Epoch 117: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.7562 - val_loss: 2.1869\n",
      "Epoch 118/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.0334\n",
      "Epoch 118: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.0334 - val_accuracy: 0.7592 - val_loss: 1.8992\n",
      "Epoch 119/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0184\n",
      "Epoch 119: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0184 - val_accuracy: 0.7772 - val_loss: 1.6670\n",
      "Epoch 120/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0094\n",
      "Epoch 120: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0094 - val_accuracy: 0.7562 - val_loss: 1.9526\n",
      "Epoch 121/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0161\n",
      "Epoch 121: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.7682 - val_loss: 2.1248\n",
      "Epoch 122/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0167\n",
      "Epoch 122: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0168 - val_accuracy: 0.7423 - val_loss: 1.8882\n",
      "Epoch 123/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0228\n",
      "Epoch 123: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.0227 - val_accuracy: 0.7692 - val_loss: 1.7780\n",
      "Epoch 124/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0090\n",
      "Epoch 124: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.7642 - val_loss: 1.8157\n",
      "Epoch 125/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0099\n",
      "Epoch 125: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0099 - val_accuracy: 0.7522 - val_loss: 1.7149\n",
      "Epoch 126/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0145\n",
      "Epoch 126: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0145 - val_accuracy: 0.7353 - val_loss: 2.0242\n",
      "Epoch 127/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0359\n",
      "Epoch 127: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0358 - val_accuracy: 0.7652 - val_loss: 1.8769\n",
      "Epoch 128/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0116\n",
      "Epoch 128: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0116 - val_accuracy: 0.7632 - val_loss: 2.0742\n",
      "Epoch 129/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0116\n",
      "Epoch 129: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0116 - val_accuracy: 0.7493 - val_loss: 1.7879\n",
      "Epoch 130/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0028\n",
      "Epoch 130: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.7702 - val_loss: 1.7781\n",
      "Epoch 131/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0029\n",
      "Epoch 131: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.7722 - val_loss: 1.7947\n",
      "Epoch 132/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.6116e-04\n",
      "Epoch 132: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.5994e-04 - val_accuracy: 0.7762 - val_loss: 1.8679\n",
      "Epoch 133/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0327\n",
      "Epoch 133: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0328 - val_accuracy: 0.7502 - val_loss: 2.2287\n",
      "Epoch 134/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0340\n",
      "Epoch 134: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0339 - val_accuracy: 0.7692 - val_loss: 1.7959\n",
      "Epoch 135/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0137\n",
      "Epoch 135: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9958 - loss: 0.0136 - val_accuracy: 0.7732 - val_loss: 1.9649\n",
      "Epoch 136/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0080\n",
      "Epoch 136: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0080 - val_accuracy: 0.7762 - val_loss: 1.8637\n",
      "Epoch 137/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0020\n",
      "Epoch 137: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.7742 - val_loss: 1.8267\n",
      "Epoch 138/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0037\n",
      "Epoch 138: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.7582 - val_loss: 1.8644\n",
      "Epoch 139/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0242\n",
      "Epoch 139: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0242 - val_accuracy: 0.7413 - val_loss: 2.0497\n",
      "Epoch 140/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0180\n",
      "Epoch 140: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0179 - val_accuracy: 0.7682 - val_loss: 1.8805\n",
      "Epoch 141/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0052\n",
      "Epoch 141: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 0.7502 - val_loss: 1.9767\n",
      "Epoch 142/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0248\n",
      "Epoch 142: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0248 - val_accuracy: 0.7642 - val_loss: 1.8968\n",
      "Epoch 143/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0080\n",
      "Epoch 143: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0080 - val_accuracy: 0.7732 - val_loss: 1.9136\n",
      "Epoch 144/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0053\n",
      "Epoch 144: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0053 - val_accuracy: 0.7592 - val_loss: 1.8523\n",
      "Epoch 145/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0076\n",
      "Epoch 145: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.7632 - val_loss: 1.8456\n",
      "Epoch 146/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0109\n",
      "Epoch 146: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0110 - val_accuracy: 0.7512 - val_loss: 1.9432\n",
      "Epoch 147/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0071\n",
      "Epoch 147: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.7493 - val_loss: 2.3120\n",
      "Epoch 148/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0392\n",
      "Epoch 148: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.0391 - val_accuracy: 0.7612 - val_loss: 1.9628\n",
      "Epoch 149/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0103\n",
      "Epoch 149: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0103 - val_accuracy: 0.7682 - val_loss: 1.9381\n",
      "Epoch 150/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0035\n",
      "Epoch 150: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.7702 - val_loss: 1.8999\n",
      "Epoch 151/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 151: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7632 - val_loss: 1.9755\n",
      "Epoch 152/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2475e-04\n",
      "Epoch 152: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2690e-04 - val_accuracy: 0.7622 - val_loss: 2.1192\n",
      "Epoch 153/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0019\n",
      "Epoch 153: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.7183 - val_loss: 3.0132\n",
      "Epoch 154/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9723 - loss: 0.0912\n",
      "Epoch 154: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9726 - loss: 0.0902 - val_accuracy: 0.7662 - val_loss: 1.7916\n",
      "Epoch 155/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0093\n",
      "Epoch 155: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0093 - val_accuracy: 0.7792 - val_loss: 1.8574\n",
      "Epoch 156/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0055\n",
      "Epoch 156: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.7542 - val_loss: 1.8545\n",
      "Epoch 157/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9980 - loss: 0.0068\n",
      "Epoch 157: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.7762 - val_loss: 1.8910\n",
      "Epoch 158/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0033\n",
      "Epoch 158: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.7652 - val_loss: 2.1636\n",
      "Epoch 159/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0063\n",
      "Epoch 159: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.7612 - val_loss: 2.3189\n",
      "Epoch 160/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0165\n",
      "Epoch 160: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9949 - loss: 0.0166 - val_accuracy: 0.7313 - val_loss: 1.9790\n",
      "Epoch 161/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0289\n",
      "Epoch 161: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0288 - val_accuracy: 0.7373 - val_loss: 1.9390\n",
      "Epoch 162/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0178\n",
      "Epoch 162: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.0178 - val_accuracy: 0.7592 - val_loss: 1.9164\n",
      "Epoch 163/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9988 - loss: 0.0037\n",
      "Epoch 163: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.7502 - val_loss: 2.0699\n",
      "Epoch 164/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0079\n",
      "Epoch 164: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0080 - val_accuracy: 0.7582 - val_loss: 2.1062\n",
      "Epoch 165/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0138\n",
      "Epoch 165: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0138 - val_accuracy: 0.7622 - val_loss: 1.9934\n",
      "Epoch 166/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0068\n",
      "Epoch 166: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 0.7632 - val_loss: 1.9743\n",
      "Epoch 167/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0035\n",
      "Epoch 167: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0035 - val_accuracy: 0.7572 - val_loss: 2.0343\n",
      "Epoch 168/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0054\n",
      "Epoch 168: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0054 - val_accuracy: 0.7722 - val_loss: 2.1119\n",
      "Epoch 169/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0061\n",
      "Epoch 169: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0062 - val_accuracy: 0.7682 - val_loss: 2.1355\n",
      "Epoch 170/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0379\n",
      "Epoch 170: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9881 - loss: 0.0378 - val_accuracy: 0.7622 - val_loss: 2.3201\n",
      "Epoch 171/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0148\n",
      "Epoch 171: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0148 - val_accuracy: 0.7632 - val_loss: 2.1145\n",
      "Epoch 172/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0032\n",
      "Epoch 172: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.7463 - val_loss: 2.1207\n",
      "Epoch 173/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0044\n",
      "Epoch 173: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.7672 - val_loss: 2.2199\n",
      "Epoch 174/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0012\n",
      "Epoch 174: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.7702 - val_loss: 2.3903\n",
      "Epoch 175/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0165\n",
      "Epoch 175: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0165 - val_accuracy: 0.7552 - val_loss: 2.2077\n",
      "Epoch 176/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0254\n",
      "Epoch 176: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0255 - val_accuracy: 0.7652 - val_loss: 2.3836\n",
      "Epoch 177/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0132\n",
      "Epoch 177: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0132 - val_accuracy: 0.7602 - val_loss: 2.0421\n",
      "Epoch 178/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0103\n",
      "Epoch 178: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0104 - val_accuracy: 0.7682 - val_loss: 1.9473\n",
      "Epoch 179/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0021\n",
      "Epoch 179: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.7622 - val_loss: 1.9926\n",
      "Epoch 180/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9983 - loss: 0.0049\n",
      "Epoch 180: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.7433 - val_loss: 2.7628\n",
      "Epoch 181/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0175\n",
      "Epoch 181: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0175 - val_accuracy: 0.7473 - val_loss: 2.1080\n",
      "Epoch 182/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0071\n",
      "Epoch 182: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0070 - val_accuracy: 0.7762 - val_loss: 1.9723\n",
      "Epoch 183/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0015\n",
      "Epoch 183: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.7562 - val_loss: 2.1006\n",
      "Epoch 184/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0069\n",
      "Epoch 184: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0069 - val_accuracy: 0.7542 - val_loss: 2.4362\n",
      "Epoch 185/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0154\n",
      "Epoch 185: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0154 - val_accuracy: 0.7642 - val_loss: 2.1932\n",
      "Epoch 186/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0097\n",
      "Epoch 186: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0098 - val_accuracy: 0.7423 - val_loss: 1.9955\n",
      "Epoch 187/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0117\n",
      "Epoch 187: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0118 - val_accuracy: 0.7642 - val_loss: 2.2016\n",
      "Epoch 188/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0134\n",
      "Epoch 188: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0133 - val_accuracy: 0.7522 - val_loss: 2.1041\n",
      "Epoch 189/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0219\n",
      "Epoch 189: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0218 - val_accuracy: 0.7662 - val_loss: 2.0411\n",
      "Epoch 190/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0096\n",
      "Epoch 190: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9963 - loss: 0.0096 - val_accuracy: 0.7343 - val_loss: 2.1615\n",
      "Epoch 191/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9965 - loss: 0.0109\n",
      "Epoch 191: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0109 - val_accuracy: 0.7363 - val_loss: 2.0488\n",
      "Epoch 192/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0132\n",
      "Epoch 192: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0132 - val_accuracy: 0.7662 - val_loss: 2.3400\n",
      "Epoch 193/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0070\n",
      "Epoch 193: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.7752 - val_loss: 2.1623\n",
      "Epoch 194/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0048\n",
      "Epoch 194: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.7692 - val_loss: 2.0969\n",
      "Epoch 195/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0014\n",
      "Epoch 195: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.7692 - val_loss: 2.3055\n",
      "Epoch 196/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 8.7772e-04\n",
      "Epoch 196: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 8.7161e-04 - val_accuracy: 0.7802 - val_loss: 2.1724\n",
      "Epoch 197/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.7171e-04\n",
      "Epoch 197: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.6942e-04 - val_accuracy: 0.7822 - val_loss: 2.1680\n",
      "Epoch 198/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.3045e-04\n",
      "Epoch 198: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.4919e-04 - val_accuracy: 0.7662 - val_loss: 2.1561\n",
      "Epoch 199/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0348\n",
      "Epoch 199: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0351 - val_accuracy: 0.7652 - val_loss: 2.0045\n",
      "Epoch 200/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0384\n",
      "Epoch 200: val_loss did not improve from 0.69091\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0380 - val_accuracy: 0.7632 - val_loss: 1.8427\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6210 - loss: 3.0940\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "model7 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6569 - loss: 1.0151\n",
      "Epoch 1: val_loss improved from inf to 1.53742, saving model to model_8/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6572 - loss: 1.0138 - val_accuracy: 0.5425 - val_loss: 1.5374\n",
      "Epoch 2/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7106 - loss: 0.7997\n",
      "Epoch 2: val_loss improved from 1.53742 to 0.96336, saving model to model_8/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7107 - loss: 0.7991 - val_accuracy: 0.6813 - val_loss: 0.9634\n",
      "Epoch 3/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.7270\n",
      "Epoch 3: val_loss improved from 0.96336 to 0.75632, saving model to model_8/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7334 - loss: 0.7268 - val_accuracy: 0.7163 - val_loss: 0.7563\n",
      "Epoch 4/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7614 - loss: 0.6538\n",
      "Epoch 4: val_loss did not improve from 0.75632\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7612 - loss: 0.6541 - val_accuracy: 0.7153 - val_loss: 0.7947\n",
      "Epoch 5/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7743 - loss: 0.6154\n",
      "Epoch 5: val_loss did not improve from 0.75632\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7743 - loss: 0.6155 - val_accuracy: 0.7263 - val_loss: 0.7668\n",
      "Epoch 6/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7896 - loss: 0.5713\n",
      "Epoch 6: val_loss improved from 0.75632 to 0.69801, saving model to model_8/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7895 - loss: 0.5713 - val_accuracy: 0.7363 - val_loss: 0.6980\n",
      "Epoch 7/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8122 - loss: 0.5283\n",
      "Epoch 7: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8119 - loss: 0.5286 - val_accuracy: 0.7373 - val_loss: 0.7405\n",
      "Epoch 8/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8166 - loss: 0.4997\n",
      "Epoch 8: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8166 - loss: 0.4996 - val_accuracy: 0.7433 - val_loss: 0.7201\n",
      "Epoch 9/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8419 - loss: 0.4477\n",
      "Epoch 9: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8418 - loss: 0.4478 - val_accuracy: 0.7123 - val_loss: 0.8431\n",
      "Epoch 10/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8427 - loss: 0.4288\n",
      "Epoch 10: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8426 - loss: 0.4289 - val_accuracy: 0.7483 - val_loss: 0.7474\n",
      "Epoch 11/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8545 - loss: 0.3969\n",
      "Epoch 11: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8545 - loss: 0.3970 - val_accuracy: 0.7213 - val_loss: 0.7797\n",
      "Epoch 12/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8763 - loss: 0.3464\n",
      "Epoch 12: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8762 - loss: 0.3467 - val_accuracy: 0.7453 - val_loss: 0.7551\n",
      "Epoch 13/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8826 - loss: 0.3393\n",
      "Epoch 13: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8826 - loss: 0.3393 - val_accuracy: 0.7133 - val_loss: 1.0308\n",
      "Epoch 14/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8977 - loss: 0.2988\n",
      "Epoch 14: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8976 - loss: 0.2990 - val_accuracy: 0.7493 - val_loss: 0.7880\n",
      "Epoch 15/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9090 - loss: 0.2755\n",
      "Epoch 15: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.2755 - val_accuracy: 0.7433 - val_loss: 0.8797\n",
      "Epoch 16/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9151 - loss: 0.2416\n",
      "Epoch 16: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9151 - loss: 0.2416 - val_accuracy: 0.7483 - val_loss: 0.8426\n",
      "Epoch 17/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9340 - loss: 0.2101\n",
      "Epoch 17: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9339 - loss: 0.2102 - val_accuracy: 0.7343 - val_loss: 0.9632\n",
      "Epoch 18/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9368 - loss: 0.1941\n",
      "Epoch 18: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9368 - loss: 0.1942 - val_accuracy: 0.7582 - val_loss: 0.8702\n",
      "Epoch 19/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9416 - loss: 0.1772\n",
      "Epoch 19: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9415 - loss: 0.1774 - val_accuracy: 0.7502 - val_loss: 1.0169\n",
      "Epoch 20/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9500 - loss: 0.1620\n",
      "Epoch 20: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9500 - loss: 0.1621 - val_accuracy: 0.7203 - val_loss: 1.0486\n",
      "Epoch 21/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9509 - loss: 0.1496\n",
      "Epoch 21: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9509 - loss: 0.1496 - val_accuracy: 0.7373 - val_loss: 0.9215\n",
      "Epoch 22/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9627 - loss: 0.1278\n",
      "Epoch 22: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9627 - loss: 0.1278 - val_accuracy: 0.7512 - val_loss: 1.0737\n",
      "Epoch 23/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9593 - loss: 0.1230\n",
      "Epoch 23: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9592 - loss: 0.1231 - val_accuracy: 0.7173 - val_loss: 1.0734\n",
      "Epoch 24/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9728 - loss: 0.0995\n",
      "Epoch 24: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9727 - loss: 0.0996 - val_accuracy: 0.7393 - val_loss: 1.1457\n",
      "Epoch 25/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.0790\n",
      "Epoch 25: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.0792 - val_accuracy: 0.7243 - val_loss: 1.2297\n",
      "Epoch 26/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9736 - loss: 0.0830\n",
      "Epoch 26: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9736 - loss: 0.0830 - val_accuracy: 0.7562 - val_loss: 1.1169\n",
      "Epoch 27/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9789 - loss: 0.0748\n",
      "Epoch 27: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9787 - loss: 0.0752 - val_accuracy: 0.7453 - val_loss: 1.2311\n",
      "Epoch 28/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9757 - loss: 0.0747\n",
      "Epoch 28: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9756 - loss: 0.0747 - val_accuracy: 0.7413 - val_loss: 1.2517\n",
      "Epoch 29/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9804 - loss: 0.0643\n",
      "Epoch 29: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.0645 - val_accuracy: 0.7423 - val_loss: 1.3197\n",
      "Epoch 30/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9778 - loss: 0.0688\n",
      "Epoch 30: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9778 - loss: 0.0688 - val_accuracy: 0.7223 - val_loss: 1.3253\n",
      "Epoch 31/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.0677\n",
      "Epoch 31: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.0676 - val_accuracy: 0.7473 - val_loss: 1.3784\n",
      "Epoch 32/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9791 - loss: 0.0635\n",
      "Epoch 32: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9791 - loss: 0.0634 - val_accuracy: 0.7363 - val_loss: 1.3620\n",
      "Epoch 33/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.0401\n",
      "Epoch 33: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.0401 - val_accuracy: 0.7353 - val_loss: 1.4257\n",
      "Epoch 34/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0488\n",
      "Epoch 34: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0490 - val_accuracy: 0.7433 - val_loss: 1.4179\n",
      "Epoch 35/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9809 - loss: 0.0587\n",
      "Epoch 35: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9809 - loss: 0.0587 - val_accuracy: 0.7273 - val_loss: 1.4373\n",
      "Epoch 36/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.0532\n",
      "Epoch 36: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.0531 - val_accuracy: 0.7133 - val_loss: 1.4861\n",
      "Epoch 37/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0386\n",
      "Epoch 37: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9886 - loss: 0.0386 - val_accuracy: 0.7273 - val_loss: 1.4241\n",
      "Epoch 38/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.0477\n",
      "Epoch 38: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9837 - loss: 0.0478 - val_accuracy: 0.7463 - val_loss: 1.5059\n",
      "Epoch 39/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.0385\n",
      "Epoch 39: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9893 - loss: 0.0385 - val_accuracy: 0.7293 - val_loss: 1.4616\n",
      "Epoch 40/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0249\n",
      "Epoch 40: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9932 - loss: 0.0250 - val_accuracy: 0.7403 - val_loss: 1.5280\n",
      "Epoch 41/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0238\n",
      "Epoch 41: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9931 - loss: 0.0238 - val_accuracy: 0.7083 - val_loss: 1.8765\n",
      "Epoch 42/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9792 - loss: 0.0582\n",
      "Epoch 42: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9792 - loss: 0.0582 - val_accuracy: 0.6523 - val_loss: 2.0663\n",
      "Epoch 43/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9790 - loss: 0.0591\n",
      "Epoch 43: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9791 - loss: 0.0590 - val_accuracy: 0.7393 - val_loss: 1.4482\n",
      "Epoch 44/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.0364\n",
      "Epoch 44: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9891 - loss: 0.0364 - val_accuracy: 0.7423 - val_loss: 1.6578\n",
      "Epoch 45/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0316\n",
      "Epoch 45: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0316 - val_accuracy: 0.7353 - val_loss: 1.5954\n",
      "Epoch 46/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0246\n",
      "Epoch 46: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9930 - loss: 0.0247 - val_accuracy: 0.7323 - val_loss: 1.4636\n",
      "Epoch 47/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0194\n",
      "Epoch 47: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0195 - val_accuracy: 0.7453 - val_loss: 1.6097\n",
      "Epoch 48/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9907 - loss: 0.0310\n",
      "Epoch 48: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0313 - val_accuracy: 0.7313 - val_loss: 1.4996\n",
      "Epoch 49/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0394\n",
      "Epoch 49: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0393 - val_accuracy: 0.7483 - val_loss: 1.5620\n",
      "Epoch 50/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0238\n",
      "Epoch 50: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0242 - val_accuracy: 0.6883 - val_loss: 1.7781\n",
      "Epoch 51/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0315\n",
      "Epoch 51: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0315 - val_accuracy: 0.6913 - val_loss: 1.7384\n",
      "Epoch 52/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0260\n",
      "Epoch 52: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0260 - val_accuracy: 0.7532 - val_loss: 1.6879\n",
      "Epoch 53/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0239\n",
      "Epoch 53: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0241 - val_accuracy: 0.7483 - val_loss: 1.5992\n",
      "Epoch 54/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0476\n",
      "Epoch 54: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0476 - val_accuracy: 0.7512 - val_loss: 1.6341\n",
      "Epoch 55/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0209\n",
      "Epoch 55: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0208 - val_accuracy: 0.7413 - val_loss: 1.5431\n",
      "Epoch 56/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0142\n",
      "Epoch 56: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.7243 - val_loss: 1.7629\n",
      "Epoch 57/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0373\n",
      "Epoch 57: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0374 - val_accuracy: 0.7433 - val_loss: 2.0734\n",
      "Epoch 58/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0360\n",
      "Epoch 58: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9872 - loss: 0.0358 - val_accuracy: 0.7542 - val_loss: 1.7200\n",
      "Epoch 59/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0242\n",
      "Epoch 59: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0242 - val_accuracy: 0.7193 - val_loss: 1.7683\n",
      "Epoch 60/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0230\n",
      "Epoch 60: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0230 - val_accuracy: 0.7463 - val_loss: 1.7063\n",
      "Epoch 61/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0216\n",
      "Epoch 61: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0216 - val_accuracy: 0.7383 - val_loss: 1.6472\n",
      "Epoch 62/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0173\n",
      "Epoch 62: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0172 - val_accuracy: 0.7363 - val_loss: 1.6383\n",
      "Epoch 63/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0178\n",
      "Epoch 63: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9945 - loss: 0.0178 - val_accuracy: 0.7443 - val_loss: 1.7363\n",
      "Epoch 64/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0383\n",
      "Epoch 64: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9863 - loss: 0.0384 - val_accuracy: 0.7153 - val_loss: 2.1058\n",
      "Epoch 65/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9931 - loss: 0.0245\n",
      "Epoch 65: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9931 - loss: 0.0245 - val_accuracy: 0.7552 - val_loss: 1.5354\n",
      "Epoch 66/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9976 - loss: 0.0086\n",
      "Epoch 66: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0086 - val_accuracy: 0.7463 - val_loss: 1.7822\n",
      "Epoch 67/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0235\n",
      "Epoch 67: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0236 - val_accuracy: 0.7253 - val_loss: 2.5503\n",
      "Epoch 68/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0368\n",
      "Epoch 68: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0368 - val_accuracy: 0.7253 - val_loss: 1.7518\n",
      "Epoch 69/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0147\n",
      "Epoch 69: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0148 - val_accuracy: 0.7323 - val_loss: 1.6416\n",
      "Epoch 70/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9972 - loss: 0.0099\n",
      "Epoch 70: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0099 - val_accuracy: 0.7413 - val_loss: 1.9214\n",
      "Epoch 71/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0137\n",
      "Epoch 71: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0138 - val_accuracy: 0.7423 - val_loss: 1.8673\n",
      "Epoch 72/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9904 - loss: 0.0299\n",
      "Epoch 72: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9904 - loss: 0.0298 - val_accuracy: 0.7283 - val_loss: 1.8431\n",
      "Epoch 73/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9937 - loss: 0.0211\n",
      "Epoch 73: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9938 - loss: 0.0211 - val_accuracy: 0.7373 - val_loss: 1.8399\n",
      "Epoch 74/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0173\n",
      "Epoch 74: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0175 - val_accuracy: 0.7483 - val_loss: 1.9843\n",
      "Epoch 75/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0392\n",
      "Epoch 75: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0392 - val_accuracy: 0.7453 - val_loss: 1.8352\n",
      "Epoch 76/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0293\n",
      "Epoch 76: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0293 - val_accuracy: 0.7423 - val_loss: 1.8192\n",
      "Epoch 77/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0120\n",
      "Epoch 77: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0120 - val_accuracy: 0.7473 - val_loss: 1.7201\n",
      "Epoch 78/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0080\n",
      "Epoch 78: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0080 - val_accuracy: 0.7652 - val_loss: 1.7860\n",
      "Epoch 79/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0207\n",
      "Epoch 79: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0208 - val_accuracy: 0.6893 - val_loss: 1.8907\n",
      "Epoch 80/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9925 - loss: 0.0205\n",
      "Epoch 80: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0205 - val_accuracy: 0.7113 - val_loss: 1.8257\n",
      "Epoch 81/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0373\n",
      "Epoch 81: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0373 - val_accuracy: 0.7373 - val_loss: 1.8933\n",
      "Epoch 82/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0158\n",
      "Epoch 82: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0158 - val_accuracy: 0.7582 - val_loss: 1.7703\n",
      "Epoch 83/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0093\n",
      "Epoch 83: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0093 - val_accuracy: 0.7293 - val_loss: 1.9386\n",
      "Epoch 84/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0171\n",
      "Epoch 84: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0170 - val_accuracy: 0.7413 - val_loss: 2.0318\n",
      "Epoch 85/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0209\n",
      "Epoch 85: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9942 - loss: 0.0209 - val_accuracy: 0.7383 - val_loss: 1.8989\n",
      "Epoch 86/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0102\n",
      "Epoch 86: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0101 - val_accuracy: 0.7473 - val_loss: 1.8386\n",
      "Epoch 87/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0026\n",
      "Epoch 87: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.7483 - val_loss: 1.8273\n",
      "Epoch 88/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0063\n",
      "Epoch 88: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 0.7103 - val_loss: 2.1763\n",
      "Epoch 89/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0767\n",
      "Epoch 89: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0767 - val_accuracy: 0.7193 - val_loss: 1.8681\n",
      "Epoch 90/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9921 - loss: 0.0235\n",
      "Epoch 90: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0234 - val_accuracy: 0.7562 - val_loss: 1.6254\n",
      "Epoch 91/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0091\n",
      "Epoch 91: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0091 - val_accuracy: 0.7363 - val_loss: 2.0300\n",
      "Epoch 92/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0125\n",
      "Epoch 92: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0127 - val_accuracy: 0.7612 - val_loss: 1.9210\n",
      "Epoch 93/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0311\n",
      "Epoch 93: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0309 - val_accuracy: 0.7303 - val_loss: 1.9118\n",
      "Epoch 94/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0094\n",
      "Epoch 94: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0094 - val_accuracy: 0.7243 - val_loss: 1.7677\n",
      "Epoch 95/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0091\n",
      "Epoch 95: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0091 - val_accuracy: 0.7493 - val_loss: 1.8909\n",
      "Epoch 96/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0130\n",
      "Epoch 96: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0130 - val_accuracy: 0.7383 - val_loss: 1.8858\n",
      "Epoch 97/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0176\n",
      "Epoch 97: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9939 - loss: 0.0175 - val_accuracy: 0.7373 - val_loss: 1.8236\n",
      "Epoch 98/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0131\n",
      "Epoch 98: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0135 - val_accuracy: 0.7293 - val_loss: 2.1665\n",
      "Epoch 99/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0447\n",
      "Epoch 99: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9839 - loss: 0.0446 - val_accuracy: 0.7073 - val_loss: 1.9564\n",
      "Epoch 100/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0115\n",
      "Epoch 100: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0115 - val_accuracy: 0.7592 - val_loss: 1.9015\n",
      "Epoch 101/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9996 - loss: 0.0034\n",
      "Epoch 101: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.7592 - val_loss: 1.7492\n",
      "Epoch 102/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012\n",
      "Epoch 102: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7473 - val_loss: 1.8322\n",
      "Epoch 103/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0026\n",
      "Epoch 103: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.7602 - val_loss: 1.8692\n",
      "Epoch 104/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0469\n",
      "Epoch 104: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0469 - val_accuracy: 0.7183 - val_loss: 2.3787\n",
      "Epoch 105/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9875 - loss: 0.0354\n",
      "Epoch 105: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9875 - loss: 0.0353 - val_accuracy: 0.7193 - val_loss: 2.0056\n",
      "Epoch 106/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0139\n",
      "Epoch 106: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9955 - loss: 0.0139 - val_accuracy: 0.7532 - val_loss: 1.8309\n",
      "Epoch 107/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0086\n",
      "Epoch 107: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9980 - loss: 0.0086 - val_accuracy: 0.7562 - val_loss: 1.8326\n",
      "Epoch 108/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0069\n",
      "Epoch 108: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.7313 - val_loss: 1.9329\n",
      "Epoch 109/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0028\n",
      "Epoch 109: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.7622 - val_loss: 1.8003\n",
      "Epoch 110/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9995 - loss: 0.0028\n",
      "Epoch 110: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.7463 - val_loss: 1.9369\n",
      "Epoch 111/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0061\n",
      "Epoch 111: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 0.7203 - val_loss: 2.4311\n",
      "Epoch 112/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.0897\n",
      "Epoch 112: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.0896 - val_accuracy: 0.7403 - val_loss: 1.8722\n",
      "Epoch 113/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0126\n",
      "Epoch 113: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0126 - val_accuracy: 0.7373 - val_loss: 1.9256\n",
      "Epoch 114/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0088\n",
      "Epoch 114: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0088 - val_accuracy: 0.7313 - val_loss: 1.8816\n",
      "Epoch 115/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0082\n",
      "Epoch 115: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0082 - val_accuracy: 0.7423 - val_loss: 2.0099\n",
      "Epoch 116/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0051\n",
      "Epoch 116: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9984 - loss: 0.0052 - val_accuracy: 0.7393 - val_loss: 1.9320\n",
      "Epoch 117/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0115\n",
      "Epoch 117: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0115 - val_accuracy: 0.7473 - val_loss: 1.9934\n",
      "Epoch 118/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0085\n",
      "Epoch 118: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.7233 - val_loss: 2.1390\n",
      "Epoch 119/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0247\n",
      "Epoch 119: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0247 - val_accuracy: 0.7413 - val_loss: 1.9492\n",
      "Epoch 120/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0134\n",
      "Epoch 120: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0135 - val_accuracy: 0.7612 - val_loss: 1.8534\n",
      "Epoch 121/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0142\n",
      "Epoch 121: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0142 - val_accuracy: 0.7542 - val_loss: 1.9578\n",
      "Epoch 122/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0082\n",
      "Epoch 122: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0083 - val_accuracy: 0.6973 - val_loss: 2.0951\n",
      "Epoch 123/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9984 - loss: 0.0074\n",
      "Epoch 123: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0076 - val_accuracy: 0.6893 - val_loss: 2.2323\n",
      "Epoch 124/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9953 - loss: 0.0156\n",
      "Epoch 124: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9953 - loss: 0.0156 - val_accuracy: 0.7423 - val_loss: 1.8745\n",
      "Epoch 125/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0172\n",
      "Epoch 125: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0174 - val_accuracy: 0.7053 - val_loss: 2.1014\n",
      "Epoch 126/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.0300\n",
      "Epoch 126: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9906 - loss: 0.0299 - val_accuracy: 0.7083 - val_loss: 1.9872\n",
      "Epoch 127/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0091\n",
      "Epoch 127: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0091 - val_accuracy: 0.7353 - val_loss: 1.8856\n",
      "Epoch 128/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0065\n",
      "Epoch 128: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0065 - val_accuracy: 0.7622 - val_loss: 1.9380\n",
      "Epoch 129/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0027\n",
      "Epoch 129: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.7572 - val_loss: 1.8822\n",
      "Epoch 130/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0019\n",
      "Epoch 130: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.7213 - val_loss: 2.1699\n",
      "Epoch 131/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0392\n",
      "Epoch 131: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0392 - val_accuracy: 0.6913 - val_loss: 2.1633\n",
      "Epoch 132/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0273\n",
      "Epoch 132: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0272 - val_accuracy: 0.7423 - val_loss: 1.9501\n",
      "Epoch 133/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0195\n",
      "Epoch 133: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0195 - val_accuracy: 0.7493 - val_loss: 1.8940\n",
      "Epoch 134/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0072\n",
      "Epoch 134: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0072 - val_accuracy: 0.7473 - val_loss: 2.0676\n",
      "Epoch 135/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0216\n",
      "Epoch 135: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0216 - val_accuracy: 0.7443 - val_loss: 1.9129\n",
      "Epoch 136/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0047\n",
      "Epoch 136: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0047 - val_accuracy: 0.7542 - val_loss: 1.8367\n",
      "Epoch 137/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0024\n",
      "Epoch 137: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 0.0024 - val_accuracy: 0.7433 - val_loss: 1.8487\n",
      "Epoch 138/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0011\n",
      "Epoch 138: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.7502 - val_loss: 1.8967\n",
      "Epoch 139/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0123\n",
      "Epoch 139: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0125 - val_accuracy: 0.7073 - val_loss: 2.5076\n",
      "Epoch 140/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0433\n",
      "Epoch 140: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0431 - val_accuracy: 0.7622 - val_loss: 2.0011\n",
      "Epoch 141/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0109\n",
      "Epoch 141: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9964 - loss: 0.0109 - val_accuracy: 0.7722 - val_loss: 1.9963\n",
      "Epoch 142/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0085\n",
      "Epoch 142: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0084 - val_accuracy: 0.7502 - val_loss: 1.8531\n",
      "Epoch 143/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0026\n",
      "Epoch 143: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.7602 - val_loss: 1.9195\n",
      "Epoch 144/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.0895e-04\n",
      "Epoch 144: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 9.0780e-04 - val_accuracy: 0.7552 - val_loss: 1.8233\n",
      "Epoch 145/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.7527e-04\n",
      "Epoch 145: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.7627e-04 - val_accuracy: 0.7582 - val_loss: 1.8395\n",
      "Epoch 146/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0050\n",
      "Epoch 146: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.6673 - val_loss: 2.8743\n",
      "Epoch 147/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0390\n",
      "Epoch 147: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0389 - val_accuracy: 0.7542 - val_loss: 2.1124\n",
      "Epoch 148/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9965 - loss: 0.0105\n",
      "Epoch 148: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.7213 - val_loss: 1.9855\n",
      "Epoch 149/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0083\n",
      "Epoch 149: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0083 - val_accuracy: 0.7333 - val_loss: 2.1595\n",
      "Epoch 150/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9922 - loss: 0.0205\n",
      "Epoch 150: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9923 - loss: 0.0205 - val_accuracy: 0.7493 - val_loss: 1.9388\n",
      "Epoch 151/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0122\n",
      "Epoch 151: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0121 - val_accuracy: 0.7572 - val_loss: 1.9169\n",
      "Epoch 152/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0057\n",
      "Epoch 152: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0058 - val_accuracy: 0.7413 - val_loss: 2.1311\n",
      "Epoch 153/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0043\n",
      "Epoch 153: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.7443 - val_loss: 2.2658\n",
      "Epoch 154/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0242\n",
      "Epoch 154: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0243 - val_accuracy: 0.7343 - val_loss: 2.0188\n",
      "Epoch 155/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0189\n",
      "Epoch 155: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0189 - val_accuracy: 0.7393 - val_loss: 1.9208\n",
      "Epoch 156/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0090\n",
      "Epoch 156: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0089 - val_accuracy: 0.7493 - val_loss: 2.1111\n",
      "Epoch 157/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0032\n",
      "Epoch 157: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.7622 - val_loss: 1.9875\n",
      "Epoch 158/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9999 - loss: 9.1448e-04\n",
      "Epoch 158: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9999 - loss: 9.1566e-04 - val_accuracy: 0.7602 - val_loss: 1.9733\n",
      "Epoch 159/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0013\n",
      "Epoch 159: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.7732 - val_loss: 1.9647\n",
      "Epoch 160/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.4712e-04\n",
      "Epoch 160: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.4767e-04 - val_accuracy: 0.7552 - val_loss: 2.1336\n",
      "Epoch 161/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0066\n",
      "Epoch 161: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9972 - loss: 0.0070 - val_accuracy: 0.7153 - val_loss: 2.0754\n",
      "Epoch 162/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0504\n",
      "Epoch 162: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0502 - val_accuracy: 0.7043 - val_loss: 2.0399\n",
      "Epoch 163/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9963 - loss: 0.0107\n",
      "Epoch 163: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.7542 - val_loss: 2.0800\n",
      "Epoch 164/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0114\n",
      "Epoch 164: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9974 - loss: 0.0114 - val_accuracy: 0.7602 - val_loss: 2.0272\n",
      "Epoch 165/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9971 - loss: 0.0064\n",
      "Epoch 165: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.0065 - val_accuracy: 0.7453 - val_loss: 2.0629\n",
      "Epoch 166/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0083\n",
      "Epoch 166: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0083 - val_accuracy: 0.7463 - val_loss: 2.0746\n",
      "Epoch 167/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0079\n",
      "Epoch 167: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0078 - val_accuracy: 0.7343 - val_loss: 2.0570\n",
      "Epoch 168/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0147\n",
      "Epoch 168: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0148 - val_accuracy: 0.7463 - val_loss: 2.0098\n",
      "Epoch 169/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9919 - loss: 0.0226\n",
      "Epoch 169: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0226 - val_accuracy: 0.7592 - val_loss: 1.8227\n",
      "Epoch 170/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0044\n",
      "Epoch 170: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9982 - loss: 0.0044 - val_accuracy: 0.7443 - val_loss: 1.9494\n",
      "Epoch 171/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0096\n",
      "Epoch 171: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0095 - val_accuracy: 0.7532 - val_loss: 1.9790\n",
      "Epoch 172/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0077\n",
      "Epoch 172: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.7043 - val_loss: 2.0870\n",
      "Epoch 173/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0143\n",
      "Epoch 173: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0143 - val_accuracy: 0.7233 - val_loss: 2.3012\n",
      "Epoch 174/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0261\n",
      "Epoch 174: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0260 - val_accuracy: 0.7293 - val_loss: 1.9617\n",
      "Epoch 175/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0146\n",
      "Epoch 175: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9950 - loss: 0.0144 - val_accuracy: 0.7463 - val_loss: 1.8461\n",
      "Epoch 176/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0019\n",
      "Epoch 176: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.7483 - val_loss: 1.9083\n",
      "Epoch 177/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0035\n",
      "Epoch 177: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.7552 - val_loss: 1.8870\n",
      "Epoch 178/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.8417e-04\n",
      "Epoch 178: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.8533e-04 - val_accuracy: 0.7532 - val_loss: 1.9346\n",
      "Epoch 179/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.6444e-04\n",
      "Epoch 179: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.6431e-04 - val_accuracy: 0.7712 - val_loss: 1.8927\n",
      "Epoch 180/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9433e-04\n",
      "Epoch 180: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9458e-04 - val_accuracy: 0.7652 - val_loss: 1.9504\n",
      "Epoch 181/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1558e-04\n",
      "Epoch 181: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1664e-04 - val_accuracy: 0.7592 - val_loss: 1.9786\n",
      "Epoch 182/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.8995e-04\n",
      "Epoch 182: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.9041e-04 - val_accuracy: 0.7642 - val_loss: 2.0714\n",
      "Epoch 183/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.6373e-04\n",
      "Epoch 183: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.6379e-04 - val_accuracy: 0.7592 - val_loss: 2.0288\n",
      "Epoch 184/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1808e-04\n",
      "Epoch 184: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.1848e-04 - val_accuracy: 0.7542 - val_loss: 2.0579\n",
      "Epoch 185/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4126e-04\n",
      "Epoch 185: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4084e-04 - val_accuracy: 0.7632 - val_loss: 2.0963\n",
      "Epoch 186/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1230e-04\n",
      "Epoch 186: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1243e-04 - val_accuracy: 0.7552 - val_loss: 2.0978\n",
      "Epoch 187/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.0586\n",
      "Epoch 187: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9822 - loss: 0.0590 - val_accuracy: 0.7263 - val_loss: 1.9496\n",
      "Epoch 188/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0321\n",
      "Epoch 188: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9872 - loss: 0.0320 - val_accuracy: 0.7463 - val_loss: 1.7605\n",
      "Epoch 189/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0055\n",
      "Epoch 189: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.7602 - val_loss: 1.8693\n",
      "Epoch 190/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0086\n",
      "Epoch 190: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9979 - loss: 0.0086 - val_accuracy: 0.7483 - val_loss: 1.8799\n",
      "Epoch 191/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0038\n",
      "Epoch 191: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.7632 - val_loss: 1.8608\n",
      "Epoch 192/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0042\n",
      "Epoch 192: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.7463 - val_loss: 1.9240\n",
      "Epoch 193/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0031\n",
      "Epoch 193: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.7383 - val_loss: 2.0912\n",
      "Epoch 194/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0042\n",
      "Epoch 194: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.7522 - val_loss: 2.1236\n",
      "Epoch 195/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0086\n",
      "Epoch 195: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0086 - val_accuracy: 0.7493 - val_loss: 2.0211\n",
      "Epoch 196/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0149\n",
      "Epoch 196: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0151 - val_accuracy: 0.7433 - val_loss: 2.1431\n",
      "Epoch 197/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0111\n",
      "Epoch 197: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0112 - val_accuracy: 0.7273 - val_loss: 2.0037\n",
      "Epoch 198/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0111\n",
      "Epoch 198: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0110 - val_accuracy: 0.7522 - val_loss: 2.0164\n",
      "Epoch 199/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0063\n",
      "Epoch 199: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.7632 - val_loss: 2.0351\n",
      "Epoch 200/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0094\n",
      "Epoch 200: val_loss did not improve from 0.69801\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0094 - val_accuracy: 0.7502 - val_loss: 1.9601\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6386 - loss: 3.0126\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "model8 trained\n",
      "Epoch 1/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6496 - loss: 1.0336\n",
      "Epoch 1: val_loss improved from inf to 1.65603, saving model to model_9/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.6506 - loss: 1.0300 - val_accuracy: 0.1508 - val_loss: 1.6560\n",
      "Epoch 2/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7124 - loss: 0.8036\n",
      "Epoch 2: val_loss improved from 1.65603 to 0.97226, saving model to model_9/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7125 - loss: 0.8030 - val_accuracy: 0.6503 - val_loss: 0.9723\n",
      "Epoch 3/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7505 - loss: 0.6962\n",
      "Epoch 3: val_loss improved from 0.97226 to 0.71992, saving model to model_9/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7503 - loss: 0.6965 - val_accuracy: 0.7213 - val_loss: 0.7199\n",
      "Epoch 4/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7702 - loss: 0.6462\n",
      "Epoch 4: val_loss improved from 0.71992 to 0.70691, saving model to model_9/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7699 - loss: 0.6466 - val_accuracy: 0.7303 - val_loss: 0.7069\n",
      "Epoch 5/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7747 - loss: 0.6193\n",
      "Epoch 5: val_loss improved from 0.70691 to 0.70465, saving model to model_9/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7747 - loss: 0.6192 - val_accuracy: 0.7433 - val_loss: 0.7047\n",
      "Epoch 6/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7949 - loss: 0.5608\n",
      "Epoch 6: val_loss did not improve from 0.70465\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7949 - loss: 0.5609 - val_accuracy: 0.7393 - val_loss: 0.7289\n",
      "Epoch 7/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8082 - loss: 0.5390\n",
      "Epoch 7: val_loss improved from 0.70465 to 0.68484, saving model to model_9/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8082 - loss: 0.5390 - val_accuracy: 0.7403 - val_loss: 0.6848\n",
      "Epoch 8/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8177 - loss: 0.5043\n",
      "Epoch 8: val_loss did not improve from 0.68484\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8177 - loss: 0.5043 - val_accuracy: 0.7323 - val_loss: 0.6879\n",
      "Epoch 9/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8366 - loss: 0.4636\n",
      "Epoch 9: val_loss did not improve from 0.68484\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8364 - loss: 0.4639 - val_accuracy: 0.7333 - val_loss: 0.7349\n",
      "Epoch 10/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8481 - loss: 0.4168\n",
      "Epoch 10: val_loss improved from 0.68484 to 0.68361, saving model to model_9/checkpoint.weights.h5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8478 - loss: 0.4174 - val_accuracy: 0.7512 - val_loss: 0.6836\n",
      "Epoch 11/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8569 - loss: 0.3963\n",
      "Epoch 11: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8568 - loss: 0.3965 - val_accuracy: 0.7423 - val_loss: 0.7539\n",
      "Epoch 12/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8599 - loss: 0.3828\n",
      "Epoch 12: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8599 - loss: 0.3828 - val_accuracy: 0.6983 - val_loss: 0.8203\n",
      "Epoch 13/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8849 - loss: 0.3376\n",
      "Epoch 13: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8848 - loss: 0.3377 - val_accuracy: 0.7013 - val_loss: 1.1008\n",
      "Epoch 14/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8902 - loss: 0.3102\n",
      "Epoch 14: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8902 - loss: 0.3103 - val_accuracy: 0.7473 - val_loss: 0.7734\n",
      "Epoch 15/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9015 - loss: 0.2834\n",
      "Epoch 15: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.2837 - val_accuracy: 0.7323 - val_loss: 0.8007\n",
      "Epoch 16/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9170 - loss: 0.2495\n",
      "Epoch 16: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9169 - loss: 0.2495 - val_accuracy: 0.7063 - val_loss: 0.8710\n",
      "Epoch 17/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9186 - loss: 0.2427\n",
      "Epoch 17: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9186 - loss: 0.2427 - val_accuracy: 0.7423 - val_loss: 0.8020\n",
      "Epoch 18/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9369 - loss: 0.1998\n",
      "Epoch 18: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.2001 - val_accuracy: 0.7532 - val_loss: 0.8273\n",
      "Epoch 19/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9394 - loss: 0.1871\n",
      "Epoch 19: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9393 - loss: 0.1873 - val_accuracy: 0.7303 - val_loss: 0.8790\n",
      "Epoch 20/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9426 - loss: 0.1784\n",
      "Epoch 20: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9425 - loss: 0.1785 - val_accuracy: 0.7293 - val_loss: 0.9072\n",
      "Epoch 21/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9506 - loss: 0.1586\n",
      "Epoch 21: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9505 - loss: 0.1588 - val_accuracy: 0.7213 - val_loss: 0.9251\n",
      "Epoch 22/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9564 - loss: 0.1414\n",
      "Epoch 22: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9564 - loss: 0.1414 - val_accuracy: 0.7383 - val_loss: 0.9097\n",
      "Epoch 23/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.1081\n",
      "Epoch 23: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9698 - loss: 0.1082 - val_accuracy: 0.7463 - val_loss: 1.0194\n",
      "Epoch 24/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9702 - loss: 0.1012\n",
      "Epoch 24: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9701 - loss: 0.1014 - val_accuracy: 0.7313 - val_loss: 1.0502\n",
      "Epoch 25/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9749 - loss: 0.0892\n",
      "Epoch 25: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9748 - loss: 0.0894 - val_accuracy: 0.7443 - val_loss: 1.0049\n",
      "Epoch 26/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9736 - loss: 0.0870\n",
      "Epoch 26: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9736 - loss: 0.0870 - val_accuracy: 0.7183 - val_loss: 1.0852\n",
      "Epoch 27/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9701 - loss: 0.0883\n",
      "Epoch 27: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9702 - loss: 0.0883 - val_accuracy: 0.7373 - val_loss: 1.0985\n",
      "Epoch 28/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0770\n",
      "Epoch 28: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0770 - val_accuracy: 0.7313 - val_loss: 1.0689\n",
      "Epoch 29/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0594\n",
      "Epoch 29: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0596 - val_accuracy: 0.7433 - val_loss: 1.1386\n",
      "Epoch 30/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0617\n",
      "Epoch 30: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0618 - val_accuracy: 0.7552 - val_loss: 1.2454\n",
      "Epoch 31/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.0612\n",
      "Epoch 31: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9800 - loss: 0.0613 - val_accuracy: 0.7133 - val_loss: 1.2454\n",
      "Epoch 32/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0568\n",
      "Epoch 32: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0567 - val_accuracy: 0.7273 - val_loss: 1.7130\n",
      "Epoch 33/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 0.0433\n",
      "Epoch 33: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 0.0433 - val_accuracy: 0.7363 - val_loss: 1.1975\n",
      "Epoch 34/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0494\n",
      "Epoch 34: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0495 - val_accuracy: 0.7423 - val_loss: 1.3542\n",
      "Epoch 35/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9788 - loss: 0.0637\n",
      "Epoch 35: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9788 - loss: 0.0636 - val_accuracy: 0.7383 - val_loss: 1.4633\n",
      "Epoch 36/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0365\n",
      "Epoch 36: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0365 - val_accuracy: 0.7313 - val_loss: 1.3605\n",
      "Epoch 37/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0490\n",
      "Epoch 37: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9841 - loss: 0.0491 - val_accuracy: 0.7233 - val_loss: 1.5942\n",
      "Epoch 38/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0444\n",
      "Epoch 38: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0445 - val_accuracy: 0.7343 - val_loss: 1.2810\n",
      "Epoch 39/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0465\n",
      "Epoch 39: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9855 - loss: 0.0465 - val_accuracy: 0.7163 - val_loss: 1.4468\n",
      "Epoch 40/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0441\n",
      "Epoch 40: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0441 - val_accuracy: 0.6833 - val_loss: 1.4756\n",
      "Epoch 41/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.0319\n",
      "Epoch 41: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0321 - val_accuracy: 0.7423 - val_loss: 1.6934\n",
      "Epoch 42/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0445\n",
      "Epoch 42: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0444 - val_accuracy: 0.7473 - val_loss: 1.5306\n",
      "Epoch 43/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0353\n",
      "Epoch 43: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0353 - val_accuracy: 0.7313 - val_loss: 1.4465\n",
      "Epoch 44/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0220\n",
      "Epoch 44: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0220 - val_accuracy: 0.7483 - val_loss: 1.3305\n",
      "Epoch 45/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0198\n",
      "Epoch 45: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9949 - loss: 0.0199 - val_accuracy: 0.7413 - val_loss: 1.4371\n",
      "Epoch 46/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0285\n",
      "Epoch 46: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0289 - val_accuracy: 0.7063 - val_loss: 2.2612\n",
      "Epoch 47/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0512\n",
      "Epoch 47: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0512 - val_accuracy: 0.7473 - val_loss: 1.4723\n",
      "Epoch 48/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0382\n",
      "Epoch 48: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0383 - val_accuracy: 0.7313 - val_loss: 1.4372\n",
      "Epoch 49/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9889 - loss: 0.0340\n",
      "Epoch 49: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0340 - val_accuracy: 0.7353 - val_loss: 1.4666\n",
      "Epoch 50/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0156\n",
      "Epoch 50: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0156 - val_accuracy: 0.7293 - val_loss: 1.5809\n",
      "Epoch 51/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0129\n",
      "Epoch 51: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0129 - val_accuracy: 0.7403 - val_loss: 1.4351\n",
      "Epoch 52/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0119\n",
      "Epoch 52: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9969 - loss: 0.0120 - val_accuracy: 0.7363 - val_loss: 1.8615\n",
      "Epoch 53/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0466\n",
      "Epoch 53: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9839 - loss: 0.0466 - val_accuracy: 0.7532 - val_loss: 1.4718\n",
      "Epoch 54/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.0455\n",
      "Epoch 54: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9829 - loss: 0.0454 - val_accuracy: 0.7403 - val_loss: 1.5450\n",
      "Epoch 55/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0186\n",
      "Epoch 55: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0187 - val_accuracy: 0.7453 - val_loss: 1.5334\n",
      "Epoch 56/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0406\n",
      "Epoch 56: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0405 - val_accuracy: 0.7233 - val_loss: 1.6155\n",
      "Epoch 57/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0240\n",
      "Epoch 57: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0240 - val_accuracy: 0.7283 - val_loss: 1.8959\n",
      "Epoch 58/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0328\n",
      "Epoch 58: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9907 - loss: 0.0327 - val_accuracy: 0.7473 - val_loss: 1.4151\n",
      "Epoch 59/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0130\n",
      "Epoch 59: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9966 - loss: 0.0130 - val_accuracy: 0.7403 - val_loss: 1.5789\n",
      "Epoch 60/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0169\n",
      "Epoch 60: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0169 - val_accuracy: 0.7413 - val_loss: 1.6441\n",
      "Epoch 61/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0290\n",
      "Epoch 61: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9918 - loss: 0.0290 - val_accuracy: 0.7433 - val_loss: 1.8327\n",
      "Epoch 62/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0317\n",
      "Epoch 62: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0318 - val_accuracy: 0.7313 - val_loss: 1.7003\n",
      "Epoch 63/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0253\n",
      "Epoch 63: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9905 - loss: 0.0253 - val_accuracy: 0.7343 - val_loss: 1.7431\n",
      "Epoch 64/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0209\n",
      "Epoch 64: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9939 - loss: 0.0209 - val_accuracy: 0.7353 - val_loss: 1.6288\n",
      "Epoch 65/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0147\n",
      "Epoch 65: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0148 - val_accuracy: 0.7253 - val_loss: 1.6116\n",
      "Epoch 66/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0381\n",
      "Epoch 66: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0382 - val_accuracy: 0.7453 - val_loss: 1.6814\n",
      "Epoch 67/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0288\n",
      "Epoch 67: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0287 - val_accuracy: 0.7333 - val_loss: 1.5973\n",
      "Epoch 68/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9943 - loss: 0.0206\n",
      "Epoch 68: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0206 - val_accuracy: 0.7363 - val_loss: 1.6115\n",
      "Epoch 69/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0097\n",
      "Epoch 69: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0097 - val_accuracy: 0.7572 - val_loss: 1.6825\n",
      "Epoch 70/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0141\n",
      "Epoch 70: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9958 - loss: 0.0141 - val_accuracy: 0.6144 - val_loss: 2.8734\n",
      "Epoch 71/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0391\n",
      "Epoch 71: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0391 - val_accuracy: 0.7612 - val_loss: 1.7077\n",
      "Epoch 72/200\n",
      "\u001b[1m274/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0214\n",
      "Epoch 72: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0213 - val_accuracy: 0.7393 - val_loss: 1.7150\n",
      "Epoch 73/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0146\n",
      "Epoch 73: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0148 - val_accuracy: 0.7253 - val_loss: 1.8210\n",
      "Epoch 74/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0268\n",
      "Epoch 74: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0268 - val_accuracy: 0.7453 - val_loss: 1.6645\n",
      "Epoch 75/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0153\n",
      "Epoch 75: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9956 - loss: 0.0153 - val_accuracy: 0.7133 - val_loss: 1.6919\n",
      "Epoch 76/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0172\n",
      "Epoch 76: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9936 - loss: 0.0172 - val_accuracy: 0.7373 - val_loss: 1.7229\n",
      "Epoch 77/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0115\n",
      "Epoch 77: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9967 - loss: 0.0115 - val_accuracy: 0.7233 - val_loss: 1.7507\n",
      "Epoch 78/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9896 - loss: 0.0357\n",
      "Epoch 78: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0356 - val_accuracy: 0.7083 - val_loss: 1.7585\n",
      "Epoch 79/200\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0280\n",
      "Epoch 79: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0280 - val_accuracy: 0.7233 - val_loss: 1.7761\n",
      "Epoch 80/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0121\n",
      "Epoch 80: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0121 - val_accuracy: 0.7323 - val_loss: 1.7228\n",
      "Epoch 81/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0103\n",
      "Epoch 81: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0103 - val_accuracy: 0.7483 - val_loss: 1.7944\n",
      "Epoch 82/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0062\n",
      "Epoch 82: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9989 - loss: 0.0062 - val_accuracy: 0.7373 - val_loss: 1.8953\n",
      "Epoch 83/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9924 - loss: 0.0245\n",
      "Epoch 83: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0250 - val_accuracy: 0.7173 - val_loss: 1.8258\n",
      "Epoch 84/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0370\n",
      "Epoch 84: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0369 - val_accuracy: 0.7073 - val_loss: 1.9578\n",
      "Epoch 85/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0174\n",
      "Epoch 85: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0173 - val_accuracy: 0.7323 - val_loss: 1.8510\n",
      "Epoch 86/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0075\n",
      "Epoch 86: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9982 - loss: 0.0075 - val_accuracy: 0.7512 - val_loss: 1.7334\n",
      "Epoch 87/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0034\n",
      "Epoch 87: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.7502 - val_loss: 1.7964\n",
      "Epoch 88/200\n",
      "\u001b[1m275/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0118\n",
      "Epoch 88: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0119 - val_accuracy: 0.7173 - val_loss: 1.7915\n",
      "Epoch 89/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9978 - loss: 0.0094\n",
      "Epoch 89: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9977 - loss: 0.0095 - val_accuracy: 0.7313 - val_loss: 1.8720\n",
      "Epoch 90/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0307\n",
      "Epoch 90: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0307 - val_accuracy: 0.6783 - val_loss: 2.0909\n",
      "Epoch 91/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0262\n",
      "Epoch 91: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9906 - loss: 0.0261 - val_accuracy: 0.7453 - val_loss: 1.7946\n",
      "Epoch 92/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0187\n",
      "Epoch 92: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0187 - val_accuracy: 0.7423 - val_loss: 1.7209\n",
      "Epoch 93/200\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0035\n",
      "Epoch 93: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9998 - loss: 0.0035 - val_accuracy: 0.7453 - val_loss: 1.8134\n",
      "Epoch 94/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0028\n",
      "Epoch 94: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9997 - loss: 0.0029 - val_accuracy: 0.7443 - val_loss: 1.8594\n",
      "Epoch 95/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0228\n",
      "Epoch 95: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9917 - loss: 0.0228 - val_accuracy: 0.7223 - val_loss: 1.9000\n",
      "Epoch 96/200\n",
      "\u001b[1m279/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0275\n",
      "Epoch 96: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0275 - val_accuracy: 0.7473 - val_loss: 1.7407\n",
      "Epoch 97/200\n",
      "\u001b[1m277/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0134\n",
      "Epoch 97: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9961 - loss: 0.0135 - val_accuracy: 0.7073 - val_loss: 1.8979\n",
      "Epoch 98/200\n",
      "\u001b[1m280/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0163\n",
      "Epoch 98: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0163 - val_accuracy: 0.7303 - val_loss: 1.9097\n",
      "Epoch 99/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0158\n",
      "Epoch 99: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9950 - loss: 0.0158 - val_accuracy: 0.7582 - val_loss: 1.8478\n",
      "Epoch 100/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0149\n",
      "Epoch 100: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0149 - val_accuracy: 0.7502 - val_loss: 1.7739\n",
      "Epoch 101/200\n",
      "\u001b[1m278/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0059\n",
      "Epoch 101: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0059 - val_accuracy: 0.7433 - val_loss: 1.8121\n",
      "Epoch 102/200\n",
      "\u001b[1m276/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0081\n",
      "Epoch 102: val_loss did not improve from 0.68361\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9974 - loss: 0.0082 - val_accuracy: 0.7313 - val_loss: 2.2219\n",
      "Epoch 103/200\n",
      "\u001b[1m197/282\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0269"
     ]
    }
   ],
   "source": [
    "# Define lists to store evaluation metrics\n",
    "acc_scores = []\n",
    "auc_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "mcc_scores = []\n",
    "loss_scores = []\n",
    "cm_list = []\n",
    "y_pred_list = []\n",
    "history_list=[]\n",
    "n_splits=10\n",
    "# Define Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "print(\"training model\")\n",
    "i=0\n",
    "for train_index, test_index in skf.split(X_resize, y):\n",
    "    \n",
    "    X_train, X_test = X_resize[train_index], X_resize[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    acc, auc_score, precision, recall, f1, mcc, loss, cm, y_pred,history = train_evaluate_model(X_train, y_train, X_test, y_test,i)\n",
    "    \n",
    "    acc_scores.append(acc)\n",
    "    auc_scores.append(auc_score)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    mcc_scores.append(mcc)\n",
    "    loss_scores.append(loss)\n",
    "    cm_list.append(cm)\n",
    "    y_pred_list.append(y_pred)\n",
    "    history_list.append(history)\n",
    "    print(f\"model{i} trained\")\n",
    "    i+=1\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "mean_acc = np.mean(acc_scores)\n",
    "std_acc = np.std(acc_scores)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "\n",
    "mean_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "\n",
    "mean_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "mean_mcc = np.mean(mcc_scores)\n",
    "std_mcc = np.std(mcc_scores)\n",
    "\n",
    "mean_loss = np.mean(loss_scores)\n",
    "std_loss = np.std(loss_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics per Model:\n",
      "     Model  Accuracy       AUC  Precision    Recall  F1 Score       MCC  \\\n",
      "0  Model 0  0.730904  0.907976   0.723946  0.730904  0.715673  0.463591   \n",
      "1  Model 1  0.740389  0.896439   0.733883  0.740389  0.733868  0.486779   \n",
      "2  Model 2  0.745382  0.909781   0.730433  0.745382  0.733843  0.488955   \n",
      "3  Model 3  0.736395  0.890267   0.705984  0.736395  0.713863  0.446930   \n",
      "4  Model 4  0.705941  0.884838   0.720262  0.705941  0.709737  0.450120   \n",
      "\n",
      "       Loss  \n",
      "0  2.124256  \n",
      "1  1.900169  \n",
      "2  2.002961  \n",
      "3  2.421261  \n",
      "4  2.303769  \n",
      "Performance Metrics of all models:\n",
      "      Metric      Mean   Std Dev\n",
      "0   Accuracy  0.731802  0.013776\n",
      "1        AUC  0.897860  0.009733\n",
      "2  Precision  0.722902  0.009712\n",
      "3     Recall  0.731802  0.013776\n",
      "4   F1 Score  0.721397  0.010353\n",
      "5        MCC  0.467275  0.017732\n",
      "6       Loss  2.150483  0.190749\n"
     ]
    }
   ],
   "source": [
    "results_per_model = pd.DataFrame({\n",
    "    \"Model\": [f\"Model {i}\" for i in range(n_splits)],\n",
    "    \"Accuracy\": acc_scores,\n",
    "    \"AUC\": auc_scores,\n",
    "    \"Precision\": precision_scores,\n",
    "    \"Recall\": recall_scores,\n",
    "    \"F1 Score\": f1_scores,\n",
    "    \"MCC\": mcc_scores,\n",
    "    \"Loss\": loss_scores\n",
    "})\n",
    "print(\"Performance Metrics per Model:\")\n",
    "print(results_per_model)\n",
    "\n",
    "# Display results in a table\n",
    "results_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1 Score\", \"MCC\", \"Loss\"],\n",
    "    \"Mean\": [mean_acc, mean_auc, mean_precision, mean_recall, mean_f1, mean_mcc, mean_loss],\n",
    "    \"Std Dev\": [std_acc, std_auc, std_precision, std_recall, std_f1, std_mcc, std_loss]\n",
    "})\n",
    "\n",
    "print(\"Performance Metrics of all models:\")\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model : 2\n",
      "\n",
      "Confusion Matrix of the Best Model (Maximized AUC):\n",
      "[[  22   13   16    1    5    1    7]\n",
      " [   6   47   26    1   18    1    4]\n",
      " [  14   10  105    0   70    1   20]\n",
      " [   1    7    2    2   10    0    1]\n",
      " [   9    5   53    0 1223    1   50]\n",
      " [   0    0    0    0    9   17    3]\n",
      " [   4    4   40    0   97    0   77]]\n",
      "Lengths of y_test and best_y_pred are equal.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix of the best model\n",
    "best_auc_index = np.argmax(auc_scores)\n",
    "print(\"Best Model : \" + str(best_auc_index))\n",
    "best_cm = cm_list[best_auc_index]\n",
    "print(\"\\nConfusion Matrix of the Best Model (Maximized AUC):\")\n",
    "print(best_cm)\n",
    "\n",
    "#Best prediction\n",
    "best_y_pred = y_pred_list[best_auc_index]\n",
    "\n",
    "# Ensure that y_test and best_y_pred have the same length\n",
    "if len(y_test) > len(best_y_pred):\n",
    "    y_test = y_test[:len(best_y_pred)]\n",
    "    print(\"Lengths of y_test and best_y_pred are not equal. Resized y_test to match the length of best_y_pred.\")\n",
    "elif len(best_y_pred) > len(y_test):\n",
    "    best_y_pred = best_y_pred[:len(y_test)]\n",
    "    print(\"Lengths of y_test and best_y_pred are not equal. Resized best_y_pred to match the length of y_test.\")\n",
    "elif len(y_test) == len(best_y_pred):\n",
    "    print(\"Lengths of y_test and best_y_pred are equal.\")\n",
    "# Now, you can plot the curves\n",
    "plot_curves(y_test, best_y_pred, n_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a3966be3d0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "history=history_list[best_auc_index]\n",
    "# Plot mean loss vs epochs for training and validation\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.title('Mean Loss vs Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_curves_v2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_curves_v2\u001b[49m(y_test, best_y_pred, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_curves_v2' is not defined"
     ]
    }
   ],
   "source": [
    "plot_curves_v2(y_test, best_y_pred, n_classes=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybersecurity-Z7yOgMbu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
