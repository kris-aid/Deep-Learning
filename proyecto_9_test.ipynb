{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saidm\\Documents\\Universidad\\9no_Semestre\\Data Mining\\Deberes\\Deep-Learning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>183</td>\n",
       "      <td>165</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>165</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>208</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>208</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>206</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>121</td>\n",
       "      <td>104</td>\n",
       "      <td>103</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>132</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>167</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>175</td>\n",
       "      <td>156</td>\n",
       "      <td>160</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>181</td>\n",
       "      <td>178</td>\n",
       "      <td>181</td>\n",
       "      <td>159</td>\n",
       "      <td>153</td>\n",
       "      <td>172</td>\n",
       "      <td>151</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>160</td>\n",
       "      <td>124</td>\n",
       "      <td>146</td>\n",
       "      <td>164</td>\n",
       "      <td>131</td>\n",
       "      <td>152</td>\n",
       "      <td>167</td>\n",
       "      <td>127</td>\n",
       "      <td>146</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>162</td>\n",
       "      <td>167</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>162</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>175</td>\n",
       "      <td>142</td>\n",
       "      <td>121</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>134</td>\n",
       "      <td>181</td>\n",
       "      <td>150</td>\n",
       "      <td>133</td>\n",
       "      <td>178</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>174</td>\n",
       "      <td>137</td>\n",
       "      <td>125</td>\n",
       "      <td>175</td>\n",
       "      <td>139</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "10010        183        165        181        182        165        180   \n",
       "10011          2          3          1         38         33         32   \n",
       "10012        132        118        118        167        149        149   \n",
       "10013        160        124        146        164        131        152   \n",
       "10014        175        142        121        181        150        134   \n",
       "\n",
       "       pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2343  pixel2344  \\\n",
       "10010        184        166        182        188  ...        208        185   \n",
       "10011        121        104        103        132  ...         96         79   \n",
       "10012        175        156        160        184  ...        204        181   \n",
       "10013        167        127        146        169  ...        185        162   \n",
       "10014        181        150        133        178  ...        159         79   \n",
       "\n",
       "       pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  \\\n",
       "10010        187        208        186        186        206        187   \n",
       "10011         76         24         23         21          3          4   \n",
       "10012        178        181        159        153        172        151   \n",
       "10013        167        184        157        166        185        162   \n",
       "10014         82        174        137        125        175        139   \n",
       "\n",
       "       pixel2351  label  \n",
       "10010        189      0  \n",
       "10011          1      0  \n",
       "10012        145      0  \n",
       "10013        172      0  \n",
       "10014        126      6  \n",
       "\n",
       "[5 rows x 2353 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfpath=\"hmnist_28_28_RGB.csv\"\n",
    "df=pd.read_csv(dfpath)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10015, 28, 28, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting 'y' column\n",
    "y = df['label']\n",
    "\n",
    "# Extracting 'X' DataFrame without the 'label' column\n",
    "X = df.drop(columns=['label'])\n",
    "X_resize=np.array([i.reshape(28,28,3) for i in np.array(X)  ])\n",
    "X_resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, roc_curve, auc, precision_recall_curve,roc_curve, roc_auc_score\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, BatchNormalization,ReLU,Add,Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input, Model\n",
    "#from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "\n",
    "# Define your CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "\n",
    "# Define your CNN model\n",
    "def create_model():\n",
    "    model_cnn = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3,3), input_shape=(28, 28, 3), activation='relu', padding='same'),\n",
    "        MaxPool2D(pool_size=(2,2), strides=2),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "        MaxPool2D(pool_size=(2,2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(units=7, activation='softmax')\n",
    "    ])\n",
    "    return model_cnn\n",
    "\n",
    "def create_model_2():\n",
    "    model_cnn = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPool2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(7, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model_cnn\n",
    "def create_resnet_model():\n",
    "    \n",
    "    def residual_block(x, filters, kernel_size=3, strides=2):\n",
    "        # First convolutional layer\n",
    "        y = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = ReLU()(y)\n",
    "\n",
    "        # Second convolutional layer\n",
    "        y = Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same')(y)\n",
    "        y = BatchNormalization()(y)\n",
    "\n",
    "        # Shortcut connection\n",
    "        if strides != 1:\n",
    "            x = Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "        # Add the shortcut and residual\n",
    "        y = Add()([x, y])\n",
    "        y = ReLU()(y)\n",
    "        return y\n",
    "    inputs = Input(shape=(28, 28, 3))\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPool2D((2, 2))(x)\n",
    "\n",
    "    # First residual block\n",
    "    x = residual_block(x, 64, strides=4)\n",
    "    # Second residual block\n",
    "    x = residual_block(x, 64)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(7, activation='softmax')(x)\n",
    "\n",
    "    model_resnet = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model_resnet\n",
    "\n",
    "# Define function to train and evaluate model\n",
    "def train_evaluate_model(X_train, y_train, X_test, y_test,num_model):\n",
    "\n",
    "    model = create_resnet_model()\n",
    "    checkpoint_path = f\"model_{num_model}_checkpoint/cp.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    \n",
    "    cp_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.save(checkpoint_dir+'/model.h5')\n",
    "    history = model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), callbacks=[cp_callback])\n",
    "    #model=load_model(checkpoint_dir+'/model.h5')\n",
    "    eval_metrics = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    auc_score= roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "    acc = accuracy_score(y_test, y_pred_classes)\n",
    "    precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
    "    mcc = matthews_corrcoef(y_test, y_pred_classes)\n",
    "    loss = eval_metrics[0]\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "    return acc, auc_score, precision, recall, f1, mcc, loss, cm, y_pred,history\n",
    "\n",
    "\n",
    "\n",
    "# Define function to plot AUC-ROC and Precision-Recall curves\n",
    "def plot_curves_binary(y_true, y_pred_prob):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_prob[:, 1])\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # Plot AUC-ROC curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Plot Precision-Recall curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define function to plot AUC-ROC and Precision-Recall curves for multiclass\n",
    "from itertools import cycle\n",
    "from sklearn.calibration import label_binarize\n",
    "def plot_curves(y_true, y_pred_prob, n_classes):\n",
    "        # Binarize the output\n",
    "        y_true_bin = label_binarize(y_true, classes=[0, 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "        # Compute ROC curve and ROC area for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Compute micro-average ROC curve and ROC area\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_prob.ravel())\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "        # Compute Precision-Recall curve for each class\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        for i in range(n_classes):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot ROC curve for each class\n",
    "        plt.subplot(1, 2, 1)\n",
    "        colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'green', 'purple', 'yellow'])\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2, label='ROC curve of class {0} (AUC = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "        # Plot Precision-Recall curve for each class\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(recall[i], precision[i], color=color, lw=2, label='Precision-Recall curve of class {0}'.format(i))\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another function. First we calculate the roc_auc_score for each class and then we calculate the mean of all the scores. and then we plot the roc curve\n",
    "# we do the same for the precision-recall curve\n",
    "def plot_curves_v2(y_true, y_pred_prob, n_classes):\n",
    "    # Binarize the output\n",
    "    y_true_bin = label_binarize(y_true, classes=[0, 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_pred_prob.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Compute Precision-Recall curve for each class\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    \n",
    "    # Compute micro-average Precision-Recall curve and area\n",
    "    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true_bin.ravel(), y_pred_prob.ravel())\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "   #calculate the mean of the roc_auc_score\n",
    "    all_auc = np.mean(list(roc_auc.values()))\n",
    "    # Plot all_auc score\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % all_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic mean AUC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Plot all_precision-recall score\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall[\"micro\"], precision[\"micro\"], color='green', lw=2, label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve mean Precision and Recall')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saidm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cybersecurity-Z7yOgMbu-py3.11\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - ETA: 0s - loss: 0.9380 - accuracy: 1.2481e-04\n",
      "Epoch 1: val_loss improved from inf to 0.88355, saving model to model_0_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 5s 10ms/step - loss: 0.9380 - accuracy: 1.2481e-04 - val_loss: 0.8836 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.8048 - accuracy: 0.0023\n",
      "Epoch 2: val_loss improved from 0.88355 to 0.80779, saving model to model_0_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.8049 - accuracy: 0.0025 - val_loss: 0.8078 - val_accuracy: 0.0130\n",
      "Epoch 3/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.7394 - accuracy: 0.0106\n",
      "Epoch 3: val_loss improved from 0.80779 to 0.77494, saving model to model_0_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.7403 - accuracy: 0.0104 - val_loss: 0.7749 - val_accuracy: 0.0070\n",
      "Epoch 4/200\n",
      "243/251 [============================>.] - ETA: 0s - loss: 0.6876 - accuracy: 0.0197\n",
      "Epoch 4: val_loss did not improve from 0.77494\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.6900 - accuracy: 0.0198 - val_loss: 0.7771 - val_accuracy: 0.0145\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.0200\n",
      "Epoch 5: val_loss did not improve from 0.77494\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.6446 - accuracy: 0.0200 - val_loss: 0.8304 - val_accuracy: 0.0315\n",
      "Epoch 6/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.6044 - accuracy: 0.0224\n",
      "Epoch 6: val_loss improved from 0.77494 to 0.71873, saving model to model_0_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.6033 - accuracy: 0.0222 - val_loss: 0.7187 - val_accuracy: 0.0180\n",
      "Epoch 7/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.5664 - accuracy: 0.0226\n",
      "Epoch 7: val_loss did not improve from 0.71873\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.5655 - accuracy: 0.0225 - val_loss: 0.7676 - val_accuracy: 0.0110\n",
      "Epoch 8/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.5268 - accuracy: 0.0261\n",
      "Epoch 8: val_loss did not improve from 0.71873\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.5267 - accuracy: 0.0262 - val_loss: 0.7616 - val_accuracy: 0.0110\n",
      "Epoch 9/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.4949 - accuracy: 0.0259\n",
      "Epoch 9: val_loss improved from 0.71873 to 0.70990, saving model to model_0_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.4954 - accuracy: 0.0255 - val_loss: 0.7099 - val_accuracy: 0.0280\n",
      "Epoch 10/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.0272\n",
      "Epoch 10: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.4572 - accuracy: 0.0273 - val_loss: 0.8777 - val_accuracy: 0.0250\n",
      "Epoch 11/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.4255 - accuracy: 0.0290\n",
      "Epoch 11: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.4251 - accuracy: 0.0290 - val_loss: 0.7556 - val_accuracy: 0.0414\n",
      "Epoch 12/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.3965 - accuracy: 0.0291\n",
      "Epoch 12: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.3952 - accuracy: 0.0290 - val_loss: 0.7815 - val_accuracy: 0.0509\n",
      "Epoch 13/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.3618 - accuracy: 0.0289\n",
      "Epoch 13: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.3620 - accuracy: 0.0290 - val_loss: 0.8195 - val_accuracy: 0.0215\n",
      "Epoch 14/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.3320 - accuracy: 0.0295\n",
      "Epoch 14: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 7ms/step - loss: 0.3313 - accuracy: 0.0295 - val_loss: 1.1224 - val_accuracy: 0.0150\n",
      "Epoch 15/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.0308\n",
      "Epoch 15: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.3064 - accuracy: 0.0308 - val_loss: 0.9053 - val_accuracy: 0.0494\n",
      "Epoch 16/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.0310\n",
      "Epoch 16: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.2743 - accuracy: 0.0312 - val_loss: 0.9270 - val_accuracy: 0.0569\n",
      "Epoch 17/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.0305\n",
      "Epoch 17: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.2623 - accuracy: 0.0303 - val_loss: 0.9132 - val_accuracy: 0.0349\n",
      "Epoch 18/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.2274 - accuracy: 0.0323\n",
      "Epoch 18: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.2282 - accuracy: 0.0323 - val_loss: 0.8514 - val_accuracy: 0.0135\n",
      "Epoch 19/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.0316\n",
      "Epoch 19: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.2144 - accuracy: 0.0316 - val_loss: 0.8558 - val_accuracy: 0.0235\n",
      "Epoch 20/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.1862 - accuracy: 0.0314\n",
      "Epoch 20: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.1870 - accuracy: 0.0316 - val_loss: 1.0449 - val_accuracy: 0.0150\n",
      "Epoch 21/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.0316\n",
      "Epoch 21: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.1767 - accuracy: 0.0316 - val_loss: 1.0609 - val_accuracy: 0.0330\n",
      "Epoch 22/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.1521 - accuracy: 0.0320\n",
      "Epoch 22: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.1520 - accuracy: 0.0320 - val_loss: 0.9569 - val_accuracy: 0.0315\n",
      "Epoch 23/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.1378 - accuracy: 0.0311\n",
      "Epoch 23: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.1378 - accuracy: 0.0312 - val_loss: 1.0978 - val_accuracy: 0.0364\n",
      "Epoch 24/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.0322\n",
      "Epoch 24: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.1304 - accuracy: 0.0323 - val_loss: 1.0530 - val_accuracy: 0.0180\n",
      "Epoch 25/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.0314\n",
      "Epoch 25: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.1184 - accuracy: 0.0315 - val_loss: 1.0481 - val_accuracy: 0.0175\n",
      "Epoch 26/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.1103 - accuracy: 0.0326\n",
      "Epoch 26: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.1100 - accuracy: 0.0327 - val_loss: 1.1757 - val_accuracy: 0.0225\n",
      "Epoch 27/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.0325\n",
      "Epoch 27: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0970 - accuracy: 0.0325 - val_loss: 1.0991 - val_accuracy: 0.0175\n",
      "Epoch 28/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.0900 - accuracy: 0.0325\n",
      "Epoch 28: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0908 - accuracy: 0.0323 - val_loss: 1.1644 - val_accuracy: 0.0170\n",
      "Epoch 29/200\n",
      "242/251 [===========================>..] - ETA: 0s - loss: 0.0811 - accuracy: 0.0322\n",
      "Epoch 29: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0815 - accuracy: 0.0323 - val_loss: 1.1995 - val_accuracy: 0.0349\n",
      "Epoch 30/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.0322\n",
      "Epoch 30: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0654 - accuracy: 0.0322 - val_loss: 1.7532 - val_accuracy: 0.0075\n",
      "Epoch 31/200\n",
      "242/251 [===========================>..] - ETA: 0s - loss: 0.0571 - accuracy: 0.0334\n",
      "Epoch 31: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0569 - accuracy: 0.0332 - val_loss: 1.2537 - val_accuracy: 0.0270\n",
      "Epoch 32/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0690 - accuracy: 0.0316\n",
      "Epoch 32: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0692 - accuracy: 0.0316 - val_loss: 1.4523 - val_accuracy: 0.0514\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.0322\n",
      "Epoch 33: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0700 - accuracy: 0.0322 - val_loss: 1.2798 - val_accuracy: 0.0245\n",
      "Epoch 34/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.0318\n",
      "Epoch 34: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0498 - accuracy: 0.0318 - val_loss: 1.7671 - val_accuracy: 0.0369\n",
      "Epoch 35/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0643 - accuracy: 0.0329\n",
      "Epoch 35: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0657 - accuracy: 0.0328 - val_loss: 1.3384 - val_accuracy: 0.0584\n",
      "Epoch 36/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0804 - accuracy: 0.0321\n",
      "Epoch 36: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0808 - accuracy: 0.0321 - val_loss: 1.4988 - val_accuracy: 0.0334\n",
      "Epoch 37/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.0325\n",
      "Epoch 37: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0452 - accuracy: 0.0327 - val_loss: 1.4223 - val_accuracy: 0.0330\n",
      "Epoch 38/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.0328\n",
      "Epoch 38: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0294 - accuracy: 0.0325 - val_loss: 1.3548 - val_accuracy: 0.0359\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 0.0326\n",
      "Epoch 39: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0372 - accuracy: 0.0326 - val_loss: 1.5419 - val_accuracy: 0.0275\n",
      "Epoch 40/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.0328\n",
      "Epoch 40: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0591 - accuracy: 0.0328 - val_loss: 1.5318 - val_accuracy: 0.0095\n",
      "Epoch 41/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.0324\n",
      "Epoch 41: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0317 - accuracy: 0.0325 - val_loss: 1.4462 - val_accuracy: 0.0180\n",
      "Epoch 42/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.0320\n",
      "Epoch 42: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0389 - accuracy: 0.0323 - val_loss: 1.7118 - val_accuracy: 0.0574\n",
      "Epoch 43/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.0331\n",
      "Epoch 43: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0457 - accuracy: 0.0328 - val_loss: 1.5845 - val_accuracy: 0.0140\n",
      "Epoch 44/200\n",
      "242/251 [===========================>..] - ETA: 0s - loss: 0.0452 - accuracy: 0.0328\n",
      "Epoch 44: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0457 - accuracy: 0.0325 - val_loss: 1.5415 - val_accuracy: 0.0070\n",
      "Epoch 45/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.0328\n",
      "Epoch 45: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0343 - accuracy: 0.0326 - val_loss: 1.5052 - val_accuracy: 0.0334\n",
      "Epoch 46/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.0320\n",
      "Epoch 46: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0316 - accuracy: 0.0325 - val_loss: 1.4353 - val_accuracy: 0.0090\n",
      "Epoch 47/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.0330\n",
      "Epoch 47: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0470 - accuracy: 0.0331 - val_loss: 1.5545 - val_accuracy: 0.0280\n",
      "Epoch 48/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.0327\n",
      "Epoch 48: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0272 - accuracy: 0.0327 - val_loss: 1.7888 - val_accuracy: 0.0175\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.0328\n",
      "Epoch 49: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0297 - accuracy: 0.0328 - val_loss: 1.5871 - val_accuracy: 0.0290\n",
      "Epoch 50/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.0323\n",
      "Epoch 50: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0247 - accuracy: 0.0328 - val_loss: 1.7916 - val_accuracy: 0.0230\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.0330\n",
      "Epoch 51: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0547 - accuracy: 0.0330 - val_loss: 1.6907 - val_accuracy: 0.0165\n",
      "Epoch 52/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.0320\n",
      "Epoch 52: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0367 - accuracy: 0.0321 - val_loss: 1.6518 - val_accuracy: 0.0544\n",
      "Epoch 53/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.0328\n",
      "Epoch 53: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0189 - accuracy: 0.0330 - val_loss: 1.5360 - val_accuracy: 0.0315\n",
      "Epoch 54/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.0328\n",
      "Epoch 54: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0188 - accuracy: 0.0325 - val_loss: 1.6949 - val_accuracy: 0.0399\n",
      "Epoch 55/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.0334\n",
      "Epoch 55: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0249 - accuracy: 0.0330 - val_loss: 1.6716 - val_accuracy: 0.0255\n",
      "Epoch 56/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.0329\n",
      "Epoch 56: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0459 - accuracy: 0.0327 - val_loss: 1.5581 - val_accuracy: 0.0205\n",
      "Epoch 57/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.0327\n",
      "Epoch 57: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0280 - accuracy: 0.0328 - val_loss: 1.7379 - val_accuracy: 0.0155\n",
      "Epoch 58/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.0326\n",
      "Epoch 58: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0212 - accuracy: 0.0326 - val_loss: 1.6281 - val_accuracy: 0.0354\n",
      "Epoch 59/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.0328\n",
      "Epoch 59: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0199 - accuracy: 0.0327 - val_loss: 1.7607 - val_accuracy: 0.0155\n",
      "Epoch 60/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.0324\n",
      "Epoch 60: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0233 - accuracy: 0.0325 - val_loss: 1.6499 - val_accuracy: 0.0250\n",
      "Epoch 61/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.0328\n",
      "Epoch 61: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0292 - accuracy: 0.0327 - val_loss: 1.6729 - val_accuracy: 0.0155\n",
      "Epoch 62/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.0325\n",
      "Epoch 62: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0121 - accuracy: 0.0326 - val_loss: 2.0872 - val_accuracy: 0.0704\n",
      "Epoch 63/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.0321\n",
      "Epoch 63: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0320 - accuracy: 0.0327 - val_loss: 2.8699 - val_accuracy: 0.0150\n",
      "Epoch 64/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.0331\n",
      "Epoch 64: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0508 - accuracy: 0.0331 - val_loss: 1.6920 - val_accuracy: 0.0250\n",
      "Epoch 65/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.0329\n",
      "Epoch 65: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0280 - accuracy: 0.0327 - val_loss: 1.6276 - val_accuracy: 0.0165\n",
      "Epoch 66/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.0329\n",
      "Epoch 66: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0217 - accuracy: 0.0327 - val_loss: 1.8907 - val_accuracy: 0.0070\n",
      "Epoch 67/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.0330\n",
      "Epoch 67: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0122 - accuracy: 0.0330 - val_loss: 1.7430 - val_accuracy: 0.0230\n",
      "Epoch 68/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.0329\n",
      "Epoch 68: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0277 - accuracy: 0.0326 - val_loss: 1.6260 - val_accuracy: 0.0359\n",
      "Epoch 69/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.0329\n",
      "Epoch 69: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0273 - accuracy: 0.0332 - val_loss: 1.9276 - val_accuracy: 0.0359\n",
      "Epoch 70/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.0326\n",
      "Epoch 70: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0318 - accuracy: 0.0327 - val_loss: 2.0545 - val_accuracy: 0.0359\n",
      "Epoch 71/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.0328\n",
      "Epoch 71: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0148 - accuracy: 0.0326 - val_loss: 1.7265 - val_accuracy: 0.0339\n",
      "Epoch 72/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.0328\n",
      "Epoch 72: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0127 - accuracy: 0.0327 - val_loss: 1.7511 - val_accuracy: 0.0235\n",
      "Epoch 73/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.0328\n",
      "Epoch 73: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0096 - accuracy: 0.0328 - val_loss: 1.7439 - val_accuracy: 0.0220\n",
      "Epoch 74/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.0323\n",
      "Epoch 74: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0317 - accuracy: 0.0323 - val_loss: 2.0521 - val_accuracy: 0.0330\n",
      "Epoch 75/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.0329\n",
      "Epoch 75: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0376 - accuracy: 0.0330 - val_loss: 1.8964 - val_accuracy: 0.0334\n",
      "Epoch 76/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.0328\n",
      "Epoch 76: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.0151 - accuracy: 0.0330 - val_loss: 2.2012 - val_accuracy: 0.0130\n",
      "Epoch 77/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.0320\n",
      "Epoch 77: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0131 - accuracy: 0.0326 - val_loss: 1.6475 - val_accuracy: 0.0275\n",
      "Epoch 78/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.0326\n",
      "Epoch 78: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0315 - accuracy: 0.0326 - val_loss: 1.6742 - val_accuracy: 0.0225\n",
      "Epoch 79/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.0321\n",
      "Epoch 79: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 0.0302 - accuracy: 0.0323 - val_loss: 1.7243 - val_accuracy: 0.0295\n",
      "Epoch 80/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.0330\n",
      "Epoch 80: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 0.0067 - accuracy: 0.0328 - val_loss: 1.7011 - val_accuracy: 0.0285\n",
      "Epoch 81/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.0326\n",
      "Epoch 81: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0023 - accuracy: 0.0327 - val_loss: 1.7001 - val_accuracy: 0.0344\n",
      "Epoch 82/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.0327\n",
      "Epoch 82: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0039 - accuracy: 0.0327 - val_loss: 1.8416 - val_accuracy: 0.0305\n",
      "Epoch 83/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.0324\n",
      "Epoch 83: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0476 - accuracy: 0.0323 - val_loss: 2.0695 - val_accuracy: 0.0115\n",
      "Epoch 84/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.0329\n",
      "Epoch 84: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0366 - accuracy: 0.0328 - val_loss: 1.9496 - val_accuracy: 0.0160\n",
      "Epoch 85/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.0329\n",
      "Epoch 85: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0449 - accuracy: 0.0326 - val_loss: 1.7790 - val_accuracy: 0.0384\n",
      "Epoch 86/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.0324\n",
      "Epoch 86: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0134 - accuracy: 0.0326 - val_loss: 1.6393 - val_accuracy: 0.0305\n",
      "Epoch 87/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.0324\n",
      "Epoch 87: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0049 - accuracy: 0.0327 - val_loss: 1.7107 - val_accuracy: 0.0175\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.0327\n",
      "Epoch 88: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0027 - accuracy: 0.0327 - val_loss: 1.7895 - val_accuracy: 0.0359\n",
      "Epoch 89/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.0326\n",
      "Epoch 89: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0027 - accuracy: 0.0327 - val_loss: 1.7952 - val_accuracy: 0.0180\n",
      "Epoch 90/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.0325\n",
      "Epoch 90: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0048 - accuracy: 0.0327 - val_loss: 1.8959 - val_accuracy: 0.0434\n",
      "Epoch 91/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.0329\n",
      "Epoch 91: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0379 - accuracy: 0.0328 - val_loss: 2.3991 - val_accuracy: 0.0090\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.0325\n",
      "Epoch 92: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0507 - accuracy: 0.0325 - val_loss: 1.8135 - val_accuracy: 0.0090\n",
      "Epoch 93/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.0326\n",
      "Epoch 93: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0148 - accuracy: 0.0326 - val_loss: 1.9513 - val_accuracy: 0.0639\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.0325\n",
      "Epoch 94: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0088 - accuracy: 0.0325 - val_loss: 1.7502 - val_accuracy: 0.0240\n",
      "Epoch 95/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.0329\n",
      "Epoch 95: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0096 - accuracy: 0.0327 - val_loss: 1.7895 - val_accuracy: 0.0459\n",
      "Epoch 96/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.0329\n",
      "Epoch 96: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0079 - accuracy: 0.0328 - val_loss: 1.8460 - val_accuracy: 0.0310\n",
      "Epoch 97/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.0324\n",
      "Epoch 97: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0062 - accuracy: 0.0327 - val_loss: 1.8552 - val_accuracy: 0.0120\n",
      "Epoch 98/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.0325\n",
      "Epoch 98: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0456 - accuracy: 0.0330 - val_loss: 2.0471 - val_accuracy: 0.0349\n",
      "Epoch 99/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.0325\n",
      "Epoch 99: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0245 - accuracy: 0.0326 - val_loss: 1.7390 - val_accuracy: 0.0315\n",
      "Epoch 100/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.0329\n",
      "Epoch 100: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0127 - accuracy: 0.0327 - val_loss: 1.7385 - val_accuracy: 0.0270\n",
      "Epoch 101/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.0328\n",
      "Epoch 101: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0037 - accuracy: 0.0327 - val_loss: 1.7879 - val_accuracy: 0.0275\n",
      "Epoch 102/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.0328\n",
      "Epoch 102: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0014 - accuracy: 0.0327 - val_loss: 1.7705 - val_accuracy: 0.0220\n",
      "Epoch 103/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.0330\n",
      "Epoch 103: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0085 - accuracy: 0.0327 - val_loss: 2.0848 - val_accuracy: 0.0105\n",
      "Epoch 104/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.0332\n",
      "Epoch 104: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0618 - accuracy: 0.0328 - val_loss: 1.7359 - val_accuracy: 0.0320\n",
      "Epoch 105/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.0329\n",
      "Epoch 105: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0185 - accuracy: 0.0326 - val_loss: 1.9660 - val_accuracy: 0.0080\n",
      "Epoch 106/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.0326\n",
      "Epoch 106: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0055 - accuracy: 0.0327 - val_loss: 1.7827 - val_accuracy: 0.0210\n",
      "Epoch 107/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.0328\n",
      "Epoch 107: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0045 - accuracy: 0.0328 - val_loss: 1.7729 - val_accuracy: 0.0230\n",
      "Epoch 108/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.0325\n",
      "Epoch 108: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0031 - accuracy: 0.0326 - val_loss: 1.6950 - val_accuracy: 0.0290\n",
      "Epoch 109/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.0332\n",
      "Epoch 109: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0423 - accuracy: 0.0328 - val_loss: 1.9741 - val_accuracy: 0.0195\n",
      "Epoch 110/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.0329\n",
      "Epoch 110: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0209 - accuracy: 0.0328 - val_loss: 1.6857 - val_accuracy: 0.0200\n",
      "Epoch 111/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.0320\n",
      "Epoch 111: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0039 - accuracy: 0.0326 - val_loss: 1.7407 - val_accuracy: 0.0165\n",
      "Epoch 112/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.0330\n",
      "Epoch 112: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0041 - accuracy: 0.0328 - val_loss: 2.0632 - val_accuracy: 0.0255\n",
      "Epoch 113/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.0328\n",
      "Epoch 113: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0071 - accuracy: 0.0327 - val_loss: 1.9042 - val_accuracy: 0.0594\n",
      "Epoch 114/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.0325\n",
      "Epoch 114: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0076 - accuracy: 0.0326 - val_loss: 1.8792 - val_accuracy: 0.0429\n",
      "Epoch 115/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.0329\n",
      "Epoch 115: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0393 - accuracy: 0.0330 - val_loss: 1.9651 - val_accuracy: 0.0175\n",
      "Epoch 116/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.0320\n",
      "Epoch 116: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0209 - accuracy: 0.0323 - val_loss: 1.8221 - val_accuracy: 0.0205\n",
      "Epoch 117/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.0324\n",
      "Epoch 117: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0220 - accuracy: 0.0327 - val_loss: 2.1582 - val_accuracy: 0.0305\n",
      "Epoch 118/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.0333\n",
      "Epoch 118: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0160 - accuracy: 0.0330 - val_loss: 1.8085 - val_accuracy: 0.0424\n",
      "Epoch 119/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.0326\n",
      "Epoch 119: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0074 - accuracy: 0.0328 - val_loss: 2.2252 - val_accuracy: 0.0105\n",
      "Epoch 120/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.0329\n",
      "Epoch 120: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0078 - accuracy: 0.0327 - val_loss: 2.0708 - val_accuracy: 0.0230\n",
      "Epoch 121/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.0329\n",
      "Epoch 121: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0049 - accuracy: 0.0327 - val_loss: 1.8723 - val_accuracy: 0.0270\n",
      "Epoch 122/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.0326\n",
      "Epoch 122: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0423 - accuracy: 0.0327 - val_loss: 2.3129 - val_accuracy: 0.0170\n",
      "Epoch 123/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.0326\n",
      "Epoch 123: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0180 - accuracy: 0.0325 - val_loss: 2.0635 - val_accuracy: 0.0255\n",
      "Epoch 124/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.0325\n",
      "Epoch 124: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0092 - accuracy: 0.0326 - val_loss: 1.8705 - val_accuracy: 0.0285\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.0327\n",
      "Epoch 125: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0027 - accuracy: 0.0327 - val_loss: 2.1112 - val_accuracy: 0.0155\n",
      "Epoch 126/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.0327\n",
      "Epoch 126: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0315 - accuracy: 0.0328 - val_loss: 1.8665 - val_accuracy: 0.0100\n",
      "Epoch 127/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.0325\n",
      "Epoch 127: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0100 - accuracy: 0.0327 - val_loss: 1.8538 - val_accuracy: 0.0399\n",
      "Epoch 128/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.0325\n",
      "Epoch 128: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0086 - accuracy: 0.0327 - val_loss: 2.0931 - val_accuracy: 0.0125\n",
      "Epoch 129/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.0326\n",
      "Epoch 129: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0086 - accuracy: 0.0328 - val_loss: 1.9458 - val_accuracy: 0.0359\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.0327\n",
      "Epoch 130: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0047 - accuracy: 0.0327 - val_loss: 1.8371 - val_accuracy: 0.0330\n",
      "Epoch 131/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.0326\n",
      "Epoch 131: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0022 - accuracy: 0.0328 - val_loss: 1.8448 - val_accuracy: 0.0180\n",
      "Epoch 132/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.0327\n",
      "Epoch 132: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0130 - accuracy: 0.0327 - val_loss: 2.0727 - val_accuracy: 0.0230\n",
      "Epoch 133/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.0326\n",
      "Epoch 133: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0372 - accuracy: 0.0325 - val_loss: 1.8428 - val_accuracy: 0.0384\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.0328\n",
      "Epoch 134: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0253 - accuracy: 0.0328 - val_loss: 1.9635 - val_accuracy: 0.0399\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.0326\n",
      "Epoch 135: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0094 - accuracy: 0.0326 - val_loss: 1.8459 - val_accuracy: 0.0220\n",
      "Epoch 136/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.0325\n",
      "Epoch 136: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0103 - accuracy: 0.0328 - val_loss: 1.8838 - val_accuracy: 0.0130\n",
      "Epoch 137/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.0329\n",
      "Epoch 137: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0051 - accuracy: 0.0328 - val_loss: 1.8602 - val_accuracy: 0.0245\n",
      "Epoch 138/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.0329\n",
      "Epoch 138: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0045 - accuracy: 0.0327 - val_loss: 1.8584 - val_accuracy: 0.0315\n",
      "Epoch 139/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.0325\n",
      "Epoch 139: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0024 - accuracy: 0.0327 - val_loss: 2.0048 - val_accuracy: 0.0290\n",
      "Epoch 140/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.0327\n",
      "Epoch 140: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0015 - accuracy: 0.0327 - val_loss: 1.9431 - val_accuracy: 0.0424\n",
      "Epoch 141/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.0321\n",
      "Epoch 141: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0268 - accuracy: 0.0325 - val_loss: 2.2001 - val_accuracy: 0.0155\n",
      "Epoch 142/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.0329\n",
      "Epoch 142: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0533 - accuracy: 0.0330 - val_loss: 1.8366 - val_accuracy: 0.0145\n",
      "Epoch 143/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.0325\n",
      "Epoch 143: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0130 - accuracy: 0.0327 - val_loss: 1.9903 - val_accuracy: 0.0260\n",
      "Epoch 144/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.0328\n",
      "Epoch 144: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0032 - accuracy: 0.0326 - val_loss: 1.7653 - val_accuracy: 0.0200\n",
      "Epoch 145/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.0329\n",
      "Epoch 145: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0039 - accuracy: 0.0328 - val_loss: 1.8640 - val_accuracy: 0.0260\n",
      "Epoch 146/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.0330\n",
      "Epoch 146: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0112 - accuracy: 0.0330 - val_loss: 2.0205 - val_accuracy: 0.0155\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.0330\n",
      "Epoch 147: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0129 - accuracy: 0.0330 - val_loss: 1.9888 - val_accuracy: 0.0195\n",
      "Epoch 148/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.0329\n",
      "Epoch 148: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0038 - accuracy: 0.0327 - val_loss: 2.0374 - val_accuracy: 0.0165\n",
      "Epoch 149/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.0328\n",
      "Epoch 149: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0056 - accuracy: 0.0327 - val_loss: 2.4186 - val_accuracy: 0.0549\n",
      "Epoch 150/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.0329\n",
      "Epoch 150: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0234 - accuracy: 0.0328 - val_loss: 2.0725 - val_accuracy: 0.0290\n",
      "Epoch 151/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.0326\n",
      "Epoch 151: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0133 - accuracy: 0.0331 - val_loss: 1.9095 - val_accuracy: 0.0155\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.0325\n",
      "Epoch 152: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0143 - accuracy: 0.0325 - val_loss: 1.9553 - val_accuracy: 0.0195\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.0326\n",
      "Epoch 153: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0100 - accuracy: 0.0326 - val_loss: 2.1538 - val_accuracy: 0.0135\n",
      "Epoch 154/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.0328\n",
      "Epoch 154: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0065 - accuracy: 0.0328 - val_loss: 1.9587 - val_accuracy: 0.0369\n",
      "Epoch 155/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.0330\n",
      "Epoch 155: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0165 - accuracy: 0.0330 - val_loss: 1.9855 - val_accuracy: 0.0459\n",
      "Epoch 156/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.0325\n",
      "Epoch 156: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0152 - accuracy: 0.0325 - val_loss: 1.9516 - val_accuracy: 0.0524\n",
      "Epoch 157/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.0327\n",
      "Epoch 157: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0099 - accuracy: 0.0327 - val_loss: 2.0406 - val_accuracy: 0.0155\n",
      "Epoch 158/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.0327\n",
      "Epoch 158: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0057 - accuracy: 0.0327 - val_loss: 1.9513 - val_accuracy: 0.0115\n",
      "Epoch 159/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.0328\n",
      "Epoch 159: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0258 - accuracy: 0.0326 - val_loss: 2.6430 - val_accuracy: 0.0075\n",
      "Epoch 160/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.0323\n",
      "Epoch 160: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0127 - accuracy: 0.0323 - val_loss: 1.8876 - val_accuracy: 0.0180\n",
      "Epoch 161/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.0326\n",
      "Epoch 161: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0042 - accuracy: 0.0327 - val_loss: 1.9756 - val_accuracy: 0.0235\n",
      "Epoch 162/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.0328\n",
      "Epoch 162: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0091 - accuracy: 0.0327 - val_loss: 2.0671 - val_accuracy: 0.0554\n",
      "Epoch 163/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.0329\n",
      "Epoch 163: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0046 - accuracy: 0.0327 - val_loss: 2.1855 - val_accuracy: 0.0205\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.0326\n",
      "Epoch 164: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0048 - accuracy: 0.0326 - val_loss: 2.0662 - val_accuracy: 0.0250\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.0330\n",
      "Epoch 165: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0299 - accuracy: 0.0330 - val_loss: 2.3206 - val_accuracy: 0.0070\n",
      "Epoch 166/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.0331\n",
      "Epoch 166: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0201 - accuracy: 0.0330 - val_loss: 1.8988 - val_accuracy: 0.0245\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.0325\n",
      "Epoch 167: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0081 - accuracy: 0.0325 - val_loss: 2.0092 - val_accuracy: 0.0140\n",
      "Epoch 168/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.0330\n",
      "Epoch 168: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0017 - accuracy: 0.0327 - val_loss: 1.9045 - val_accuracy: 0.0215\n",
      "Epoch 169/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 5.6741e-04 - accuracy: 0.0321\n",
      "Epoch 169: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 5.6601e-04 - accuracy: 0.0327 - val_loss: 1.9308 - val_accuracy: 0.0240\n",
      "Epoch 170/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.0328\n",
      "Epoch 170: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0073 - accuracy: 0.0327 - val_loss: 2.2840 - val_accuracy: 0.0414\n",
      "Epoch 171/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.0330\n",
      "Epoch 171: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0277 - accuracy: 0.0327 - val_loss: 2.2751 - val_accuracy: 0.0634\n",
      "Epoch 172/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.0326\n",
      "Epoch 172: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0203 - accuracy: 0.0328 - val_loss: 2.1777 - val_accuracy: 0.0155\n",
      "Epoch 173/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.0330\n",
      "Epoch 173: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0096 - accuracy: 0.0327 - val_loss: 2.1282 - val_accuracy: 0.0320\n",
      "Epoch 174/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.0330\n",
      "Epoch 174: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0085 - accuracy: 0.0328 - val_loss: 2.0677 - val_accuracy: 0.0115\n",
      "Epoch 175/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.0326\n",
      "Epoch 175: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0040 - accuracy: 0.0326 - val_loss: 2.0361 - val_accuracy: 0.0235\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.0328\n",
      "Epoch 176: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0054 - accuracy: 0.0328 - val_loss: 2.0359 - val_accuracy: 0.0325\n",
      "Epoch 177/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.0327\n",
      "Epoch 177: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0344 - accuracy: 0.0328 - val_loss: 2.1299 - val_accuracy: 0.0339\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.0325\n",
      "Epoch 178: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0097 - accuracy: 0.0325 - val_loss: 1.9738 - val_accuracy: 0.0399\n",
      "Epoch 179/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.0324\n",
      "Epoch 179: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0019 - accuracy: 0.0327 - val_loss: 1.9461 - val_accuracy: 0.0320\n",
      "Epoch 180/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.0328\n",
      "Epoch 180: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0011 - accuracy: 0.0328 - val_loss: 1.9725 - val_accuracy: 0.0265\n",
      "Epoch 181/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 7.6090e-04 - accuracy: 0.0326\n",
      "Epoch 181: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 7.5723e-04 - accuracy: 0.0327 - val_loss: 1.9713 - val_accuracy: 0.0240\n",
      "Epoch 182/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 3.5643e-04 - accuracy: 0.0329\n",
      "Epoch 182: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 3.5505e-04 - accuracy: 0.0327 - val_loss: 1.9550 - val_accuracy: 0.0230\n",
      "Epoch 183/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 2.3475e-04 - accuracy: 0.0329\n",
      "Epoch 183: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 2.4061e-04 - accuracy: 0.0327 - val_loss: 1.9993 - val_accuracy: 0.0230\n",
      "Epoch 184/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 2.6178e-04 - accuracy: 0.0326\n",
      "Epoch 184: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 2.6198e-04 - accuracy: 0.0327 - val_loss: 2.0122 - val_accuracy: 0.0240\n",
      "Epoch 185/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 4.1572e-04 - accuracy: 0.0326\n",
      "Epoch 185: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 4.1544e-04 - accuracy: 0.0327 - val_loss: 2.0528 - val_accuracy: 0.0280\n",
      "Epoch 186/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 5.8848e-04 - accuracy: 0.0326\n",
      "Epoch 186: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 6.1208e-04 - accuracy: 0.0327 - val_loss: 2.0345 - val_accuracy: 0.0295\n",
      "Epoch 187/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.0327\n",
      "Epoch 187: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0754 - accuracy: 0.0328 - val_loss: 2.1703 - val_accuracy: 0.0549\n",
      "Epoch 188/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.0328\n",
      "Epoch 188: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0252 - accuracy: 0.0327 - val_loss: 1.8857 - val_accuracy: 0.0100\n",
      "Epoch 189/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.0328\n",
      "Epoch 189: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0046 - accuracy: 0.0328 - val_loss: 1.8140 - val_accuracy: 0.0330\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.0327\n",
      "Epoch 190: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0033 - accuracy: 0.0327 - val_loss: 1.8751 - val_accuracy: 0.0175\n",
      "Epoch 191/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.0328\n",
      "Epoch 191: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0017 - accuracy: 0.0327 - val_loss: 1.8795 - val_accuracy: 0.0260\n",
      "Epoch 192/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.0326\n",
      "Epoch 192: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0138 - accuracy: 0.0326 - val_loss: 1.9045 - val_accuracy: 0.0315\n",
      "Epoch 193/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.0330\n",
      "Epoch 193: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0128 - accuracy: 0.0330 - val_loss: 2.0596 - val_accuracy: 0.0859\n",
      "Epoch 194/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.0325\n",
      "Epoch 194: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0057 - accuracy: 0.0326 - val_loss: 1.9739 - val_accuracy: 0.0205\n",
      "Epoch 195/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.0329\n",
      "Epoch 195: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0046 - accuracy: 0.0327 - val_loss: 2.0522 - val_accuracy: 0.0230\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.0325\n",
      "Epoch 196: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0119 - accuracy: 0.0325 - val_loss: 2.1360 - val_accuracy: 0.0354\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.0330\n",
      "Epoch 197: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0182 - accuracy: 0.0330 - val_loss: 2.4441 - val_accuracy: 0.0065\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.0326\n",
      "Epoch 198: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0106 - accuracy: 0.0326 - val_loss: 2.0681 - val_accuracy: 0.0424\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.0323\n",
      "Epoch 199: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0185 - accuracy: 0.0323 - val_loss: 2.1901 - val_accuracy: 0.0349\n",
      "Epoch 200/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.0326\n",
      "Epoch 200: val_loss did not improve from 0.70990\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0103 - accuracy: 0.0327 - val_loss: 2.1243 - val_accuracy: 0.0245\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 2.1243 - accuracy: 0.0245\n",
      "63/63 [==============================] - 1s 6ms/step\n",
      "model0 trained\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saidm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cybersecurity-Z7yOgMbu-py3.11\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/251 [============================>.] - ETA: 0s - loss: 0.9400 - accuracy: 8.8206e-04\n",
      "Epoch 1: val_loss improved from inf to 0.88997, saving model to model_1_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 6s 13ms/step - loss: 0.9422 - accuracy: 8.7369e-04 - val_loss: 0.8900 - val_accuracy: 4.9925e-04\n",
      "Epoch 2/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.7901 - accuracy: 0.0080\n",
      "Epoch 2: val_loss improved from 0.88997 to 0.80490, saving model to model_1_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.7905 - accuracy: 0.0081 - val_loss: 0.8049 - val_accuracy: 0.0050\n",
      "Epoch 3/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.7231 - accuracy: 0.0154\n",
      "Epoch 3: val_loss did not improve from 0.80490\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.7267 - accuracy: 0.0154 - val_loss: 0.8257 - val_accuracy: 0.0035\n",
      "Epoch 4/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.0202\n",
      "Epoch 4: val_loss did not improve from 0.80490\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.6797 - accuracy: 0.0203 - val_loss: 0.8393 - val_accuracy: 0.0409\n",
      "Epoch 5/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6353 - accuracy: 0.0221\n",
      "Epoch 5: val_loss improved from 0.80490 to 0.77282, saving model to model_1_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.6358 - accuracy: 0.0221 - val_loss: 0.7728 - val_accuracy: 0.0344\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.5920 - accuracy: 0.0287\n",
      "Epoch 6: val_loss did not improve from 0.77282\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.5920 - accuracy: 0.0287 - val_loss: 0.7865 - val_accuracy: 0.0040\n",
      "Epoch 7/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.5538 - accuracy: 0.0273\n",
      "Epoch 7: val_loss did not improve from 0.77282\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.5555 - accuracy: 0.0275 - val_loss: 0.8261 - val_accuracy: 0.0100\n",
      "Epoch 8/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.0256\n",
      "Epoch 8: val_loss improved from 0.77282 to 0.73585, saving model to model_1_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.5208 - accuracy: 0.0256 - val_loss: 0.7359 - val_accuracy: 0.0215\n",
      "Epoch 9/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.4891 - accuracy: 0.0278\n",
      "Epoch 9: val_loss did not improve from 0.73585\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.4878 - accuracy: 0.0281 - val_loss: 0.7513 - val_accuracy: 0.0270\n",
      "Epoch 10/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.4580 - accuracy: 0.0275\n",
      "Epoch 10: val_loss improved from 0.73585 to 0.73328, saving model to model_1_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.4586 - accuracy: 0.0278 - val_loss: 0.7333 - val_accuracy: 0.0235\n",
      "Epoch 11/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.4233 - accuracy: 0.0308\n",
      "Epoch 11: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.4239 - accuracy: 0.0307 - val_loss: 0.8520 - val_accuracy: 0.0260\n",
      "Epoch 12/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.3844 - accuracy: 0.0286\n",
      "Epoch 12: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.3848 - accuracy: 0.0288 - val_loss: 0.7568 - val_accuracy: 0.0285\n",
      "Epoch 13/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.3617 - accuracy: 0.0304\n",
      "Epoch 13: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.3615 - accuracy: 0.0303 - val_loss: 0.8988 - val_accuracy: 0.0120\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.0308\n",
      "Epoch 14: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.3335 - accuracy: 0.0308 - val_loss: 0.8663 - val_accuracy: 0.0275\n",
      "Epoch 15/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.0299\n",
      "Epoch 15: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.2991 - accuracy: 0.0300 - val_loss: 0.9220 - val_accuracy: 0.0095\n",
      "Epoch 16/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.0301\n",
      "Epoch 16: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.2718 - accuracy: 0.0302 - val_loss: 1.1377 - val_accuracy: 0.0384\n",
      "Epoch 17/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.2440 - accuracy: 0.0297\n",
      "Epoch 17: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.2446 - accuracy: 0.0296 - val_loss: 0.8354 - val_accuracy: 0.0325\n",
      "Epoch 18/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.2272 - accuracy: 0.0311\n",
      "Epoch 18: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.2273 - accuracy: 0.0312 - val_loss: 0.8746 - val_accuracy: 0.0339\n",
      "Epoch 19/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.2146 - accuracy: 0.0299\n",
      "Epoch 19: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.2150 - accuracy: 0.0300 - val_loss: 0.8964 - val_accuracy: 0.0295\n",
      "Epoch 20/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.1870 - accuracy: 0.0312\n",
      "Epoch 20: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.1890 - accuracy: 0.0310 - val_loss: 1.0037 - val_accuracy: 0.0180\n",
      "Epoch 21/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.0312\n",
      "Epoch 21: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.1702 - accuracy: 0.0315 - val_loss: 1.0290 - val_accuracy: 0.0205\n",
      "Epoch 22/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.0322\n",
      "Epoch 22: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1487 - accuracy: 0.0323 - val_loss: 1.0967 - val_accuracy: 0.0235\n",
      "Epoch 23/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.0315\n",
      "Epoch 23: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1386 - accuracy: 0.0312 - val_loss: 1.0699 - val_accuracy: 0.0290\n",
      "Epoch 24/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.1239 - accuracy: 0.0319\n",
      "Epoch 24: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.1242 - accuracy: 0.0320 - val_loss: 1.0597 - val_accuracy: 0.0344\n",
      "Epoch 25/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.1125 - accuracy: 0.0318\n",
      "Epoch 25: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1126 - accuracy: 0.0316 - val_loss: 1.2086 - val_accuracy: 0.0190\n",
      "Epoch 26/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.1034 - accuracy: 0.0332\n",
      "Epoch 26: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1027 - accuracy: 0.0328 - val_loss: 1.0798 - val_accuracy: 0.0389\n",
      "Epoch 27/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 0.0325\n",
      "Epoch 27: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0896 - accuracy: 0.0325 - val_loss: 1.3986 - val_accuracy: 0.0065\n",
      "Epoch 28/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 0.0318\n",
      "Epoch 28: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0883 - accuracy: 0.0316 - val_loss: 1.2203 - val_accuracy: 0.0414\n",
      "Epoch 29/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.0324\n",
      "Epoch 29: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0823 - accuracy: 0.0325 - val_loss: 1.2643 - val_accuracy: 0.0205\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.0323\n",
      "Epoch 30: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0814 - accuracy: 0.0323 - val_loss: 1.8155 - val_accuracy: 0.0085\n",
      "Epoch 31/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.0325\n",
      "Epoch 31: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0645 - accuracy: 0.0325 - val_loss: 1.2356 - val_accuracy: 0.0374\n",
      "Epoch 32/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.0333\n",
      "Epoch 32: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0607 - accuracy: 0.0332 - val_loss: 1.3684 - val_accuracy: 0.0210\n",
      "Epoch 33/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.0328\n",
      "Epoch 33: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0502 - accuracy: 0.0327 - val_loss: 1.3468 - val_accuracy: 0.0330\n",
      "Epoch 34/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.0321\n",
      "Epoch 34: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0557 - accuracy: 0.0321 - val_loss: 1.4034 - val_accuracy: 0.0160\n",
      "Epoch 35/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.0323\n",
      "Epoch 35: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0638 - accuracy: 0.0322 - val_loss: 1.4978 - val_accuracy: 0.0280\n",
      "Epoch 36/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.0318\n",
      "Epoch 36: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0566 - accuracy: 0.0318 - val_loss: 1.5589 - val_accuracy: 0.0290\n",
      "Epoch 37/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.0329\n",
      "Epoch 37: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0504 - accuracy: 0.0328 - val_loss: 1.3958 - val_accuracy: 0.0240\n",
      "Epoch 38/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.0315\n",
      "Epoch 38: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0413 - accuracy: 0.0321 - val_loss: 1.5059 - val_accuracy: 0.0584\n",
      "Epoch 39/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0381 - accuracy: 0.0331\n",
      "Epoch 39: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0387 - accuracy: 0.0332 - val_loss: 1.7103 - val_accuracy: 0.0604\n",
      "Epoch 40/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.0328\n",
      "Epoch 40: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0451 - accuracy: 0.0330 - val_loss: 1.4259 - val_accuracy: 0.0364\n",
      "Epoch 41/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.0326\n",
      "Epoch 41: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0361 - accuracy: 0.0326 - val_loss: 1.4939 - val_accuracy: 0.0200\n",
      "Epoch 42/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.0326\n",
      "Epoch 42: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0529 - accuracy: 0.0326 - val_loss: 2.3540 - val_accuracy: 0.0404\n",
      "Epoch 43/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0491 - accuracy: 0.0329\n",
      "Epoch 43: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0489 - accuracy: 0.0330 - val_loss: 1.6067 - val_accuracy: 0.0494\n",
      "Epoch 44/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.0319\n",
      "Epoch 44: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0384 - accuracy: 0.0325 - val_loss: 1.5577 - val_accuracy: 0.0330\n",
      "Epoch 45/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0623 - accuracy: 0.0330\n",
      "Epoch 45: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0627 - accuracy: 0.0328 - val_loss: 1.4286 - val_accuracy: 0.0364\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.0328\n",
      "Epoch 46: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0245 - accuracy: 0.0328 - val_loss: 1.5518 - val_accuracy: 0.0379\n",
      "Epoch 47/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.0326\n",
      "Epoch 47: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0177 - accuracy: 0.0328 - val_loss: 1.5751 - val_accuracy: 0.0409\n",
      "Epoch 48/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.0326\n",
      "Epoch 48: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0232 - accuracy: 0.0330 - val_loss: 1.7125 - val_accuracy: 0.0110\n",
      "Epoch 49/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.0337\n",
      "Epoch 49: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0301 - accuracy: 0.0332 - val_loss: 1.6642 - val_accuracy: 0.0280\n",
      "Epoch 50/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.0329\n",
      "Epoch 50: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0401 - accuracy: 0.0330 - val_loss: 1.7661 - val_accuracy: 0.0394\n",
      "Epoch 51/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.0324\n",
      "Epoch 51: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0388 - accuracy: 0.0323 - val_loss: 1.6823 - val_accuracy: 0.0419\n",
      "Epoch 52/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.0324\n",
      "Epoch 52: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0345 - accuracy: 0.0326 - val_loss: 1.7645 - val_accuracy: 0.0325\n",
      "Epoch 53/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.0332\n",
      "Epoch 53: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0279 - accuracy: 0.0330 - val_loss: 1.6058 - val_accuracy: 0.0215\n",
      "Epoch 54/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.0323\n",
      "Epoch 54: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0212 - accuracy: 0.0326 - val_loss: 1.6447 - val_accuracy: 0.0230\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.0327\n",
      "Epoch 55: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0224 - accuracy: 0.0327 - val_loss: 2.5443 - val_accuracy: 0.0849\n",
      "Epoch 56/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.0330\n",
      "Epoch 56: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0320 - accuracy: 0.0330 - val_loss: 2.0270 - val_accuracy: 0.0359\n",
      "Epoch 57/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.0326\n",
      "Epoch 57: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0245 - accuracy: 0.0326 - val_loss: 1.8058 - val_accuracy: 0.0334\n",
      "Epoch 58/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.0329\n",
      "Epoch 58: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0245 - accuracy: 0.0327 - val_loss: 1.8387 - val_accuracy: 0.0300\n",
      "Epoch 59/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.0328\n",
      "Epoch 59: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0236 - accuracy: 0.0325 - val_loss: 2.4799 - val_accuracy: 0.0659\n",
      "Epoch 60/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.0325\n",
      "Epoch 60: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0346 - accuracy: 0.0330 - val_loss: 1.7786 - val_accuracy: 0.0514\n",
      "Epoch 61/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.0326\n",
      "Epoch 61: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0220 - accuracy: 0.0326 - val_loss: 1.8842 - val_accuracy: 0.0404\n",
      "Epoch 62/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.0328\n",
      "Epoch 62: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0270 - accuracy: 0.0327 - val_loss: 1.9140 - val_accuracy: 0.0110\n",
      "Epoch 63/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.0332\n",
      "Epoch 63: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0348 - accuracy: 0.0328 - val_loss: 1.7765 - val_accuracy: 0.0225\n",
      "Epoch 64/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.0329\n",
      "Epoch 64: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0193 - accuracy: 0.0327 - val_loss: 1.8169 - val_accuracy: 0.0325\n",
      "Epoch 65/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.0330\n",
      "Epoch 65: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0130 - accuracy: 0.0330 - val_loss: 2.0556 - val_accuracy: 0.0250\n",
      "Epoch 66/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.0329\n",
      "Epoch 66: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0509 - accuracy: 0.0328 - val_loss: 1.8555 - val_accuracy: 0.0539\n",
      "Epoch 67/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.0324\n",
      "Epoch 67: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0218 - accuracy: 0.0322 - val_loss: 1.7996 - val_accuracy: 0.0155\n",
      "Epoch 68/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.0324\n",
      "Epoch 68: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0102 - accuracy: 0.0326 - val_loss: 1.7504 - val_accuracy: 0.0270\n",
      "Epoch 69/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.0326\n",
      "Epoch 69: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0171 - accuracy: 0.0328 - val_loss: 1.9179 - val_accuracy: 0.0220\n",
      "Epoch 70/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.0324\n",
      "Epoch 70: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0297 - accuracy: 0.0325 - val_loss: 2.1460 - val_accuracy: 0.0175\n",
      "Epoch 71/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.0324\n",
      "Epoch 71: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0237 - accuracy: 0.0322 - val_loss: 1.8854 - val_accuracy: 0.0399\n",
      "Epoch 72/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.0330\n",
      "Epoch 72: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0315 - accuracy: 0.0330 - val_loss: 1.8949 - val_accuracy: 0.0245\n",
      "Epoch 73/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.0328\n",
      "Epoch 73: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0385 - accuracy: 0.0327 - val_loss: 1.9145 - val_accuracy: 0.0369\n",
      "Epoch 74/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.0327\n",
      "Epoch 74: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0137 - accuracy: 0.0327 - val_loss: 1.7901 - val_accuracy: 0.0384\n",
      "Epoch 75/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.0328\n",
      "Epoch 75: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0058 - accuracy: 0.0328 - val_loss: 1.7048 - val_accuracy: 0.0250\n",
      "Epoch 76/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.0327\n",
      "Epoch 76: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0205 - accuracy: 0.0327 - val_loss: 1.8561 - val_accuracy: 0.0349\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.0328\n",
      "Epoch 77: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0154 - accuracy: 0.0328 - val_loss: 1.8727 - val_accuracy: 0.0379\n",
      "Epoch 78/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.0325\n",
      "Epoch 78: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0190 - accuracy: 0.0326 - val_loss: 1.7757 - val_accuracy: 0.0320\n",
      "Epoch 79/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.0321\n",
      "Epoch 79: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0261 - accuracy: 0.0321 - val_loss: 1.9875 - val_accuracy: 0.0235\n",
      "Epoch 80/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.0324\n",
      "Epoch 80: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0202 - accuracy: 0.0325 - val_loss: 2.1641 - val_accuracy: 0.0160\n",
      "Epoch 81/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.0330\n",
      "Epoch 81: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0193 - accuracy: 0.0328 - val_loss: 1.8536 - val_accuracy: 0.0300\n",
      "Epoch 82/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.0330\n",
      "Epoch 82: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0189 - accuracy: 0.0330 - val_loss: 2.2441 - val_accuracy: 0.0649\n",
      "Epoch 83/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.0329\n",
      "Epoch 83: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0455 - accuracy: 0.0331 - val_loss: 2.3772 - val_accuracy: 0.0429\n",
      "Epoch 84/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.0329\n",
      "Epoch 84: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0174 - accuracy: 0.0330 - val_loss: 1.9117 - val_accuracy: 0.0320\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.0325\n",
      "Epoch 85: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0085 - accuracy: 0.0325 - val_loss: 1.9635 - val_accuracy: 0.0379\n",
      "Epoch 86/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.0329\n",
      "Epoch 86: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0188 - accuracy: 0.0327 - val_loss: 1.9414 - val_accuracy: 0.0444\n",
      "Epoch 87/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.0328\n",
      "Epoch 87: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0096 - accuracy: 0.0327 - val_loss: 2.0246 - val_accuracy: 0.0230\n",
      "Epoch 88/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.0329\n",
      "Epoch 88: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0142 - accuracy: 0.0327 - val_loss: 2.1963 - val_accuracy: 0.0160\n",
      "Epoch 89/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.0326\n",
      "Epoch 89: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0396 - accuracy: 0.0326 - val_loss: 1.9784 - val_accuracy: 0.0120\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.0323\n",
      "Epoch 90: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0127 - accuracy: 0.0323 - val_loss: 1.8236 - val_accuracy: 0.0325\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.0325\n",
      "Epoch 91: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0118 - accuracy: 0.0325 - val_loss: 1.9910 - val_accuracy: 0.0230\n",
      "Epoch 92/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.0325\n",
      "Epoch 92: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0228 - accuracy: 0.0328 - val_loss: 1.9813 - val_accuracy: 0.0494\n",
      "Epoch 93/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.0330\n",
      "Epoch 93: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0211 - accuracy: 0.0331 - val_loss: 2.3896 - val_accuracy: 0.0140\n",
      "Epoch 94/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.0325\n",
      "Epoch 94: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0176 - accuracy: 0.0325 - val_loss: 1.9172 - val_accuracy: 0.0349\n",
      "Epoch 95/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.0328\n",
      "Epoch 95: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0142 - accuracy: 0.0325 - val_loss: 1.9799 - val_accuracy: 0.0155\n",
      "Epoch 96/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.0326\n",
      "Epoch 96: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0040 - accuracy: 0.0326 - val_loss: 1.8673 - val_accuracy: 0.0479\n",
      "Epoch 97/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.0328\n",
      "Epoch 97: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0021 - accuracy: 0.0327 - val_loss: 1.9560 - val_accuracy: 0.0245\n",
      "Epoch 98/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.0324\n",
      "Epoch 98: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0360 - accuracy: 0.0323 - val_loss: 2.2761 - val_accuracy: 0.0359\n",
      "Epoch 99/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.0325\n",
      "Epoch 99: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0274 - accuracy: 0.0325 - val_loss: 1.9555 - val_accuracy: 0.0444\n",
      "Epoch 100/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.0326\n",
      "Epoch 100: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0111 - accuracy: 0.0327 - val_loss: 2.0093 - val_accuracy: 0.0334\n",
      "Epoch 101/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.0328\n",
      "Epoch 101: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0049 - accuracy: 0.0327 - val_loss: 2.0542 - val_accuracy: 0.0150\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.0326\n",
      "Epoch 102: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0198 - accuracy: 0.0326 - val_loss: 1.9123 - val_accuracy: 0.0210\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.0325\n",
      "Epoch 103: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0475 - accuracy: 0.0325 - val_loss: 1.9094 - val_accuracy: 0.0230\n",
      "Epoch 104/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.0326\n",
      "Epoch 104: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0098 - accuracy: 0.0325 - val_loss: 1.8251 - val_accuracy: 0.0464\n",
      "Epoch 105/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.0324\n",
      "Epoch 105: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0100 - accuracy: 0.0325 - val_loss: 1.8434 - val_accuracy: 0.0364\n",
      "Epoch 106/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.0329\n",
      "Epoch 106: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0173 - accuracy: 0.0328 - val_loss: 2.1519 - val_accuracy: 0.0364\n",
      "Epoch 107/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.0330\n",
      "Epoch 107: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0122 - accuracy: 0.0328 - val_loss: 1.8989 - val_accuracy: 0.0434\n",
      "Epoch 108/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.0329\n",
      "Epoch 108: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0036 - accuracy: 0.0327 - val_loss: 1.9278 - val_accuracy: 0.0389\n",
      "Epoch 109/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.0327\n",
      "Epoch 109: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0024 - accuracy: 0.0327 - val_loss: 1.9667 - val_accuracy: 0.0320\n",
      "Epoch 110/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.0323\n",
      "Epoch 110: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0141 - accuracy: 0.0327 - val_loss: 2.1612 - val_accuracy: 0.0320\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.0326\n",
      "Epoch 111: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0392 - accuracy: 0.0326 - val_loss: 2.2057 - val_accuracy: 0.0245\n",
      "Epoch 112/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.0327\n",
      "Epoch 112: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0263 - accuracy: 0.0328 - val_loss: 2.2887 - val_accuracy: 0.0180\n",
      "Epoch 113/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.0323\n",
      "Epoch 113: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0115 - accuracy: 0.0325 - val_loss: 1.9724 - val_accuracy: 0.0369\n",
      "Epoch 114/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.0329\n",
      "Epoch 114: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0206 - accuracy: 0.0331 - val_loss: 1.9681 - val_accuracy: 0.0220\n",
      "Epoch 115/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.0325\n",
      "Epoch 115: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0189 - accuracy: 0.0327 - val_loss: 2.0089 - val_accuracy: 0.0354\n",
      "Epoch 116/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.0329\n",
      "Epoch 116: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0083 - accuracy: 0.0331 - val_loss: 2.0623 - val_accuracy: 0.0175\n",
      "Epoch 117/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.0328\n",
      "Epoch 117: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0043 - accuracy: 0.0327 - val_loss: 1.9104 - val_accuracy: 0.0215\n",
      "Epoch 118/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.0329\n",
      "Epoch 118: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0037 - accuracy: 0.0327 - val_loss: 2.0346 - val_accuracy: 0.0230\n",
      "Epoch 119/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.0326\n",
      "Epoch 119: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0120 - accuracy: 0.0328 - val_loss: 2.5736 - val_accuracy: 0.0110\n",
      "Epoch 120/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.0323\n",
      "Epoch 120: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0300 - accuracy: 0.0326 - val_loss: 2.0375 - val_accuracy: 0.0275\n",
      "Epoch 121/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.0329\n",
      "Epoch 121: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0294 - accuracy: 0.0328 - val_loss: 2.0319 - val_accuracy: 0.0250\n",
      "Epoch 122/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.0328\n",
      "Epoch 122: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0144 - accuracy: 0.0327 - val_loss: 2.0454 - val_accuracy: 0.0155\n",
      "Epoch 123/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.0326\n",
      "Epoch 123: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0079 - accuracy: 0.0327 - val_loss: 2.1630 - val_accuracy: 0.0280\n",
      "Epoch 124/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.0328\n",
      "Epoch 124: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0064 - accuracy: 0.0327 - val_loss: 1.9911 - val_accuracy: 0.0414\n",
      "Epoch 125/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.0326\n",
      "Epoch 125: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0183 - accuracy: 0.0326 - val_loss: 2.3344 - val_accuracy: 0.0245\n",
      "Epoch 126/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.0327\n",
      "Epoch 126: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0067 - accuracy: 0.0327 - val_loss: 2.0715 - val_accuracy: 0.0404\n",
      "Epoch 127/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.0330\n",
      "Epoch 127: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0037 - accuracy: 0.0328 - val_loss: 2.0305 - val_accuracy: 0.0439\n",
      "Epoch 128/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.0328\n",
      "Epoch 128: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0023 - accuracy: 0.0326 - val_loss: 2.0415 - val_accuracy: 0.0344\n",
      "Epoch 129/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.0330\n",
      "Epoch 129: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0057 - accuracy: 0.0327 - val_loss: 2.9244 - val_accuracy: 0.0050\n",
      "Epoch 130/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.0329\n",
      "Epoch 130: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0577 - accuracy: 0.0328 - val_loss: 2.0404 - val_accuracy: 0.0140\n",
      "Epoch 131/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.0329\n",
      "Epoch 131: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0181 - accuracy: 0.0326 - val_loss: 1.9199 - val_accuracy: 0.0230\n",
      "Epoch 132/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.0327\n",
      "Epoch 132: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0110 - accuracy: 0.0327 - val_loss: 1.9393 - val_accuracy: 0.0320\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.0326\n",
      "Epoch 133: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0041 - accuracy: 0.0326 - val_loss: 1.9162 - val_accuracy: 0.0439\n",
      "Epoch 134/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.0326\n",
      "Epoch 134: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0011 - accuracy: 0.0327 - val_loss: 1.9445 - val_accuracy: 0.0369\n",
      "Epoch 135/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.0318\n",
      "Epoch 135: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0053 - accuracy: 0.0327 - val_loss: 2.0862 - val_accuracy: 0.0554\n",
      "Epoch 136/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.0325\n",
      "Epoch 136: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0175 - accuracy: 0.0326 - val_loss: 2.5851 - val_accuracy: 0.0120\n",
      "Epoch 137/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.0330\n",
      "Epoch 137: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0295 - accuracy: 0.0330 - val_loss: 2.0615 - val_accuracy: 0.0384\n",
      "Epoch 138/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.0329\n",
      "Epoch 138: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0336 - accuracy: 0.0328 - val_loss: 2.1596 - val_accuracy: 0.0404\n",
      "Epoch 139/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.0324\n",
      "Epoch 139: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0110 - accuracy: 0.0327 - val_loss: 1.9555 - val_accuracy: 0.0474\n",
      "Epoch 140/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.0326\n",
      "Epoch 140: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0054 - accuracy: 0.0327 - val_loss: 2.1336 - val_accuracy: 0.0280\n",
      "Epoch 141/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.0328\n",
      "Epoch 141: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0135 - accuracy: 0.0327 - val_loss: 2.0252 - val_accuracy: 0.0290\n",
      "Epoch 142/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.0327\n",
      "Epoch 142: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.0328 - val_loss: 1.9761 - val_accuracy: 0.0270\n",
      "Epoch 143/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.0328\n",
      "Epoch 143: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0083 - accuracy: 0.0327 - val_loss: 2.1516 - val_accuracy: 0.0609\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.0326\n",
      "Epoch 144: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0227 - accuracy: 0.0326 - val_loss: 2.5901 - val_accuracy: 0.0349\n",
      "Epoch 145/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.0324\n",
      "Epoch 145: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0148 - accuracy: 0.0326 - val_loss: 2.1830 - val_accuracy: 0.0230\n",
      "Epoch 146/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.0329\n",
      "Epoch 146: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0188 - accuracy: 0.0328 - val_loss: 2.0624 - val_accuracy: 0.0230\n",
      "Epoch 147/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.0326\n",
      "Epoch 147: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0042 - accuracy: 0.0328 - val_loss: 2.2094 - val_accuracy: 0.0210\n",
      "Epoch 148/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.0328\n",
      "Epoch 148: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0040 - accuracy: 0.0327 - val_loss: 2.0296 - val_accuracy: 0.0265\n",
      "Epoch 149/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.0321\n",
      "Epoch 149: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0142 - accuracy: 0.0325 - val_loss: 2.3264 - val_accuracy: 0.0614\n",
      "Epoch 150/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.0325\n",
      "Epoch 150: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0122 - accuracy: 0.0326 - val_loss: 2.0963 - val_accuracy: 0.0679\n",
      "Epoch 151/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.0330\n",
      "Epoch 151: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0153 - accuracy: 0.0327 - val_loss: 2.1512 - val_accuracy: 0.0409\n",
      "Epoch 152/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.0328\n",
      "Epoch 152: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0321 - accuracy: 0.0328 - val_loss: 2.0154 - val_accuracy: 0.0364\n",
      "Epoch 153/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.0326\n",
      "Epoch 153: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0088 - accuracy: 0.0327 - val_loss: 1.9939 - val_accuracy: 0.0315\n",
      "Epoch 154/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.0327\n",
      "Epoch 154: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0066 - accuracy: 0.0327 - val_loss: 2.1540 - val_accuracy: 0.0210\n",
      "Epoch 155/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.0325\n",
      "Epoch 155: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0080 - accuracy: 0.0325 - val_loss: 2.2986 - val_accuracy: 0.0574\n",
      "Epoch 156/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.0332\n",
      "Epoch 156: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0071 - accuracy: 0.0327 - val_loss: 2.2235 - val_accuracy: 0.0330\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.0326\n",
      "Epoch 157: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0038 - accuracy: 0.0326 - val_loss: 2.0643 - val_accuracy: 0.0519\n",
      "Epoch 158/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.0325\n",
      "Epoch 158: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0028 - accuracy: 0.0326 - val_loss: 2.1320 - val_accuracy: 0.0305\n",
      "Epoch 159/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.0328\n",
      "Epoch 159: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0130 - accuracy: 0.0327 - val_loss: 2.5586 - val_accuracy: 0.0749\n",
      "Epoch 160/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.0329\n",
      "Epoch 160: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0205 - accuracy: 0.0328 - val_loss: 1.9899 - val_accuracy: 0.0369\n",
      "Epoch 161/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.0328\n",
      "Epoch 161: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0283 - accuracy: 0.0326 - val_loss: 2.2971 - val_accuracy: 0.0185\n",
      "Epoch 162/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.0330\n",
      "Epoch 162: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0103 - accuracy: 0.0327 - val_loss: 2.0471 - val_accuracy: 0.0240\n",
      "Epoch 163/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.0329\n",
      "Epoch 163: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0065 - accuracy: 0.0330 - val_loss: 2.1823 - val_accuracy: 0.0454\n",
      "Epoch 164/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.0325\n",
      "Epoch 164: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0090 - accuracy: 0.0326 - val_loss: 2.2158 - val_accuracy: 0.0634\n",
      "Epoch 165/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.0329\n",
      "Epoch 165: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0156 - accuracy: 0.0328 - val_loss: 2.2723 - val_accuracy: 0.0320\n",
      "Epoch 166/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.0326\n",
      "Epoch 166: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0080 - accuracy: 0.0327 - val_loss: 2.0885 - val_accuracy: 0.0200\n",
      "Epoch 167/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.0325\n",
      "Epoch 167: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0064 - accuracy: 0.0326 - val_loss: 2.1917 - val_accuracy: 0.0195\n",
      "Epoch 168/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.0330\n",
      "Epoch 168: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0214 - accuracy: 0.0328 - val_loss: 2.1997 - val_accuracy: 0.0205\n",
      "Epoch 169/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.0330\n",
      "Epoch 169: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0056 - accuracy: 0.0330 - val_loss: 2.0364 - val_accuracy: 0.0265\n",
      "Epoch 170/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.0328\n",
      "Epoch 170: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0061 - accuracy: 0.0326 - val_loss: 2.2148 - val_accuracy: 0.0339\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.0328\n",
      "Epoch 171: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0337 - accuracy: 0.0328 - val_loss: 2.6755 - val_accuracy: 0.0085\n",
      "Epoch 172/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.0329\n",
      "Epoch 172: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0213 - accuracy: 0.0327 - val_loss: 1.9986 - val_accuracy: 0.0409\n",
      "Epoch 173/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.0327\n",
      "Epoch 173: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0037 - accuracy: 0.0326 - val_loss: 1.9715 - val_accuracy: 0.0250\n",
      "Epoch 174/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.0328\n",
      "Epoch 174: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0014 - accuracy: 0.0326 - val_loss: 1.9826 - val_accuracy: 0.0280\n",
      "Epoch 175/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.0329\n",
      "Epoch 175: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0043 - accuracy: 0.0328 - val_loss: 2.1391 - val_accuracy: 0.0280\n",
      "Epoch 176/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.0326\n",
      "Epoch 176: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0067 - accuracy: 0.0327 - val_loss: 2.0135 - val_accuracy: 0.0315\n",
      "Epoch 177/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.0328\n",
      "Epoch 177: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0174 - accuracy: 0.0328 - val_loss: 2.2533 - val_accuracy: 0.0235\n",
      "Epoch 178/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.0323\n",
      "Epoch 178: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0107 - accuracy: 0.0326 - val_loss: 2.0708 - val_accuracy: 0.0394\n",
      "Epoch 179/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.0326\n",
      "Epoch 179: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0112 - accuracy: 0.0326 - val_loss: 2.0614 - val_accuracy: 0.0344\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.0327\n",
      "Epoch 180: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0056 - accuracy: 0.0327 - val_loss: 2.0599 - val_accuracy: 0.0364\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.0318\n",
      "Epoch 181: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0291 - accuracy: 0.0318 - val_loss: 3.0088 - val_accuracy: 0.1083\n",
      "Epoch 182/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.0328\n",
      "Epoch 182: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0197 - accuracy: 0.0327 - val_loss: 2.1056 - val_accuracy: 0.0459\n",
      "Epoch 183/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.0328\n",
      "Epoch 183: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0100 - accuracy: 0.0327 - val_loss: 2.1315 - val_accuracy: 0.0290\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.0327\n",
      "Epoch 184: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0157 - accuracy: 0.0327 - val_loss: 2.0762 - val_accuracy: 0.0235\n",
      "Epoch 185/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.0328\n",
      "Epoch 185: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0040 - accuracy: 0.0328 - val_loss: 2.0262 - val_accuracy: 0.0325\n",
      "Epoch 186/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.0327\n",
      "Epoch 186: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0047 - accuracy: 0.0327 - val_loss: 2.1655 - val_accuracy: 0.0125\n",
      "Epoch 187/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.0321\n",
      "Epoch 187: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0173 - accuracy: 0.0323 - val_loss: 2.2316 - val_accuracy: 0.0334\n",
      "Epoch 188/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.0326\n",
      "Epoch 188: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0171 - accuracy: 0.0326 - val_loss: 2.3691 - val_accuracy: 0.0439\n",
      "Epoch 189/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.0330\n",
      "Epoch 189: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0149 - accuracy: 0.0327 - val_loss: 2.1343 - val_accuracy: 0.0280\n",
      "Epoch 190/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.0329\n",
      "Epoch 190: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0058 - accuracy: 0.0328 - val_loss: 2.2835 - val_accuracy: 0.0175\n",
      "Epoch 191/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.0326\n",
      "Epoch 191: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0013 - accuracy: 0.0327 - val_loss: 2.1623 - val_accuracy: 0.0369\n",
      "Epoch 192/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.0328\n",
      "Epoch 192: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0011 - accuracy: 0.0327 - val_loss: 2.1895 - val_accuracy: 0.0275\n",
      "Epoch 193/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 4.3016e-04 - accuracy: 0.0330\n",
      "Epoch 193: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 4.2796e-04 - accuracy: 0.0327 - val_loss: 2.1091 - val_accuracy: 0.0290\n",
      "Epoch 194/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 3.5429e-04 - accuracy: 0.0326\n",
      "Epoch 194: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 3.5396e-04 - accuracy: 0.0327 - val_loss: 2.2261 - val_accuracy: 0.0290\n",
      "Epoch 195/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 5.5213e-04 - accuracy: 0.0325\n",
      "Epoch 195: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 5.6085e-04 - accuracy: 0.0327 - val_loss: 2.1541 - val_accuracy: 0.0270\n",
      "Epoch 196/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 6.6976e-04 - accuracy: 0.0325\n",
      "Epoch 196: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 6.6358e-04 - accuracy: 0.0327 - val_loss: 2.1903 - val_accuracy: 0.0325\n",
      "Epoch 197/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.0325\n",
      "Epoch 197: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0509 - accuracy: 0.0328 - val_loss: 2.2611 - val_accuracy: 0.0160\n",
      "Epoch 198/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.0330\n",
      "Epoch 198: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0426 - accuracy: 0.0330 - val_loss: 1.8593 - val_accuracy: 0.0245\n",
      "Epoch 199/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.0323\n",
      "Epoch 199: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0077 - accuracy: 0.0327 - val_loss: 1.9554 - val_accuracy: 0.0180\n",
      "Epoch 200/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.0325\n",
      "Epoch 200: val_loss did not improve from 0.73328\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0041 - accuracy: 0.0326 - val_loss: 1.9002 - val_accuracy: 0.0454\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.9002 - accuracy: 0.0454\n",
      "63/63 [==============================] - 0s 5ms/step\n",
      "model1 trained\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saidm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cybersecurity-Z7yOgMbu-py3.11\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/251 [============================>.] - ETA: 0s - loss: 0.9622 - accuracy: 7.5301e-04\n",
      "Epoch 1: val_loss improved from inf to 0.93868, saving model to model_2_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 5s 10ms/step - loss: 0.9608 - accuracy: 8.7369e-04 - val_loss: 0.9387 - val_accuracy: 0.0065\n",
      "Epoch 2/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.8025 - accuracy: 0.0091\n",
      "Epoch 2: val_loss improved from 0.93868 to 0.85338, saving model to model_2_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.8014 - accuracy: 0.0090 - val_loss: 0.8534 - val_accuracy: 4.9925e-04\n",
      "Epoch 3/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.7425 - accuracy: 0.0151\n",
      "Epoch 3: val_loss improved from 0.85338 to 0.78359, saving model to model_2_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.7436 - accuracy: 0.0154 - val_loss: 0.7836 - val_accuracy: 0.0070\n",
      "Epoch 4/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.6937 - accuracy: 0.0175\n",
      "Epoch 4: val_loss improved from 0.78359 to 0.74635, saving model to model_2_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.6922 - accuracy: 0.0176 - val_loss: 0.7464 - val_accuracy: 0.0339\n",
      "Epoch 5/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.6458 - accuracy: 0.0259\n",
      "Epoch 5: val_loss improved from 0.74635 to 0.74283, saving model to model_2_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.6460 - accuracy: 0.0258 - val_loss: 0.7428 - val_accuracy: 0.0035\n",
      "Epoch 6/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.6054 - accuracy: 0.0210\n",
      "Epoch 6: val_loss did not improve from 0.74283\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.6051 - accuracy: 0.0208 - val_loss: 0.8881 - val_accuracy: 0.0060\n",
      "Epoch 7/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.5617 - accuracy: 0.0246\n",
      "Epoch 7: val_loss did not improve from 0.74283\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.5631 - accuracy: 0.0247 - val_loss: 0.8824 - val_accuracy: 0.0045\n",
      "Epoch 8/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.5417 - accuracy: 0.0251\n",
      "Epoch 8: val_loss improved from 0.74283 to 0.72880, saving model to model_2_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.5408 - accuracy: 0.0250 - val_loss: 0.7288 - val_accuracy: 0.0245\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.0297\n",
      "Epoch 9: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.5047 - accuracy: 0.0297 - val_loss: 0.9465 - val_accuracy: 0.0035\n",
      "Epoch 10/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.0280\n",
      "Epoch 10: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.4674 - accuracy: 0.0277 - val_loss: 1.0110 - val_accuracy: 0.0020\n",
      "Epoch 11/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.4384 - accuracy: 0.0275\n",
      "Epoch 11: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.4382 - accuracy: 0.0275 - val_loss: 0.8378 - val_accuracy: 0.0060\n",
      "Epoch 12/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.0301\n",
      "Epoch 12: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.4023 - accuracy: 0.0300 - val_loss: 0.8354 - val_accuracy: 0.0549\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.0280\n",
      "Epoch 13: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.3685 - accuracy: 0.0280 - val_loss: 0.7342 - val_accuracy: 0.0160\n",
      "Epoch 14/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.3487 - accuracy: 0.0278\n",
      "Epoch 14: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.3485 - accuracy: 0.0282 - val_loss: 0.7587 - val_accuracy: 0.0514\n",
      "Epoch 15/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.3158 - accuracy: 0.0293\n",
      "Epoch 15: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.3149 - accuracy: 0.0291 - val_loss: 0.7774 - val_accuracy: 0.0225\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.0310\n",
      "Epoch 16: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.2814 - accuracy: 0.0310 - val_loss: 1.1226 - val_accuracy: 0.0325\n",
      "Epoch 17/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.2606 - accuracy: 0.0299\n",
      "Epoch 17: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.2623 - accuracy: 0.0298 - val_loss: 0.9325 - val_accuracy: 0.0349\n",
      "Epoch 18/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.2363 - accuracy: 0.0301\n",
      "Epoch 18: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.2373 - accuracy: 0.0302 - val_loss: 0.9018 - val_accuracy: 0.0300\n",
      "Epoch 19/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.2071 - accuracy: 0.0321\n",
      "Epoch 19: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.2068 - accuracy: 0.0318 - val_loss: 1.1310 - val_accuracy: 0.0779\n",
      "Epoch 20/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.1903 - accuracy: 0.0304\n",
      "Epoch 20: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.1900 - accuracy: 0.0298 - val_loss: 0.9415 - val_accuracy: 0.0205\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.0301\n",
      "Epoch 21: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.1744 - accuracy: 0.0301 - val_loss: 1.0347 - val_accuracy: 0.0330\n",
      "Epoch 22/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.1558 - accuracy: 0.0314\n",
      "Epoch 22: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.1554 - accuracy: 0.0313 - val_loss: 1.0346 - val_accuracy: 0.0374\n",
      "Epoch 23/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.1386 - accuracy: 0.0300\n",
      "Epoch 23: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.1383 - accuracy: 0.0301 - val_loss: 1.0269 - val_accuracy: 0.0150\n",
      "Epoch 24/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.0309\n",
      "Epoch 24: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.1207 - accuracy: 0.0307 - val_loss: 1.3058 - val_accuracy: 0.0160\n",
      "Epoch 25/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.1095 - accuracy: 0.0318\n",
      "Epoch 25: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.1102 - accuracy: 0.0317 - val_loss: 1.1820 - val_accuracy: 0.0165\n",
      "Epoch 26/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.0321\n",
      "Epoch 26: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1086 - accuracy: 0.0321 - val_loss: 1.0876 - val_accuracy: 0.0260\n",
      "Epoch 27/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 0.0324\n",
      "Epoch 27: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0982 - accuracy: 0.0327 - val_loss: 1.2271 - val_accuracy: 0.0674\n",
      "Epoch 28/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.0314\n",
      "Epoch 28: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0909 - accuracy: 0.0313 - val_loss: 1.3814 - val_accuracy: 0.0150\n",
      "Epoch 29/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0802 - accuracy: 0.0318\n",
      "Epoch 29: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0805 - accuracy: 0.0320 - val_loss: 1.1968 - val_accuracy: 0.0215\n",
      "Epoch 30/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.0315\n",
      "Epoch 30: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0773 - accuracy: 0.0313 - val_loss: 1.4265 - val_accuracy: 0.0654\n",
      "Epoch 31/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 0.0316\n",
      "Epoch 31: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0765 - accuracy: 0.0316 - val_loss: 1.4517 - val_accuracy: 0.0230\n",
      "Epoch 32/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0616 - accuracy: 0.0315\n",
      "Epoch 32: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0619 - accuracy: 0.0316 - val_loss: 1.3053 - val_accuracy: 0.0260\n",
      "Epoch 33/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.0321\n",
      "Epoch 33: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0592 - accuracy: 0.0321 - val_loss: 1.4031 - val_accuracy: 0.0569\n",
      "Epoch 34/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0704 - accuracy: 0.0314\n",
      "Epoch 34: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0701 - accuracy: 0.0313 - val_loss: 1.6162 - val_accuracy: 0.0364\n",
      "Epoch 35/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.0322\n",
      "Epoch 35: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0516 - accuracy: 0.0323 - val_loss: 1.6710 - val_accuracy: 0.0075\n",
      "Epoch 36/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.0323\n",
      "Epoch 36: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0578 - accuracy: 0.0320 - val_loss: 1.3477 - val_accuracy: 0.0170\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.0322\n",
      "Epoch 37: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0421 - accuracy: 0.0322 - val_loss: 1.3129 - val_accuracy: 0.0504\n",
      "Epoch 38/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.0325\n",
      "Epoch 38: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0355 - accuracy: 0.0323 - val_loss: 1.4958 - val_accuracy: 0.0684\n",
      "Epoch 39/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.0331\n",
      "Epoch 39: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0413 - accuracy: 0.0331 - val_loss: 1.7772 - val_accuracy: 0.0100\n",
      "Epoch 40/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.0324\n",
      "Epoch 40: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0438 - accuracy: 0.0322 - val_loss: 1.4723 - val_accuracy: 0.0065\n",
      "Epoch 41/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.0329\n",
      "Epoch 41: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0589 - accuracy: 0.0328 - val_loss: 1.3525 - val_accuracy: 0.0409\n",
      "Epoch 42/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.0328\n",
      "Epoch 42: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0348 - accuracy: 0.0325 - val_loss: 1.5277 - val_accuracy: 0.0404\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.0328\n",
      "Epoch 43: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0360 - accuracy: 0.0328 - val_loss: 1.5918 - val_accuracy: 0.0210\n",
      "Epoch 44/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.0320\n",
      "Epoch 44: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0319 - accuracy: 0.0323 - val_loss: 1.7174 - val_accuracy: 0.0040\n",
      "Epoch 45/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.0328\n",
      "Epoch 45: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0510 - accuracy: 0.0328 - val_loss: 1.6514 - val_accuracy: 0.0379\n",
      "Epoch 46/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.0331\n",
      "Epoch 46: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0328 - accuracy: 0.0328 - val_loss: 1.5736 - val_accuracy: 0.0509\n",
      "Epoch 47/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.0324\n",
      "Epoch 47: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0300 - accuracy: 0.0325 - val_loss: 1.6289 - val_accuracy: 0.0434\n",
      "Epoch 48/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.0330\n",
      "Epoch 48: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0491 - accuracy: 0.0327 - val_loss: 1.5725 - val_accuracy: 0.0394\n",
      "Epoch 49/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.0328\n",
      "Epoch 49: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0207 - accuracy: 0.0326 - val_loss: 1.4587 - val_accuracy: 0.0210\n",
      "Epoch 50/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.0328\n",
      "Epoch 50: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0194 - accuracy: 0.0327 - val_loss: 1.5793 - val_accuracy: 0.0399\n",
      "Epoch 51/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.0323\n",
      "Epoch 51: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0570 - accuracy: 0.0321 - val_loss: 1.6174 - val_accuracy: 0.0414\n",
      "Epoch 52/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.0330\n",
      "Epoch 52: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0378 - accuracy: 0.0328 - val_loss: 1.5413 - val_accuracy: 0.0349\n",
      "Epoch 53/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.0323\n",
      "Epoch 53: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0235 - accuracy: 0.0326 - val_loss: 1.7730 - val_accuracy: 0.0579\n",
      "Epoch 54/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.0324\n",
      "Epoch 54: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0348 - accuracy: 0.0325 - val_loss: 1.9743 - val_accuracy: 0.0090\n",
      "Epoch 55/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.0325\n",
      "Epoch 55: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0310 - accuracy: 0.0325 - val_loss: 1.5664 - val_accuracy: 0.0265\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.0323\n",
      "Epoch 56: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0363 - accuracy: 0.0323 - val_loss: 1.8187 - val_accuracy: 0.0354\n",
      "Epoch 57/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.0330\n",
      "Epoch 57: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0211 - accuracy: 0.0328 - val_loss: 1.8551 - val_accuracy: 0.0090\n",
      "Epoch 58/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.0326\n",
      "Epoch 58: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0122 - accuracy: 0.0328 - val_loss: 1.6447 - val_accuracy: 0.0399\n",
      "Epoch 59/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.0325\n",
      "Epoch 59: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0237 - accuracy: 0.0326 - val_loss: 1.7265 - val_accuracy: 0.0245\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.0325\n",
      "Epoch 60: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0297 - accuracy: 0.0325 - val_loss: 1.6490 - val_accuracy: 0.0250\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.0320\n",
      "Epoch 61: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0483 - accuracy: 0.0320 - val_loss: 1.9241 - val_accuracy: 0.0354\n",
      "Epoch 62/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.0330\n",
      "Epoch 62: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0424 - accuracy: 0.0330 - val_loss: 1.6737 - val_accuracy: 0.0290\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.0325\n",
      "Epoch 63: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0166 - accuracy: 0.0325 - val_loss: 1.6096 - val_accuracy: 0.0315\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.0328\n",
      "Epoch 64: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0083 - accuracy: 0.0328 - val_loss: 1.6264 - val_accuracy: 0.0359\n",
      "Epoch 65/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.0325\n",
      "Epoch 65: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0060 - accuracy: 0.0325 - val_loss: 1.6823 - val_accuracy: 0.0230\n",
      "Epoch 66/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.0327\n",
      "Epoch 66: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0089 - accuracy: 0.0327 - val_loss: 1.9199 - val_accuracy: 0.0519\n",
      "Epoch 67/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0663 - accuracy: 0.0324\n",
      "Epoch 67: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0667 - accuracy: 0.0325 - val_loss: 1.8283 - val_accuracy: 0.0225\n",
      "Epoch 68/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.0327\n",
      "Epoch 68: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0431 - accuracy: 0.0327 - val_loss: 1.6718 - val_accuracy: 0.0235\n",
      "Epoch 69/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.0332\n",
      "Epoch 69: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0155 - accuracy: 0.0326 - val_loss: 1.4915 - val_accuracy: 0.0364\n",
      "Epoch 70/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.0329\n",
      "Epoch 70: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0078 - accuracy: 0.0328 - val_loss: 1.7857 - val_accuracy: 0.0359\n",
      "Epoch 71/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.0330\n",
      "Epoch 71: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0124 - accuracy: 0.0328 - val_loss: 1.6593 - val_accuracy: 0.0240\n",
      "Epoch 72/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.0327\n",
      "Epoch 72: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0173 - accuracy: 0.0327 - val_loss: 2.0586 - val_accuracy: 0.0255\n",
      "Epoch 73/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.0318\n",
      "Epoch 73: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0569 - accuracy: 0.0326 - val_loss: 1.7962 - val_accuracy: 0.0744\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.0322\n",
      "Epoch 74: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0178 - accuracy: 0.0322 - val_loss: 1.9815 - val_accuracy: 0.0185\n",
      "Epoch 75/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.0327\n",
      "Epoch 75: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0235 - accuracy: 0.0325 - val_loss: 1.7122 - val_accuracy: 0.0389\n",
      "Epoch 76/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.0329\n",
      "Epoch 76: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0173 - accuracy: 0.0327 - val_loss: 2.3028 - val_accuracy: 0.0155\n",
      "Epoch 77/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.0329\n",
      "Epoch 77: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0207 - accuracy: 0.0327 - val_loss: 1.8026 - val_accuracy: 0.0344\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.0327\n",
      "Epoch 78: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0135 - accuracy: 0.0327 - val_loss: 1.7669 - val_accuracy: 0.0344\n",
      "Epoch 79/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.0326\n",
      "Epoch 79: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0385 - accuracy: 0.0325 - val_loss: 1.8152 - val_accuracy: 0.0594\n",
      "Epoch 80/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.0321\n",
      "Epoch 80: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0177 - accuracy: 0.0326 - val_loss: 1.9676 - val_accuracy: 0.0554\n",
      "Epoch 81/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.0330\n",
      "Epoch 81: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0134 - accuracy: 0.0328 - val_loss: 1.8080 - val_accuracy: 0.0424\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.0325\n",
      "Epoch 82: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0157 - accuracy: 0.0325 - val_loss: 2.1613 - val_accuracy: 0.0275\n",
      "Epoch 83/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.0328\n",
      "Epoch 83: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0210 - accuracy: 0.0328 - val_loss: 1.9299 - val_accuracy: 0.0419\n",
      "Epoch 84/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.0324\n",
      "Epoch 84: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0304 - accuracy: 0.0323 - val_loss: 1.7877 - val_accuracy: 0.0185\n",
      "Epoch 85/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.0326\n",
      "Epoch 85: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0170 - accuracy: 0.0327 - val_loss: 1.8737 - val_accuracy: 0.0270\n",
      "Epoch 86/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.0331\n",
      "Epoch 86: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0151 - accuracy: 0.0328 - val_loss: 1.8488 - val_accuracy: 0.0424\n",
      "Epoch 87/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.0328\n",
      "Epoch 87: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0071 - accuracy: 0.0327 - val_loss: 1.8113 - val_accuracy: 0.0429\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.0330\n",
      "Epoch 88: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0231 - accuracy: 0.0330 - val_loss: 1.7871 - val_accuracy: 0.0210\n",
      "Epoch 89/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.0318\n",
      "Epoch 89: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0534 - accuracy: 0.0321 - val_loss: 1.8591 - val_accuracy: 0.0369\n",
      "Epoch 90/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.0326\n",
      "Epoch 90: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0155 - accuracy: 0.0328 - val_loss: 1.7952 - val_accuracy: 0.0424\n",
      "Epoch 91/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.0326\n",
      "Epoch 91: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0071 - accuracy: 0.0326 - val_loss: 1.7246 - val_accuracy: 0.0424\n",
      "Epoch 92/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.0329\n",
      "Epoch 92: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0025 - accuracy: 0.0327 - val_loss: 1.7640 - val_accuracy: 0.0265\n",
      "Epoch 93/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.0326\n",
      "Epoch 93: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0035 - accuracy: 0.0327 - val_loss: 1.7785 - val_accuracy: 0.0354\n",
      "Epoch 94/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.0331\n",
      "Epoch 94: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0019 - accuracy: 0.0327 - val_loss: 1.8291 - val_accuracy: 0.0374\n",
      "Epoch 95/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.0327\n",
      "Epoch 95: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.0327 - val_loss: 1.9234 - val_accuracy: 0.0464\n",
      "Epoch 96/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.0334\n",
      "Epoch 96: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0897 - accuracy: 0.0333 - val_loss: 1.8023 - val_accuracy: 0.0384\n",
      "Epoch 97/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.0326\n",
      "Epoch 97: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0243 - accuracy: 0.0326 - val_loss: 1.8690 - val_accuracy: 0.0280\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.0326\n",
      "Epoch 98: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0071 - accuracy: 0.0326 - val_loss: 1.6902 - val_accuracy: 0.0414\n",
      "Epoch 99/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.0326\n",
      "Epoch 99: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0048 - accuracy: 0.0327 - val_loss: 1.7377 - val_accuracy: 0.0349\n",
      "Epoch 100/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.0326\n",
      "Epoch 100: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0035 - accuracy: 0.0326 - val_loss: 1.7834 - val_accuracy: 0.0449\n",
      "Epoch 101/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.0324\n",
      "Epoch 101: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0023 - accuracy: 0.0327 - val_loss: 1.8001 - val_accuracy: 0.0220\n",
      "Epoch 102/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.0324\n",
      "Epoch 102: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0031 - accuracy: 0.0327 - val_loss: 1.8976 - val_accuracy: 0.0364\n",
      "Epoch 103/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 0.0323\n",
      "Epoch 103: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0909 - accuracy: 0.0323 - val_loss: 1.8581 - val_accuracy: 0.0235\n",
      "Epoch 104/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.0329\n",
      "Epoch 104: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0338 - accuracy: 0.0327 - val_loss: 1.8805 - val_accuracy: 0.0215\n",
      "Epoch 105/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.0329\n",
      "Epoch 105: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0096 - accuracy: 0.0326 - val_loss: 1.7977 - val_accuracy: 0.0315\n",
      "Epoch 106/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.0326\n",
      "Epoch 106: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0102 - accuracy: 0.0328 - val_loss: 1.7658 - val_accuracy: 0.0389\n",
      "Epoch 107/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.0328\n",
      "Epoch 107: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0056 - accuracy: 0.0326 - val_loss: 1.8029 - val_accuracy: 0.0719\n",
      "Epoch 108/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.0328\n",
      "Epoch 108: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0085 - accuracy: 0.0327 - val_loss: 1.9753 - val_accuracy: 0.0150\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.0328\n",
      "Epoch 109: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0053 - accuracy: 0.0328 - val_loss: 1.9271 - val_accuracy: 0.0524\n",
      "Epoch 110/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.0330\n",
      "Epoch 110: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0253 - accuracy: 0.0328 - val_loss: 1.9863 - val_accuracy: 0.0120\n",
      "Epoch 111/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.0329\n",
      "Epoch 111: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0119 - accuracy: 0.0326 - val_loss: 1.9176 - val_accuracy: 0.0564\n",
      "Epoch 112/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.0325\n",
      "Epoch 112: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0219 - accuracy: 0.0327 - val_loss: 2.4457 - val_accuracy: 0.0115\n",
      "Epoch 113/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.0328\n",
      "Epoch 113: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0272 - accuracy: 0.0325 - val_loss: 1.9244 - val_accuracy: 0.0260\n",
      "Epoch 114/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.0329\n",
      "Epoch 114: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0105 - accuracy: 0.0328 - val_loss: 1.9305 - val_accuracy: 0.0300\n",
      "Epoch 115/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.0323\n",
      "Epoch 115: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0210 - accuracy: 0.0327 - val_loss: 2.2025 - val_accuracy: 0.0205\n",
      "Epoch 116/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.0323\n",
      "Epoch 116: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0236 - accuracy: 0.0326 - val_loss: 2.1036 - val_accuracy: 0.0190\n",
      "Epoch 117/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.0328\n",
      "Epoch 117: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0137 - accuracy: 0.0326 - val_loss: 1.7553 - val_accuracy: 0.0444\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.0328\n",
      "Epoch 118: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0071 - accuracy: 0.0328 - val_loss: 2.0879 - val_accuracy: 0.0624\n",
      "Epoch 119/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.0328\n",
      "Epoch 119: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0041 - accuracy: 0.0328 - val_loss: 1.8158 - val_accuracy: 0.0310\n",
      "Epoch 120/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.0324\n",
      "Epoch 120: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0040 - accuracy: 0.0325 - val_loss: 1.9496 - val_accuracy: 0.0404\n",
      "Epoch 121/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.0329\n",
      "Epoch 121: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0264 - accuracy: 0.0327 - val_loss: 1.9607 - val_accuracy: 0.0394\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.0326\n",
      "Epoch 122: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0321 - accuracy: 0.0326 - val_loss: 1.8657 - val_accuracy: 0.0514\n",
      "Epoch 123/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.0325\n",
      "Epoch 123: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0128 - accuracy: 0.0327 - val_loss: 2.2502 - val_accuracy: 0.0235\n",
      "Epoch 124/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.0331\n",
      "Epoch 124: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0144 - accuracy: 0.0331 - val_loss: 1.9061 - val_accuracy: 0.0200\n",
      "Epoch 125/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.0328\n",
      "Epoch 125: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0141 - accuracy: 0.0326 - val_loss: 2.0337 - val_accuracy: 0.0210\n",
      "Epoch 126/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.0325\n",
      "Epoch 126: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0074 - accuracy: 0.0326 - val_loss: 1.8882 - val_accuracy: 0.0295\n",
      "Epoch 127/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.0325\n",
      "Epoch 127: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0042 - accuracy: 0.0326 - val_loss: 1.9540 - val_accuracy: 0.0285\n",
      "Epoch 128/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.0329\n",
      "Epoch 128: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0306 - accuracy: 0.0326 - val_loss: 2.7417 - val_accuracy: 0.0035\n",
      "Epoch 129/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.0328\n",
      "Epoch 129: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0132 - accuracy: 0.0328 - val_loss: 1.8333 - val_accuracy: 0.0409\n",
      "Epoch 130/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.0329\n",
      "Epoch 130: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0042 - accuracy: 0.0331 - val_loss: 2.6986 - val_accuracy: 0.0150\n",
      "Epoch 131/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.0329\n",
      "Epoch 131: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0041 - accuracy: 0.0328 - val_loss: 1.9958 - val_accuracy: 0.0529\n",
      "Epoch 132/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.0329\n",
      "Epoch 132: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0215 - accuracy: 0.0326 - val_loss: 1.9897 - val_accuracy: 0.0270\n",
      "Epoch 133/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.0322\n",
      "Epoch 133: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0206 - accuracy: 0.0322 - val_loss: 2.2386 - val_accuracy: 0.0265\n",
      "Epoch 134/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.0328\n",
      "Epoch 134: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0157 - accuracy: 0.0327 - val_loss: 2.1022 - val_accuracy: 0.0165\n",
      "Epoch 135/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.0330\n",
      "Epoch 135: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0115 - accuracy: 0.0328 - val_loss: 2.2623 - val_accuracy: 0.0235\n",
      "Epoch 136/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.0325\n",
      "Epoch 136: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0076 - accuracy: 0.0327 - val_loss: 1.8990 - val_accuracy: 0.0330\n",
      "Epoch 137/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.0328\n",
      "Epoch 137: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0172 - accuracy: 0.0326 - val_loss: 1.9325 - val_accuracy: 0.0414\n",
      "Epoch 138/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.0326\n",
      "Epoch 138: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0102 - accuracy: 0.0325 - val_loss: 2.1631 - val_accuracy: 0.0115\n",
      "Epoch 139/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.0326\n",
      "Epoch 139: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0088 - accuracy: 0.0327 - val_loss: 2.1091 - val_accuracy: 0.0275\n",
      "Epoch 140/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.0328\n",
      "Epoch 140: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0163 - accuracy: 0.0327 - val_loss: 2.5888 - val_accuracy: 0.0120\n",
      "Epoch 141/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.0328\n",
      "Epoch 141: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0074 - accuracy: 0.0330 - val_loss: 2.1239 - val_accuracy: 0.0559\n",
      "Epoch 142/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.0327\n",
      "Epoch 142: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0294 - accuracy: 0.0327 - val_loss: 2.0708 - val_accuracy: 0.0250\n",
      "Epoch 143/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.0330\n",
      "Epoch 143: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0136 - accuracy: 0.0330 - val_loss: 2.1150 - val_accuracy: 0.0369\n",
      "Epoch 144/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.0329\n",
      "Epoch 144: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0132 - accuracy: 0.0327 - val_loss: 2.4407 - val_accuracy: 0.0115\n",
      "Epoch 145/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.0329\n",
      "Epoch 145: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0122 - accuracy: 0.0328 - val_loss: 1.9609 - val_accuracy: 0.0429\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.0327\n",
      "Epoch 146: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0080 - accuracy: 0.0327 - val_loss: 2.1247 - val_accuracy: 0.0349\n",
      "Epoch 147/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.0329\n",
      "Epoch 147: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0127 - accuracy: 0.0326 - val_loss: 1.9835 - val_accuracy: 0.0469\n",
      "Epoch 148/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.0331\n",
      "Epoch 148: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0126 - accuracy: 0.0328 - val_loss: 1.9248 - val_accuracy: 0.0250\n",
      "Epoch 149/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0090 - accuracy: 0.0328\n",
      "Epoch 149: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0091 - accuracy: 0.0327 - val_loss: 2.0447 - val_accuracy: 0.0265\n",
      "Epoch 150/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.0329\n",
      "Epoch 150: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0101 - accuracy: 0.0326 - val_loss: 2.0801 - val_accuracy: 0.0190\n",
      "Epoch 151/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.0326\n",
      "Epoch 151: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0158 - accuracy: 0.0328 - val_loss: 2.3228 - val_accuracy: 0.0255\n",
      "Epoch 152/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.0324\n",
      "Epoch 152: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0227 - accuracy: 0.0325 - val_loss: 1.8413 - val_accuracy: 0.0275\n",
      "Epoch 153/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.0325\n",
      "Epoch 153: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0161 - accuracy: 0.0327 - val_loss: 1.9679 - val_accuracy: 0.0275\n",
      "Epoch 154/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.0325\n",
      "Epoch 154: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0060 - accuracy: 0.0326 - val_loss: 1.8709 - val_accuracy: 0.0305\n",
      "Epoch 155/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.0329\n",
      "Epoch 155: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0055 - accuracy: 0.0327 - val_loss: 2.3062 - val_accuracy: 0.0115\n",
      "Epoch 156/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.0330\n",
      "Epoch 156: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0028 - accuracy: 0.0326 - val_loss: 2.0971 - val_accuracy: 0.0364\n",
      "Epoch 157/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.0326\n",
      "Epoch 157: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0064 - accuracy: 0.0326 - val_loss: 2.5621 - val_accuracy: 0.0200\n",
      "Epoch 158/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.0328\n",
      "Epoch 158: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0296 - accuracy: 0.0326 - val_loss: 2.1723 - val_accuracy: 0.0295\n",
      "Epoch 159/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.0331\n",
      "Epoch 159: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0192 - accuracy: 0.0327 - val_loss: 2.2920 - val_accuracy: 0.0165\n",
      "Epoch 160/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.0327\n",
      "Epoch 160: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0079 - accuracy: 0.0327 - val_loss: 2.0658 - val_accuracy: 0.0344\n",
      "Epoch 161/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.0325\n",
      "Epoch 161: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0108 - accuracy: 0.0325 - val_loss: 2.0299 - val_accuracy: 0.0454\n",
      "Epoch 162/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.0323\n",
      "Epoch 162: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0107 - accuracy: 0.0327 - val_loss: 2.1210 - val_accuracy: 0.0325\n",
      "Epoch 163/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.0328\n",
      "Epoch 163: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0034 - accuracy: 0.0327 - val_loss: 2.0256 - val_accuracy: 0.0285\n",
      "Epoch 164/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.0328\n",
      "Epoch 164: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0046 - accuracy: 0.0326 - val_loss: 2.0463 - val_accuracy: 0.0414\n",
      "Epoch 165/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.0326\n",
      "Epoch 165: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0026 - accuracy: 0.0327 - val_loss: 2.1738 - val_accuracy: 0.0559\n",
      "Epoch 166/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.0328\n",
      "Epoch 166: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0374 - accuracy: 0.0327 - val_loss: 2.2325 - val_accuracy: 0.0325\n",
      "Epoch 167/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.0328\n",
      "Epoch 167: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0186 - accuracy: 0.0327 - val_loss: 2.4450 - val_accuracy: 0.0285\n",
      "Epoch 168/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.0323\n",
      "Epoch 168: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0053 - accuracy: 0.0326 - val_loss: 1.9066 - val_accuracy: 0.0320\n",
      "Epoch 169/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.0325\n",
      "Epoch 169: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0044 - accuracy: 0.0327 - val_loss: 1.9352 - val_accuracy: 0.0275\n",
      "Epoch 170/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.0329\n",
      "Epoch 170: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0203 - accuracy: 0.0327 - val_loss: 2.6265 - val_accuracy: 0.0320\n",
      "Epoch 171/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.0323\n",
      "Epoch 171: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0081 - accuracy: 0.0326 - val_loss: 2.1208 - val_accuracy: 0.0864\n",
      "Epoch 172/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.0328\n",
      "Epoch 172: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0023 - accuracy: 0.0328 - val_loss: 1.9969 - val_accuracy: 0.0300\n",
      "Epoch 173/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.0325\n",
      "Epoch 173: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0016 - accuracy: 0.0327 - val_loss: 2.0019 - val_accuracy: 0.0240\n",
      "Epoch 174/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.0326\n",
      "Epoch 174: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0015 - accuracy: 0.0327 - val_loss: 2.2007 - val_accuracy: 0.0275\n",
      "Epoch 175/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 6.0729e-04 - accuracy: 0.0326\n",
      "Epoch 175: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 6.0672e-04 - accuracy: 0.0327 - val_loss: 2.0424 - val_accuracy: 0.0290\n",
      "Epoch 176/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.0326\n",
      "Epoch 176: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0383 - accuracy: 0.0328 - val_loss: 2.3336 - val_accuracy: 0.0110\n",
      "Epoch 177/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.0326\n",
      "Epoch 177: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0314 - accuracy: 0.0327 - val_loss: 2.0456 - val_accuracy: 0.0180\n",
      "Epoch 178/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.0325\n",
      "Epoch 178: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0055 - accuracy: 0.0326 - val_loss: 2.0718 - val_accuracy: 0.0305\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.0326\n",
      "Epoch 179: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0019 - accuracy: 0.0326 - val_loss: 2.0554 - val_accuracy: 0.0369\n",
      "Epoch 180/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.0328\n",
      "Epoch 180: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 9.9632e-04 - accuracy: 0.0327 - val_loss: 1.9443 - val_accuracy: 0.0399\n",
      "Epoch 181/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 6.8704e-04 - accuracy: 0.0325\n",
      "Epoch 181: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 6.7925e-04 - accuracy: 0.0327 - val_loss: 2.0273 - val_accuracy: 0.0290\n",
      "Epoch 182/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 4.0704e-04 - accuracy: 0.0328\n",
      "Epoch 182: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 4.4780e-04 - accuracy: 0.0327 - val_loss: 2.0057 - val_accuracy: 0.0364\n",
      "Epoch 183/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 2.7212e-04 - accuracy: 0.0328\n",
      "Epoch 183: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 2.7143e-04 - accuracy: 0.0327 - val_loss: 2.0305 - val_accuracy: 0.0295\n",
      "Epoch 184/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 2.4083e-04 - accuracy: 0.0325\n",
      "Epoch 184: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 2.4376e-04 - accuracy: 0.0327 - val_loss: 2.0009 - val_accuracy: 0.0260\n",
      "Epoch 185/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 2.2249e-04 - accuracy: 0.0325\n",
      "Epoch 185: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 2.2245e-04 - accuracy: 0.0327 - val_loss: 2.0263 - val_accuracy: 0.0330\n",
      "Epoch 186/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 2.4342e-04 - accuracy: 0.0325\n",
      "Epoch 186: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 2.4290e-04 - accuracy: 0.0327 - val_loss: 2.0340 - val_accuracy: 0.0349\n",
      "Epoch 187/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 2.3020e-04 - accuracy: 0.0329\n",
      "Epoch 187: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 2.2848e-04 - accuracy: 0.0327 - val_loss: 2.0416 - val_accuracy: 0.0364\n",
      "Epoch 188/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 2.9521e-04 - accuracy: 0.0321\n",
      "Epoch 188: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 2.9486e-04 - accuracy: 0.0327 - val_loss: 2.0598 - val_accuracy: 0.0334\n",
      "Epoch 189/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.4763e-04 - accuracy: 0.0327\n",
      "Epoch 189: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.4921e-04 - accuracy: 0.0327 - val_loss: 2.0984 - val_accuracy: 0.0339\n",
      "Epoch 190/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 1.1996e-04 - accuracy: 0.0327\n",
      "Epoch 190: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 1.1980e-04 - accuracy: 0.0327 - val_loss: 2.1380 - val_accuracy: 0.0394\n",
      "Epoch 191/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 1.1056e-04 - accuracy: 0.0328\n",
      "Epoch 191: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 1.0940e-04 - accuracy: 0.0327 - val_loss: 2.1005 - val_accuracy: 0.0354\n",
      "Epoch 192/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 8.0215e-04 - accuracy: 0.0325\n",
      "Epoch 192: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0027 - accuracy: 0.0327 - val_loss: 3.2169 - val_accuracy: 0.0389\n",
      "Epoch 193/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.0330\n",
      "Epoch 193: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.1320 - accuracy: 0.0328 - val_loss: 2.0394 - val_accuracy: 0.0190\n",
      "Epoch 194/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.0325\n",
      "Epoch 194: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0153 - accuracy: 0.0325 - val_loss: 1.7179 - val_accuracy: 0.0325\n",
      "Epoch 195/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.0328\n",
      "Epoch 195: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0035 - accuracy: 0.0326 - val_loss: 1.7469 - val_accuracy: 0.0290\n",
      "Epoch 196/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.0321\n",
      "Epoch 196: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0027 - accuracy: 0.0327 - val_loss: 1.8118 - val_accuracy: 0.0374\n",
      "Epoch 197/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.0319\n",
      "Epoch 197: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0010 - accuracy: 0.0327 - val_loss: 1.8061 - val_accuracy: 0.0379\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 8.3933e-04 - accuracy: 0.0327\n",
      "Epoch 198: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 8.3933e-04 - accuracy: 0.0327 - val_loss: 1.8396 - val_accuracy: 0.0330\n",
      "Epoch 199/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 4.9969e-04 - accuracy: 0.0330\n",
      "Epoch 199: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 4.9864e-04 - accuracy: 0.0327 - val_loss: 1.8205 - val_accuracy: 0.0295\n",
      "Epoch 200/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.0321\n",
      "Epoch 200: val_loss did not improve from 0.72880\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0053 - accuracy: 0.0326 - val_loss: 2.0030 - val_accuracy: 0.0280\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 2.0030 - accuracy: 0.0280\n",
      "63/63 [==============================] - 0s 5ms/step\n",
      "model2 trained\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saidm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cybersecurity-Z7yOgMbu-py3.11\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/251 [============================>.] - ETA: 0s - loss: 0.9418 - accuracy: 0.0023\n",
      "Epoch 1: val_loss improved from inf to 0.88739, saving model to model_3_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 5s 10ms/step - loss: 0.9397 - accuracy: 0.0022 - val_loss: 0.8874 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.7865 - accuracy: 0.0060\n",
      "Epoch 2: val_loss improved from 0.88739 to 0.80806, saving model to model_3_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.7879 - accuracy: 0.0060 - val_loss: 0.8081 - val_accuracy: 0.0025\n",
      "Epoch 3/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.7175 - accuracy: 0.0160\n",
      "Epoch 3: val_loss improved from 0.80806 to 0.76320, saving model to model_3_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.7170 - accuracy: 0.0161 - val_loss: 0.7632 - val_accuracy: 0.0180\n",
      "Epoch 4/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.6609 - accuracy: 0.0229\n",
      "Epoch 4: val_loss improved from 0.76320 to 0.73930, saving model to model_3_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.6622 - accuracy: 0.0227 - val_loss: 0.7393 - val_accuracy: 0.0275\n",
      "Epoch 5/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.6104 - accuracy: 0.0235\n",
      "Epoch 5: val_loss improved from 0.73930 to 0.72740, saving model to model_3_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.6101 - accuracy: 0.0236 - val_loss: 0.7274 - val_accuracy: 0.0434\n",
      "Epoch 6/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.5693 - accuracy: 0.0250\n",
      "Epoch 6: val_loss improved from 0.72740 to 0.71559, saving model to model_3_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.5694 - accuracy: 0.0251 - val_loss: 0.7156 - val_accuracy: 0.0359\n",
      "Epoch 7/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.5236 - accuracy: 0.0265\n",
      "Epoch 7: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.5228 - accuracy: 0.0262 - val_loss: 0.7418 - val_accuracy: 0.0100\n",
      "Epoch 8/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.4806 - accuracy: 0.0264\n",
      "Epoch 8: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.4819 - accuracy: 0.0266 - val_loss: 0.7448 - val_accuracy: 0.0105\n",
      "Epoch 9/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.4416 - accuracy: 0.0270\n",
      "Epoch 9: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.4407 - accuracy: 0.0271 - val_loss: 0.7485 - val_accuracy: 0.0200\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.0287\n",
      "Epoch 10: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.4152 - accuracy: 0.0287 - val_loss: 0.8002 - val_accuracy: 0.0489\n",
      "Epoch 11/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.3772 - accuracy: 0.0273\n",
      "Epoch 11: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.3773 - accuracy: 0.0273 - val_loss: 0.7956 - val_accuracy: 0.0549\n",
      "Epoch 12/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.3389 - accuracy: 0.0288\n",
      "Epoch 12: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.3391 - accuracy: 0.0285 - val_loss: 0.9577 - val_accuracy: 0.0140\n",
      "Epoch 13/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.0285\n",
      "Epoch 13: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.3074 - accuracy: 0.0285 - val_loss: 0.7852 - val_accuracy: 0.0205\n",
      "Epoch 14/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.2851 - accuracy: 0.0277\n",
      "Epoch 14: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.2854 - accuracy: 0.0276 - val_loss: 0.8669 - val_accuracy: 0.0250\n",
      "Epoch 15/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.2495 - accuracy: 0.0297\n",
      "Epoch 15: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.2492 - accuracy: 0.0296 - val_loss: 0.8591 - val_accuracy: 0.0564\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.0310\n",
      "Epoch 16: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.2203 - accuracy: 0.0310 - val_loss: 0.9258 - val_accuracy: 0.0265\n",
      "Epoch 17/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.0305\n",
      "Epoch 17: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.2066 - accuracy: 0.0306 - val_loss: 1.0482 - val_accuracy: 0.0589\n",
      "Epoch 18/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.0301\n",
      "Epoch 18: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.1730 - accuracy: 0.0305 - val_loss: 0.9754 - val_accuracy: 0.0374\n",
      "Epoch 19/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.1599 - accuracy: 0.0305\n",
      "Epoch 19: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.1596 - accuracy: 0.0310 - val_loss: 1.0094 - val_accuracy: 0.0499\n",
      "Epoch 20/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.1392 - accuracy: 0.0319\n",
      "Epoch 20: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.1393 - accuracy: 0.0313 - val_loss: 0.9781 - val_accuracy: 0.0369\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.0307\n",
      "Epoch 21: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1177 - accuracy: 0.0307 - val_loss: 1.1314 - val_accuracy: 0.0135\n",
      "Epoch 22/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.1037 - accuracy: 0.0321\n",
      "Epoch 22: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.1036 - accuracy: 0.0322 - val_loss: 1.2795 - val_accuracy: 0.0100\n",
      "Epoch 23/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.0316\n",
      "Epoch 23: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0934 - accuracy: 0.0316 - val_loss: 1.4831 - val_accuracy: 0.0175\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.0328\n",
      "Epoch 24: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0964 - accuracy: 0.0328 - val_loss: 1.1993 - val_accuracy: 0.0255\n",
      "Epoch 25/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.0316\n",
      "Epoch 25: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0825 - accuracy: 0.0316 - val_loss: 1.2634 - val_accuracy: 0.0260\n",
      "Epoch 26/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.0316\n",
      "Epoch 26: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0768 - accuracy: 0.0316 - val_loss: 1.1987 - val_accuracy: 0.0210\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.0322\n",
      "Epoch 27: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0803 - accuracy: 0.0322 - val_loss: 1.2974 - val_accuracy: 0.0389\n",
      "Epoch 28/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.0323\n",
      "Epoch 28: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0680 - accuracy: 0.0321 - val_loss: 1.3534 - val_accuracy: 0.0160\n",
      "Epoch 29/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0486 - accuracy: 0.0324\n",
      "Epoch 29: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0488 - accuracy: 0.0323 - val_loss: 1.3749 - val_accuracy: 0.0514\n",
      "Epoch 30/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.0312\n",
      "Epoch 30: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0523 - accuracy: 0.0313 - val_loss: 1.3559 - val_accuracy: 0.0349\n",
      "Epoch 31/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.0330\n",
      "Epoch 31: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0525 - accuracy: 0.0327 - val_loss: 1.4410 - val_accuracy: 0.0300\n",
      "Epoch 32/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.0323\n",
      "Epoch 32: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0433 - accuracy: 0.0321 - val_loss: 1.5163 - val_accuracy: 0.0589\n",
      "Epoch 33/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.0325\n",
      "Epoch 33: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0732 - accuracy: 0.0325 - val_loss: 1.4585 - val_accuracy: 0.0295\n",
      "Epoch 34/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.0324\n",
      "Epoch 34: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0487 - accuracy: 0.0323 - val_loss: 1.5740 - val_accuracy: 0.0150\n",
      "Epoch 35/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.0323\n",
      "Epoch 35: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0359 - accuracy: 0.0320 - val_loss: 1.5328 - val_accuracy: 0.0439\n",
      "Epoch 36/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.0318\n",
      "Epoch 36: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0269 - accuracy: 0.0322 - val_loss: 1.5290 - val_accuracy: 0.0330\n",
      "Epoch 37/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.0324\n",
      "Epoch 37: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0202 - accuracy: 0.0325 - val_loss: 1.6290 - val_accuracy: 0.0270\n",
      "Epoch 38/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.0326\n",
      "Epoch 38: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0233 - accuracy: 0.0328 - val_loss: 1.6339 - val_accuracy: 0.0165\n",
      "Epoch 39/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 0.0321\n",
      "Epoch 39: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0826 - accuracy: 0.0321 - val_loss: 1.5844 - val_accuracy: 0.0334\n",
      "Epoch 40/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.0328\n",
      "Epoch 40: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0338 - accuracy: 0.0325 - val_loss: 1.5087 - val_accuracy: 0.0354\n",
      "Epoch 41/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.0322\n",
      "Epoch 41: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0251 - accuracy: 0.0322 - val_loss: 1.6301 - val_accuracy: 0.0334\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.0323\n",
      "Epoch 42: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0444 - accuracy: 0.0323 - val_loss: 1.6853 - val_accuracy: 0.0255\n",
      "Epoch 43/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.0331\n",
      "Epoch 43: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0272 - accuracy: 0.0332 - val_loss: 1.6623 - val_accuracy: 0.0185\n",
      "Epoch 44/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.0323\n",
      "Epoch 44: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0219 - accuracy: 0.0325 - val_loss: 1.6956 - val_accuracy: 0.0220\n",
      "Epoch 45/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.0329\n",
      "Epoch 45: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0439 - accuracy: 0.0325 - val_loss: 1.7787 - val_accuracy: 0.0185\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.0328\n",
      "Epoch 46: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0340 - accuracy: 0.0328 - val_loss: 1.6622 - val_accuracy: 0.0175\n",
      "Epoch 47/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.0325\n",
      "Epoch 47: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0154 - accuracy: 0.0323 - val_loss: 1.8555 - val_accuracy: 0.0155\n",
      "Epoch 48/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.0323\n",
      "Epoch 48: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0251 - accuracy: 0.0326 - val_loss: 1.7825 - val_accuracy: 0.0404\n",
      "Epoch 49/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.0326\n",
      "Epoch 49: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0231 - accuracy: 0.0328 - val_loss: 1.7778 - val_accuracy: 0.0349\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.0327\n",
      "Epoch 50: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0226 - accuracy: 0.0327 - val_loss: 1.8317 - val_accuracy: 0.0190\n",
      "Epoch 51/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 0.0323\n",
      "Epoch 51: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0468 - accuracy: 0.0326 - val_loss: 1.7213 - val_accuracy: 0.0245\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.0322\n",
      "Epoch 52: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0320 - accuracy: 0.0322 - val_loss: 1.8341 - val_accuracy: 0.0404\n",
      "Epoch 53/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.0323\n",
      "Epoch 53: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0326 - accuracy: 0.0326 - val_loss: 1.9413 - val_accuracy: 0.0105\n",
      "Epoch 54/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.0325\n",
      "Epoch 54: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0142 - accuracy: 0.0325 - val_loss: 1.7869 - val_accuracy: 0.0364\n",
      "Epoch 55/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.0326\n",
      "Epoch 55: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0145 - accuracy: 0.0326 - val_loss: 1.8102 - val_accuracy: 0.0389\n",
      "Epoch 56/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.0328\n",
      "Epoch 56: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0169 - accuracy: 0.0327 - val_loss: 1.9549 - val_accuracy: 0.0300\n",
      "Epoch 57/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.0324\n",
      "Epoch 57: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0360 - accuracy: 0.0325 - val_loss: 1.7918 - val_accuracy: 0.0389\n",
      "Epoch 58/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.0326\n",
      "Epoch 58: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0296 - accuracy: 0.0328 - val_loss: 1.7714 - val_accuracy: 0.0434\n",
      "Epoch 59/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.0328\n",
      "Epoch 59: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0286 - accuracy: 0.0330 - val_loss: 2.0262 - val_accuracy: 0.0105\n",
      "Epoch 60/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.0328\n",
      "Epoch 60: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0165 - accuracy: 0.0327 - val_loss: 1.8538 - val_accuracy: 0.0205\n",
      "Epoch 61/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.0326\n",
      "Epoch 61: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0184 - accuracy: 0.0326 - val_loss: 2.0077 - val_accuracy: 0.0140\n",
      "Epoch 62/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.0323\n",
      "Epoch 62: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0233 - accuracy: 0.0323 - val_loss: 2.0917 - val_accuracy: 0.0494\n",
      "Epoch 63/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.0319\n",
      "Epoch 63: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0375 - accuracy: 0.0323 - val_loss: 1.9401 - val_accuracy: 0.0160\n",
      "Epoch 64/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.0325\n",
      "Epoch 64: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0261 - accuracy: 0.0323 - val_loss: 1.9843 - val_accuracy: 0.0225\n",
      "Epoch 65/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.0326\n",
      "Epoch 65: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0147 - accuracy: 0.0327 - val_loss: 1.9737 - val_accuracy: 0.0354\n",
      "Epoch 66/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.0324\n",
      "Epoch 66: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0123 - accuracy: 0.0325 - val_loss: 1.9670 - val_accuracy: 0.0479\n",
      "Epoch 67/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.0323\n",
      "Epoch 67: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0145 - accuracy: 0.0325 - val_loss: 2.1008 - val_accuracy: 0.0155\n",
      "Epoch 68/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.0321\n",
      "Epoch 68: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0321 - accuracy: 0.0323 - val_loss: 2.1527 - val_accuracy: 0.0489\n",
      "Epoch 69/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.0326\n",
      "Epoch 69: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0343 - accuracy: 0.0323 - val_loss: 2.0011 - val_accuracy: 0.0429\n",
      "Epoch 70/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.0325\n",
      "Epoch 70: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0180 - accuracy: 0.0323 - val_loss: 2.0060 - val_accuracy: 0.0285\n",
      "Epoch 71/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.0320\n",
      "Epoch 71: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0163 - accuracy: 0.0323 - val_loss: 1.9938 - val_accuracy: 0.0504\n",
      "Epoch 72/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.0330\n",
      "Epoch 72: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0108 - accuracy: 0.0328 - val_loss: 2.0334 - val_accuracy: 0.0205\n",
      "Epoch 73/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.0324\n",
      "Epoch 73: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0090 - accuracy: 0.0326 - val_loss: 2.1388 - val_accuracy: 0.0444\n",
      "Epoch 74/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.0324\n",
      "Epoch 74: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0252 - accuracy: 0.0327 - val_loss: 2.0937 - val_accuracy: 0.0195\n",
      "Epoch 75/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.0321\n",
      "Epoch 75: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0189 - accuracy: 0.0323 - val_loss: 2.0110 - val_accuracy: 0.0499\n",
      "Epoch 76/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.0324\n",
      "Epoch 76: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0208 - accuracy: 0.0325 - val_loss: 2.1896 - val_accuracy: 0.0130\n",
      "Epoch 77/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.0326\n",
      "Epoch 77: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0221 - accuracy: 0.0330 - val_loss: 1.9951 - val_accuracy: 0.0399\n",
      "Epoch 78/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.0324\n",
      "Epoch 78: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0125 - accuracy: 0.0323 - val_loss: 2.0463 - val_accuracy: 0.0220\n",
      "Epoch 79/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.0322\n",
      "Epoch 79: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0107 - accuracy: 0.0323 - val_loss: 2.0552 - val_accuracy: 0.0300\n",
      "Epoch 80/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.0326\n",
      "Epoch 80: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0140 - accuracy: 0.0327 - val_loss: 2.2242 - val_accuracy: 0.0265\n",
      "Epoch 81/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.0327\n",
      "Epoch 81: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0343 - accuracy: 0.0328 - val_loss: 1.9945 - val_accuracy: 0.0240\n",
      "Epoch 82/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.0323\n",
      "Epoch 82: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0354 - accuracy: 0.0323 - val_loss: 1.9336 - val_accuracy: 0.0270\n",
      "Epoch 83/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.0329\n",
      "Epoch 83: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0213 - accuracy: 0.0327 - val_loss: 2.0598 - val_accuracy: 0.0285\n",
      "Epoch 84/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.0324\n",
      "Epoch 84: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0104 - accuracy: 0.0325 - val_loss: 1.9891 - val_accuracy: 0.0190\n",
      "Epoch 85/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.0328\n",
      "Epoch 85: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0086 - accuracy: 0.0326 - val_loss: 1.8985 - val_accuracy: 0.0295\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.0326\n",
      "Epoch 86: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0045 - accuracy: 0.0326 - val_loss: 1.9542 - val_accuracy: 0.0175\n",
      "Epoch 87/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.0325\n",
      "Epoch 87: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0020 - accuracy: 0.0326 - val_loss: 2.1174 - val_accuracy: 0.0190\n",
      "Epoch 88/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.0323\n",
      "Epoch 88: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0121 - accuracy: 0.0327 - val_loss: 2.6983 - val_accuracy: 0.0070\n",
      "Epoch 89/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.0323\n",
      "Epoch 89: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0529 - accuracy: 0.0325 - val_loss: 2.0944 - val_accuracy: 0.0105\n",
      "Epoch 90/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.0326\n",
      "Epoch 90: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0167 - accuracy: 0.0326 - val_loss: 2.2380 - val_accuracy: 0.0165\n",
      "Epoch 91/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.0325\n",
      "Epoch 91: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0067 - accuracy: 0.0325 - val_loss: 2.0574 - val_accuracy: 0.0325\n",
      "Epoch 92/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.0327\n",
      "Epoch 92: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0117 - accuracy: 0.0325 - val_loss: 2.3986 - val_accuracy: 0.0330\n",
      "Epoch 93/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.0320\n",
      "Epoch 93: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0228 - accuracy: 0.0322 - val_loss: 2.0852 - val_accuracy: 0.0374\n",
      "Epoch 94/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.0329\n",
      "Epoch 94: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0276 - accuracy: 0.0327 - val_loss: 2.0499 - val_accuracy: 0.0200\n",
      "Epoch 95/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.0327\n",
      "Epoch 95: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0178 - accuracy: 0.0328 - val_loss: 2.2413 - val_accuracy: 0.0100\n",
      "Epoch 96/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.0324\n",
      "Epoch 96: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0051 - accuracy: 0.0326 - val_loss: 2.0811 - val_accuracy: 0.0215\n",
      "Epoch 97/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.0328\n",
      "Epoch 97: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0153 - accuracy: 0.0327 - val_loss: 2.0510 - val_accuracy: 0.0305\n",
      "Epoch 98/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.0325\n",
      "Epoch 98: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0461 - accuracy: 0.0326 - val_loss: 1.9393 - val_accuracy: 0.0354\n",
      "Epoch 99/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.0328\n",
      "Epoch 99: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0135 - accuracy: 0.0328 - val_loss: 1.8202 - val_accuracy: 0.0374\n",
      "Epoch 100/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.0326\n",
      "Epoch 100: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0075 - accuracy: 0.0325 - val_loss: 2.1521 - val_accuracy: 0.0205\n",
      "Epoch 101/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.0326\n",
      "Epoch 101: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0024 - accuracy: 0.0326 - val_loss: 1.8899 - val_accuracy: 0.0250\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.0326\n",
      "Epoch 102: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0011 - accuracy: 0.0326 - val_loss: 1.9906 - val_accuracy: 0.0240\n",
      "Epoch 103/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.0321\n",
      "Epoch 103: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0011 - accuracy: 0.0326 - val_loss: 2.0686 - val_accuracy: 0.0190\n",
      "Epoch 104/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 9.2405e-04 - accuracy: 0.0318\n",
      "Epoch 104: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 9.2101e-04 - accuracy: 0.0326 - val_loss: 2.0122 - val_accuracy: 0.0290\n",
      "Epoch 105/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.0330\n",
      "Epoch 105: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0457 - accuracy: 0.0330 - val_loss: 2.1659 - val_accuracy: 0.0240\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.0328\n",
      "Epoch 106: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0402 - accuracy: 0.0328 - val_loss: 2.1095 - val_accuracy: 0.0155\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.0326\n",
      "Epoch 107: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0091 - accuracy: 0.0326 - val_loss: 2.6432 - val_accuracy: 0.0040\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.0327\n",
      "Epoch 108: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0054 - accuracy: 0.0327 - val_loss: 1.9694 - val_accuracy: 0.0414\n",
      "Epoch 109/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.0326\n",
      "Epoch 109: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0025 - accuracy: 0.0326 - val_loss: 1.9584 - val_accuracy: 0.0354\n",
      "Epoch 110/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.0328\n",
      "Epoch 110: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0049 - accuracy: 0.0327 - val_loss: 2.0580 - val_accuracy: 0.0359\n",
      "Epoch 111/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.0326\n",
      "Epoch 111: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0315 - accuracy: 0.0326 - val_loss: 2.4276 - val_accuracy: 0.0185\n",
      "Epoch 112/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.0324\n",
      "Epoch 112: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0218 - accuracy: 0.0323 - val_loss: 2.0213 - val_accuracy: 0.0364\n",
      "Epoch 113/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.0324\n",
      "Epoch 113: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0202 - accuracy: 0.0323 - val_loss: 2.2523 - val_accuracy: 0.0230\n",
      "Epoch 114/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.0329\n",
      "Epoch 114: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0101 - accuracy: 0.0327 - val_loss: 2.0327 - val_accuracy: 0.0225\n",
      "Epoch 115/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.0327\n",
      "Epoch 115: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0053 - accuracy: 0.0327 - val_loss: 1.9718 - val_accuracy: 0.0190\n",
      "Epoch 116/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.0325\n",
      "Epoch 116: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0016 - accuracy: 0.0326 - val_loss: 2.0265 - val_accuracy: 0.0210\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 8.3524e-04 - accuracy: 0.0326\n",
      "Epoch 117: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 8.3524e-04 - accuracy: 0.0326 - val_loss: 2.1044 - val_accuracy: 0.0215\n",
      "Epoch 118/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.0334\n",
      "Epoch 118: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0347 - accuracy: 0.0333 - val_loss: 2.0967 - val_accuracy: 0.0364\n",
      "Epoch 119/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.0325\n",
      "Epoch 119: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0255 - accuracy: 0.0326 - val_loss: 2.1239 - val_accuracy: 0.0300\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.0325\n",
      "Epoch 120: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0077 - accuracy: 0.0325 - val_loss: 2.0508 - val_accuracy: 0.0260\n",
      "Epoch 121/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.0326\n",
      "Epoch 121: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0027 - accuracy: 0.0326 - val_loss: 2.0585 - val_accuracy: 0.0260\n",
      "Epoch 122/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.0325\n",
      "Epoch 122: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0032 - accuracy: 0.0326 - val_loss: 2.1040 - val_accuracy: 0.0225\n",
      "Epoch 123/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.0328\n",
      "Epoch 123: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0012 - accuracy: 0.0326 - val_loss: 2.0705 - val_accuracy: 0.0320\n",
      "Epoch 124/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 8.5709e-04 - accuracy: 0.0321\n",
      "Epoch 124: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.0326 - val_loss: 2.0999 - val_accuracy: 0.0200\n",
      "Epoch 125/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.0326\n",
      "Epoch 125: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0423 - accuracy: 0.0328 - val_loss: 2.4063 - val_accuracy: 0.0539\n",
      "Epoch 126/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.0325\n",
      "Epoch 126: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0296 - accuracy: 0.0325 - val_loss: 1.9832 - val_accuracy: 0.0195\n",
      "Epoch 127/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.0325\n",
      "Epoch 127: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0174 - accuracy: 0.0325 - val_loss: 1.9892 - val_accuracy: 0.0330\n",
      "Epoch 128/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.0330\n",
      "Epoch 128: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0037 - accuracy: 0.0328 - val_loss: 2.0580 - val_accuracy: 0.0290\n",
      "Epoch 129/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.0328\n",
      "Epoch 129: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0049 - accuracy: 0.0325 - val_loss: 1.9750 - val_accuracy: 0.0280\n",
      "Epoch 130/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.0326\n",
      "Epoch 130: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0024 - accuracy: 0.0326 - val_loss: 1.9997 - val_accuracy: 0.0389\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.0326\n",
      "Epoch 131: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0013 - accuracy: 0.0326 - val_loss: 2.2084 - val_accuracy: 0.0195\n",
      "Epoch 132/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.0325\n",
      "Epoch 132: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0222 - accuracy: 0.0325 - val_loss: 2.1740 - val_accuracy: 0.0170\n",
      "Epoch 133/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.0324\n",
      "Epoch 133: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0427 - accuracy: 0.0325 - val_loss: 2.4244 - val_accuracy: 0.0419\n",
      "Epoch 134/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.0329\n",
      "Epoch 134: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0188 - accuracy: 0.0330 - val_loss: 2.1526 - val_accuracy: 0.0245\n",
      "Epoch 135/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.0325\n",
      "Epoch 135: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0097 - accuracy: 0.0326 - val_loss: 2.2012 - val_accuracy: 0.0185\n",
      "Epoch 136/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.0329\n",
      "Epoch 136: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0030 - accuracy: 0.0327 - val_loss: 2.0740 - val_accuracy: 0.0265\n",
      "Epoch 137/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.0325\n",
      "Epoch 137: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0022 - accuracy: 0.0323 - val_loss: 2.0029 - val_accuracy: 0.0424\n",
      "Epoch 138/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.0327\n",
      "Epoch 138: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0143 - accuracy: 0.0325 - val_loss: 2.1796 - val_accuracy: 0.0290\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.0323\n",
      "Epoch 139: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0183 - accuracy: 0.0323 - val_loss: 2.0929 - val_accuracy: 0.0170\n",
      "Epoch 140/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.0321\n",
      "Epoch 140: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0186 - accuracy: 0.0322 - val_loss: 2.4133 - val_accuracy: 0.0210\n",
      "Epoch 141/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.0324\n",
      "Epoch 141: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0078 - accuracy: 0.0325 - val_loss: 2.0872 - val_accuracy: 0.0225\n",
      "Epoch 142/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.0332\n",
      "Epoch 142: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0070 - accuracy: 0.0328 - val_loss: 2.2349 - val_accuracy: 0.0160\n",
      "Epoch 143/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.0326\n",
      "Epoch 143: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0068 - accuracy: 0.0326 - val_loss: 2.0456 - val_accuracy: 0.0180\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.0327\n",
      "Epoch 144: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0041 - accuracy: 0.0327 - val_loss: 2.5904 - val_accuracy: 0.0070\n",
      "Epoch 145/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.0324\n",
      "Epoch 145: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0143 - accuracy: 0.0323 - val_loss: 2.9199 - val_accuracy: 0.0055\n",
      "Epoch 146/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.0325\n",
      "Epoch 146: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0266 - accuracy: 0.0326 - val_loss: 2.1055 - val_accuracy: 0.0185\n",
      "Epoch 147/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.0327\n",
      "Epoch 147: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0066 - accuracy: 0.0326 - val_loss: 2.1618 - val_accuracy: 0.0265\n",
      "Epoch 148/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.0325\n",
      "Epoch 148: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0097 - accuracy: 0.0323 - val_loss: 2.1276 - val_accuracy: 0.0359\n",
      "Epoch 149/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.0324\n",
      "Epoch 149: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0157 - accuracy: 0.0323 - val_loss: 2.2270 - val_accuracy: 0.0225\n",
      "Epoch 150/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.0325\n",
      "Epoch 150: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0066 - accuracy: 0.0327 - val_loss: 2.3025 - val_accuracy: 0.0220\n",
      "Epoch 151/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.0328\n",
      "Epoch 151: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0045 - accuracy: 0.0326 - val_loss: 2.1298 - val_accuracy: 0.0349\n",
      "Epoch 152/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.0324\n",
      "Epoch 152: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0127 - accuracy: 0.0327 - val_loss: 2.2113 - val_accuracy: 0.0260\n",
      "Epoch 153/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.0326\n",
      "Epoch 153: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0126 - accuracy: 0.0326 - val_loss: 2.1764 - val_accuracy: 0.0135\n",
      "Epoch 154/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.0326\n",
      "Epoch 154: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0082 - accuracy: 0.0326 - val_loss: 2.2003 - val_accuracy: 0.0315\n",
      "Epoch 155/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.0329\n",
      "Epoch 155: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0156 - accuracy: 0.0326 - val_loss: 2.3268 - val_accuracy: 0.0115\n",
      "Epoch 156/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.0321\n",
      "Epoch 156: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0105 - accuracy: 0.0326 - val_loss: 2.2074 - val_accuracy: 0.0180\n",
      "Epoch 157/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.0326\n",
      "Epoch 157: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0074 - accuracy: 0.0326 - val_loss: 2.1762 - val_accuracy: 0.0305\n",
      "Epoch 158/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.0326\n",
      "Epoch 158: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0065 - accuracy: 0.0326 - val_loss: 2.2761 - val_accuracy: 0.0265\n",
      "Epoch 159/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.0323\n",
      "Epoch 159: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0162 - accuracy: 0.0327 - val_loss: 2.2502 - val_accuracy: 0.0334\n",
      "Epoch 160/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.0326\n",
      "Epoch 160: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0192 - accuracy: 0.0326 - val_loss: 2.2442 - val_accuracy: 0.0250\n",
      "Epoch 161/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.0323\n",
      "Epoch 161: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0284 - accuracy: 0.0323 - val_loss: 2.0035 - val_accuracy: 0.0155\n",
      "Epoch 162/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.0328\n",
      "Epoch 162: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0034 - accuracy: 0.0326 - val_loss: 2.0697 - val_accuracy: 0.0205\n",
      "Epoch 163/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.0320\n",
      "Epoch 163: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0035 - accuracy: 0.0326 - val_loss: 2.0229 - val_accuracy: 0.0389\n",
      "Epoch 164/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.0326\n",
      "Epoch 164: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0061 - accuracy: 0.0326 - val_loss: 2.3105 - val_accuracy: 0.0185\n",
      "Epoch 165/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.0330\n",
      "Epoch 165: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0135 - accuracy: 0.0330 - val_loss: 2.1647 - val_accuracy: 0.0354\n",
      "Epoch 166/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.0326\n",
      "Epoch 166: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0062 - accuracy: 0.0325 - val_loss: 2.2033 - val_accuracy: 0.0384\n",
      "Epoch 167/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.0326\n",
      "Epoch 167: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0088 - accuracy: 0.0325 - val_loss: 2.5790 - val_accuracy: 0.0260\n",
      "Epoch 168/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.0321\n",
      "Epoch 168: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0058 - accuracy: 0.0326 - val_loss: 2.0385 - val_accuracy: 0.0280\n",
      "Epoch 169/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.0326\n",
      "Epoch 169: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0012 - accuracy: 0.0326 - val_loss: 2.3475 - val_accuracy: 0.0205\n",
      "Epoch 170/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 4.9731e-04 - accuracy: 0.0328\n",
      "Epoch 170: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 4.9046e-04 - accuracy: 0.0326 - val_loss: 2.2290 - val_accuracy: 0.0190\n",
      "Epoch 171/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 3.6880e-04 - accuracy: 0.0326\n",
      "Epoch 171: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 3.6804e-04 - accuracy: 0.0326 - val_loss: 2.2098 - val_accuracy: 0.0250\n",
      "Epoch 172/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.0330\n",
      "Epoch 172: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0215 - accuracy: 0.0328 - val_loss: 2.5780 - val_accuracy: 0.0195\n",
      "Epoch 173/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.0319\n",
      "Epoch 173: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0463 - accuracy: 0.0318 - val_loss: 2.0399 - val_accuracy: 0.0220\n",
      "Epoch 174/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.0329\n",
      "Epoch 174: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0075 - accuracy: 0.0330 - val_loss: 2.0345 - val_accuracy: 0.0175\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.0325\n",
      "Epoch 175: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0027 - accuracy: 0.0325 - val_loss: 2.0341 - val_accuracy: 0.0260\n",
      "Epoch 176/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.0326\n",
      "Epoch 176: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0039 - accuracy: 0.0326 - val_loss: 2.0759 - val_accuracy: 0.0230\n",
      "Epoch 177/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.0324\n",
      "Epoch 177: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0109 - accuracy: 0.0325 - val_loss: 2.1128 - val_accuracy: 0.0230\n",
      "Epoch 178/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.0326\n",
      "Epoch 178: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0081 - accuracy: 0.0327 - val_loss: 2.6411 - val_accuracy: 0.0085\n",
      "Epoch 179/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.0323\n",
      "Epoch 179: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0130 - accuracy: 0.0325 - val_loss: 2.3319 - val_accuracy: 0.0240\n",
      "Epoch 180/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.0325\n",
      "Epoch 180: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0077 - accuracy: 0.0325 - val_loss: 2.2232 - val_accuracy: 0.0469\n",
      "Epoch 181/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.0332\n",
      "Epoch 181: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0051 - accuracy: 0.0326 - val_loss: 2.1909 - val_accuracy: 0.0255\n",
      "Epoch 182/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.0325\n",
      "Epoch 182: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0082 - accuracy: 0.0325 - val_loss: 2.2489 - val_accuracy: 0.0619\n",
      "Epoch 183/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.0326\n",
      "Epoch 183: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0144 - accuracy: 0.0327 - val_loss: 2.5316 - val_accuracy: 0.0215\n",
      "Epoch 184/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.0326\n",
      "Epoch 184: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0108 - accuracy: 0.0326 - val_loss: 2.1957 - val_accuracy: 0.0339\n",
      "Epoch 185/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.0326\n",
      "Epoch 185: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0038 - accuracy: 0.0326 - val_loss: 2.3276 - val_accuracy: 0.0140\n",
      "Epoch 186/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.0324\n",
      "Epoch 186: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0218 - accuracy: 0.0325 - val_loss: 2.2001 - val_accuracy: 0.0434\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.0326\n",
      "Epoch 187: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0073 - accuracy: 0.0326 - val_loss: 2.1500 - val_accuracy: 0.0439\n",
      "Epoch 188/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.0326\n",
      "Epoch 188: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0020 - accuracy: 0.0326 - val_loss: 2.2670 - val_accuracy: 0.0225\n",
      "Epoch 189/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.0326\n",
      "Epoch 189: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0012 - accuracy: 0.0326 - val_loss: 2.1884 - val_accuracy: 0.0200\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.0326\n",
      "Epoch 190: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0011 - accuracy: 0.0326 - val_loss: 2.4005 - val_accuracy: 0.0325\n",
      "Epoch 191/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.0323\n",
      "Epoch 191: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0133 - accuracy: 0.0326 - val_loss: 2.4714 - val_accuracy: 0.0200\n",
      "Epoch 192/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.0329\n",
      "Epoch 192: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0364 - accuracy: 0.0327 - val_loss: 2.6786 - val_accuracy: 0.0105\n",
      "Epoch 193/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.0326\n",
      "Epoch 193: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0170 - accuracy: 0.0327 - val_loss: 2.0558 - val_accuracy: 0.0285\n",
      "Epoch 194/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.0326\n",
      "Epoch 194: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0055 - accuracy: 0.0326 - val_loss: 2.1639 - val_accuracy: 0.0260\n",
      "Epoch 195/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.0323\n",
      "Epoch 195: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0022 - accuracy: 0.0325 - val_loss: 2.2600 - val_accuracy: 0.0095\n",
      "Epoch 196/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.0326\n",
      "Epoch 196: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0011 - accuracy: 0.0326 - val_loss: 2.1664 - val_accuracy: 0.0240\n",
      "Epoch 197/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 5.1496e-04 - accuracy: 0.0325\n",
      "Epoch 197: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 5.5777e-04 - accuracy: 0.0326 - val_loss: 2.2303 - val_accuracy: 0.0180\n",
      "Epoch 198/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.0326\n",
      "Epoch 198: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0017 - accuracy: 0.0326 - val_loss: 2.2787 - val_accuracy: 0.0235\n",
      "Epoch 199/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.0328\n",
      "Epoch 199: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0095 - accuracy: 0.0326 - val_loss: 2.7842 - val_accuracy: 0.0025\n",
      "Epoch 200/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.0323\n",
      "Epoch 200: val_loss did not improve from 0.71559\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0203 - accuracy: 0.0323 - val_loss: 2.4213 - val_accuracy: 0.0320\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 2.4213 - accuracy: 0.0320\n",
      "63/63 [==============================] - 0s 5ms/step\n",
      "model3 trained\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saidm\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\cybersecurity-Z7yOgMbu-py3.11\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249/251 [============================>.] - ETA: 0s - loss: 0.9340 - accuracy: 0.0010    \n",
      "Epoch 1: val_loss improved from inf to 0.89692, saving model to model_4_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 5s 12ms/step - loss: 0.9335 - accuracy: 9.9850e-04 - val_loss: 0.8969 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.7991 - accuracy: 0.0074\n",
      "Epoch 2: val_loss improved from 0.89692 to 0.81079, saving model to model_4_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.7991 - accuracy: 0.0074 - val_loss: 0.8108 - val_accuracy: 0.0210\n",
      "Epoch 3/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.7347 - accuracy: 0.0177\n",
      "Epoch 3: val_loss improved from 0.81079 to 0.80283, saving model to model_4_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.7344 - accuracy: 0.0178 - val_loss: 0.8028 - val_accuracy: 0.0110\n",
      "Epoch 4/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.6797 - accuracy: 0.0226\n",
      "Epoch 4: val_loss improved from 0.80283 to 0.74296, saving model to model_4_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.6806 - accuracy: 0.0228 - val_loss: 0.7430 - val_accuracy: 0.0095\n",
      "Epoch 5/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.6406 - accuracy: 0.0243\n",
      "Epoch 5: val_loss improved from 0.74296 to 0.73227, saving model to model_4_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.6397 - accuracy: 0.0245 - val_loss: 0.7323 - val_accuracy: 0.0185\n",
      "Epoch 6/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.0281\n",
      "Epoch 6: val_loss improved from 0.73227 to 0.72770, saving model to model_4_checkpoint\\cp.ckpt\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.5999 - accuracy: 0.0278 - val_loss: 0.7277 - val_accuracy: 0.0195\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.5626 - accuracy: 0.0288\n",
      "Epoch 7: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.5626 - accuracy: 0.0288 - val_loss: 0.7423 - val_accuracy: 0.0090\n",
      "Epoch 8/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.0277\n",
      "Epoch 8: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.5305 - accuracy: 0.0277 - val_loss: 0.9975 - val_accuracy: 0.1018\n",
      "Epoch 9/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.4926 - accuracy: 0.0295\n",
      "Epoch 9: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.4934 - accuracy: 0.0291 - val_loss: 0.7789 - val_accuracy: 0.0030\n",
      "Epoch 10/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.4645 - accuracy: 0.0278\n",
      "Epoch 10: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.4666 - accuracy: 0.0285 - val_loss: 0.8654 - val_accuracy: 0.0819\n",
      "Epoch 11/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.4350 - accuracy: 0.0286\n",
      "Epoch 11: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.4346 - accuracy: 0.0287 - val_loss: 0.7733 - val_accuracy: 0.0130\n",
      "Epoch 12/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.3997 - accuracy: 0.0304\n",
      "Epoch 12: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.3997 - accuracy: 0.0303 - val_loss: 0.9242 - val_accuracy: 0.1053\n",
      "Epoch 13/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.3802 - accuracy: 0.0296\n",
      "Epoch 13: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.3798 - accuracy: 0.0296 - val_loss: 0.8235 - val_accuracy: 0.0080\n",
      "Epoch 14/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.3503 - accuracy: 0.0312\n",
      "Epoch 14: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.3505 - accuracy: 0.0312 - val_loss: 0.8858 - val_accuracy: 0.0060\n",
      "Epoch 15/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.0301\n",
      "Epoch 15: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.3192 - accuracy: 0.0301 - val_loss: 0.7777 - val_accuracy: 0.0185\n",
      "Epoch 16/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.3042 - accuracy: 0.0300\n",
      "Epoch 16: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.3035 - accuracy: 0.0301 - val_loss: 0.8488 - val_accuracy: 0.0095\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.0302\n",
      "Epoch 17: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.2744 - accuracy: 0.0302 - val_loss: 0.9043 - val_accuracy: 0.0649\n",
      "Epoch 18/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.2515 - accuracy: 0.0302\n",
      "Epoch 18: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.2513 - accuracy: 0.0305 - val_loss: 1.1383 - val_accuracy: 0.0824\n",
      "Epoch 19/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.2265 - accuracy: 0.0308\n",
      "Epoch 19: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.2269 - accuracy: 0.0308 - val_loss: 0.9316 - val_accuracy: 0.0240\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.0311\n",
      "Epoch 20: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.2117 - accuracy: 0.0311 - val_loss: 0.9679 - val_accuracy: 0.0454\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.0318\n",
      "Epoch 21: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1835 - accuracy: 0.0318 - val_loss: 0.9301 - val_accuracy: 0.0190\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.0315\n",
      "Epoch 22: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1693 - accuracy: 0.0315 - val_loss: 0.9752 - val_accuracy: 0.0275\n",
      "Epoch 23/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.0324\n",
      "Epoch 23: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1550 - accuracy: 0.0322 - val_loss: 1.0034 - val_accuracy: 0.0115\n",
      "Epoch 24/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.0316\n",
      "Epoch 24: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.1445 - accuracy: 0.0320 - val_loss: 1.0677 - val_accuracy: 0.0554\n",
      "Epoch 25/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.0315\n",
      "Epoch 25: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.1225 - accuracy: 0.0315 - val_loss: 1.0407 - val_accuracy: 0.0225\n",
      "Epoch 26/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.0314\n",
      "Epoch 26: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.1082 - accuracy: 0.0315 - val_loss: 1.1903 - val_accuracy: 0.0719\n",
      "Epoch 27/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.0330\n",
      "Epoch 27: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.1009 - accuracy: 0.0330 - val_loss: 1.0634 - val_accuracy: 0.0175\n",
      "Epoch 28/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.0321\n",
      "Epoch 28: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0914 - accuracy: 0.0321 - val_loss: 1.3940 - val_accuracy: 0.0489\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.0325\n",
      "Epoch 29: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0897 - accuracy: 0.0325 - val_loss: 1.1680 - val_accuracy: 0.0205\n",
      "Epoch 30/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0832 - accuracy: 0.0318\n",
      "Epoch 30: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0834 - accuracy: 0.0318 - val_loss: 1.5188 - val_accuracy: 0.0679\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.0326\n",
      "Epoch 31: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0676 - accuracy: 0.0326 - val_loss: 1.3509 - val_accuracy: 0.0315\n",
      "Epoch 32/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.0326\n",
      "Epoch 32: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0699 - accuracy: 0.0325 - val_loss: 1.3163 - val_accuracy: 0.0210\n",
      "Epoch 33/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.0330\n",
      "Epoch 33: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0649 - accuracy: 0.0326 - val_loss: 1.4247 - val_accuracy: 0.0170\n",
      "Epoch 34/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0664 - accuracy: 0.0319\n",
      "Epoch 34: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0658 - accuracy: 0.0321 - val_loss: 1.3352 - val_accuracy: 0.0185\n",
      "Epoch 35/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.0328\n",
      "Epoch 35: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0537 - accuracy: 0.0327 - val_loss: 1.5004 - val_accuracy: 0.0155\n",
      "Epoch 36/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.0324\n",
      "Epoch 36: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0625 - accuracy: 0.0322 - val_loss: 1.5244 - val_accuracy: 0.0310\n",
      "Epoch 37/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.0319\n",
      "Epoch 37: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0554 - accuracy: 0.0317 - val_loss: 1.3940 - val_accuracy: 0.0190\n",
      "Epoch 38/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.0324\n",
      "Epoch 38: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0446 - accuracy: 0.0325 - val_loss: 1.4271 - val_accuracy: 0.0439\n",
      "Epoch 39/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.0320\n",
      "Epoch 39: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0354 - accuracy: 0.0321 - val_loss: 1.6316 - val_accuracy: 0.0290\n",
      "Epoch 40/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.0329\n",
      "Epoch 40: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0414 - accuracy: 0.0328 - val_loss: 1.4199 - val_accuracy: 0.0429\n",
      "Epoch 41/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.0327\n",
      "Epoch 41: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0404 - accuracy: 0.0322 - val_loss: 1.6575 - val_accuracy: 0.0120\n",
      "Epoch 42/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.0330\n",
      "Epoch 42: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0555 - accuracy: 0.0330 - val_loss: 1.8259 - val_accuracy: 0.0220\n",
      "Epoch 43/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.0325\n",
      "Epoch 43: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0425 - accuracy: 0.0323 - val_loss: 1.5974 - val_accuracy: 0.0409\n",
      "Epoch 44/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.0323\n",
      "Epoch 44: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 8ms/step - loss: 0.0334 - accuracy: 0.0325 - val_loss: 1.6954 - val_accuracy: 0.0364\n",
      "Epoch 45/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.0321\n",
      "Epoch 45: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0318 - accuracy: 0.0322 - val_loss: 1.5222 - val_accuracy: 0.0220\n",
      "Epoch 46/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.0325\n",
      "Epoch 46: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0408 - accuracy: 0.0323 - val_loss: 1.7046 - val_accuracy: 0.0185\n",
      "Epoch 47/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.0324\n",
      "Epoch 47: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0316 - accuracy: 0.0322 - val_loss: 1.6551 - val_accuracy: 0.0270\n",
      "Epoch 48/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.0326\n",
      "Epoch 48: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0216 - accuracy: 0.0330 - val_loss: 1.8556 - val_accuracy: 0.0464\n",
      "Epoch 49/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.0320\n",
      "Epoch 49: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0532 - accuracy: 0.0321 - val_loss: 1.7614 - val_accuracy: 0.0205\n",
      "Epoch 50/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.0328\n",
      "Epoch 50: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0263 - accuracy: 0.0327 - val_loss: 1.7081 - val_accuracy: 0.0339\n",
      "Epoch 51/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.0324\n",
      "Epoch 51: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0408 - accuracy: 0.0326 - val_loss: 1.6831 - val_accuracy: 0.0344\n",
      "Epoch 52/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.0319\n",
      "Epoch 52: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0288 - accuracy: 0.0322 - val_loss: 1.8105 - val_accuracy: 0.0409\n",
      "Epoch 53/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.0320\n",
      "Epoch 53: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0314 - accuracy: 0.0322 - val_loss: 1.9914 - val_accuracy: 0.0549\n",
      "Epoch 54/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.0328\n",
      "Epoch 54: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0213 - accuracy: 0.0327 - val_loss: 1.8091 - val_accuracy: 0.0454\n",
      "Epoch 55/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.0328\n",
      "Epoch 55: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0258 - accuracy: 0.0327 - val_loss: 1.7270 - val_accuracy: 0.0195\n",
      "Epoch 56/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.0329\n",
      "Epoch 56: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0256 - accuracy: 0.0330 - val_loss: 1.7525 - val_accuracy: 0.0245\n",
      "Epoch 57/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.0318\n",
      "Epoch 57: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0385 - accuracy: 0.0320 - val_loss: 1.6616 - val_accuracy: 0.0245\n",
      "Epoch 58/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.0328\n",
      "Epoch 58: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0217 - accuracy: 0.0325 - val_loss: 1.6694 - val_accuracy: 0.0225\n",
      "Epoch 59/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.0325\n",
      "Epoch 59: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0232 - accuracy: 0.0327 - val_loss: 1.7313 - val_accuracy: 0.0210\n",
      "Epoch 60/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.0326\n",
      "Epoch 60: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0161 - accuracy: 0.0327 - val_loss: 1.8522 - val_accuracy: 0.0330\n",
      "Epoch 61/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.0324\n",
      "Epoch 61: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0342 - accuracy: 0.0323 - val_loss: 1.9542 - val_accuracy: 0.0454\n",
      "Epoch 62/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.0328\n",
      "Epoch 62: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0374 - accuracy: 0.0328 - val_loss: 2.1178 - val_accuracy: 0.0075\n",
      "Epoch 63/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.0320\n",
      "Epoch 63: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0328 - accuracy: 0.0323 - val_loss: 1.6894 - val_accuracy: 0.0305\n",
      "Epoch 64/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.0327\n",
      "Epoch 64: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0173 - accuracy: 0.0327 - val_loss: 1.7329 - val_accuracy: 0.0449\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.0328\n",
      "Epoch 65: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0224 - accuracy: 0.0328 - val_loss: 1.8110 - val_accuracy: 0.0474\n",
      "Epoch 66/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.0324\n",
      "Epoch 66: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0208 - accuracy: 0.0327 - val_loss: 1.7943 - val_accuracy: 0.0255\n",
      "Epoch 67/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.0326\n",
      "Epoch 67: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0171 - accuracy: 0.0326 - val_loss: 1.7905 - val_accuracy: 0.0185\n",
      "Epoch 68/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.0332\n",
      "Epoch 68: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0317 - accuracy: 0.0330 - val_loss: 1.9990 - val_accuracy: 0.0115\n",
      "Epoch 69/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.0328\n",
      "Epoch 69: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0345 - accuracy: 0.0325 - val_loss: 1.9971 - val_accuracy: 0.0185\n",
      "Epoch 70/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.0325\n",
      "Epoch 70: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0386 - accuracy: 0.0325 - val_loss: 1.8816 - val_accuracy: 0.0305\n",
      "Epoch 71/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.0324\n",
      "Epoch 71: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0228 - accuracy: 0.0323 - val_loss: 1.7778 - val_accuracy: 0.0399\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.0326\n",
      "Epoch 72: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0105 - accuracy: 0.0326 - val_loss: 2.0156 - val_accuracy: 0.0300\n",
      "Epoch 73/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.0325\n",
      "Epoch 73: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0083 - accuracy: 0.0325 - val_loss: 1.7973 - val_accuracy: 0.0150\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.0326\n",
      "Epoch 74: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0049 - accuracy: 0.0326 - val_loss: 1.7295 - val_accuracy: 0.0339\n",
      "Epoch 75/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.0320\n",
      "Epoch 75: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0307 - accuracy: 0.0322 - val_loss: 1.8566 - val_accuracy: 0.0310\n",
      "Epoch 76/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.0326\n",
      "Epoch 76: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0526 - accuracy: 0.0330 - val_loss: 2.0257 - val_accuracy: 0.0624\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.0330\n",
      "Epoch 77: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0228 - accuracy: 0.0330 - val_loss: 1.7950 - val_accuracy: 0.0250\n",
      "Epoch 78/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.0324\n",
      "Epoch 78: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0088 - accuracy: 0.0323 - val_loss: 1.7986 - val_accuracy: 0.0120\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.0326\n",
      "Epoch 79: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0072 - accuracy: 0.0326 - val_loss: 1.8029 - val_accuracy: 0.0260\n",
      "Epoch 80/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.0324\n",
      "Epoch 80: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0189 - accuracy: 0.0325 - val_loss: 1.9240 - val_accuracy: 0.0215\n",
      "Epoch 81/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.0324\n",
      "Epoch 81: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0104 - accuracy: 0.0326 - val_loss: 1.8893 - val_accuracy: 0.0235\n",
      "Epoch 82/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.0325\n",
      "Epoch 82: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0252 - accuracy: 0.0325 - val_loss: 2.5066 - val_accuracy: 0.0130\n",
      "Epoch 83/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.0326\n",
      "Epoch 83: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 13ms/step - loss: 0.0431 - accuracy: 0.0325 - val_loss: 1.9966 - val_accuracy: 0.0160\n",
      "Epoch 84/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.0322\n",
      "Epoch 84: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0180 - accuracy: 0.0323 - val_loss: 1.7643 - val_accuracy: 0.0270\n",
      "Epoch 85/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.0323\n",
      "Epoch 85: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0079 - accuracy: 0.0325 - val_loss: 1.9552 - val_accuracy: 0.0320\n",
      "Epoch 86/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.0325\n",
      "Epoch 86: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0054 - accuracy: 0.0325 - val_loss: 1.9470 - val_accuracy: 0.0474\n",
      "Epoch 87/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.0326\n",
      "Epoch 87: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0238 - accuracy: 0.0327 - val_loss: 2.1041 - val_accuracy: 0.0270\n",
      "Epoch 88/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0386 - accuracy: 0.0326\n",
      "Epoch 88: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0384 - accuracy: 0.0330 - val_loss: 1.9845 - val_accuracy: 0.0524\n",
      "Epoch 89/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.0330\n",
      "Epoch 89: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0208 - accuracy: 0.0328 - val_loss: 1.8393 - val_accuracy: 0.0384\n",
      "Epoch 90/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.0328\n",
      "Epoch 90: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0299 - accuracy: 0.0328 - val_loss: 1.8430 - val_accuracy: 0.0230\n",
      "Epoch 91/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.0323\n",
      "Epoch 91: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0073 - accuracy: 0.0323 - val_loss: 1.9770 - val_accuracy: 0.0669\n",
      "Epoch 92/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.0328\n",
      "Epoch 92: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0025 - accuracy: 0.0326 - val_loss: 1.8327 - val_accuracy: 0.0275\n",
      "Epoch 93/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.0329\n",
      "Epoch 93: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0093 - accuracy: 0.0325 - val_loss: 1.9232 - val_accuracy: 0.0325\n",
      "Epoch 94/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.0329\n",
      "Epoch 94: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0310 - accuracy: 0.0326 - val_loss: 2.0703 - val_accuracy: 0.0105\n",
      "Epoch 95/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.0324\n",
      "Epoch 95: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0317 - accuracy: 0.0325 - val_loss: 1.8399 - val_accuracy: 0.0190\n",
      "Epoch 96/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.0330\n",
      "Epoch 96: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0183 - accuracy: 0.0330 - val_loss: 2.1992 - val_accuracy: 0.0055\n",
      "Epoch 97/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.0328\n",
      "Epoch 97: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0114 - accuracy: 0.0326 - val_loss: 2.0030 - val_accuracy: 0.0579\n",
      "Epoch 98/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.0326\n",
      "Epoch 98: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0058 - accuracy: 0.0326 - val_loss: 1.9317 - val_accuracy: 0.0155\n",
      "Epoch 99/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.0326\n",
      "Epoch 99: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0102 - accuracy: 0.0328 - val_loss: 2.1744 - val_accuracy: 0.0135\n",
      "Epoch 100/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.0324\n",
      "Epoch 100: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0334 - accuracy: 0.0323 - val_loss: 2.1905 - val_accuracy: 0.0105\n",
      "Epoch 101/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.0326\n",
      "Epoch 101: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0273 - accuracy: 0.0327 - val_loss: 1.9454 - val_accuracy: 0.0230\n",
      "Epoch 102/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.0327\n",
      "Epoch 102: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0077 - accuracy: 0.0325 - val_loss: 1.8803 - val_accuracy: 0.0155\n",
      "Epoch 103/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.0328\n",
      "Epoch 103: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0062 - accuracy: 0.0326 - val_loss: 1.9793 - val_accuracy: 0.0145\n",
      "Epoch 104/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.0325\n",
      "Epoch 104: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0070 - accuracy: 0.0325 - val_loss: 1.9364 - val_accuracy: 0.0180\n",
      "Epoch 105/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.0323\n",
      "Epoch 105: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0047 - accuracy: 0.0326 - val_loss: 2.0978 - val_accuracy: 0.0145\n",
      "Epoch 106/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.0328\n",
      "Epoch 106: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0349 - accuracy: 0.0327 - val_loss: 2.4836 - val_accuracy: 0.0105\n",
      "Epoch 107/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.0320\n",
      "Epoch 107: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0363 - accuracy: 0.0320 - val_loss: 2.1577 - val_accuracy: 0.0090\n",
      "Epoch 108/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.0330\n",
      "Epoch 108: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0071 - accuracy: 0.0327 - val_loss: 1.9307 - val_accuracy: 0.0205\n",
      "Epoch 109/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.0327\n",
      "Epoch 109: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0066 - accuracy: 0.0323 - val_loss: 2.0337 - val_accuracy: 0.0205\n",
      "Epoch 110/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.0325\n",
      "Epoch 110: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0042 - accuracy: 0.0325 - val_loss: 1.9758 - val_accuracy: 0.0200\n",
      "Epoch 111/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.0326\n",
      "Epoch 111: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0021 - accuracy: 0.0326 - val_loss: 1.9855 - val_accuracy: 0.0359\n",
      "Epoch 112/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.0325\n",
      "Epoch 112: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0029 - accuracy: 0.0326 - val_loss: 2.3416 - val_accuracy: 0.0040\n",
      "Epoch 113/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.0328\n",
      "Epoch 113: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0662 - accuracy: 0.0331 - val_loss: 2.1269 - val_accuracy: 0.0225\n",
      "Epoch 114/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.0324\n",
      "Epoch 114: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0239 - accuracy: 0.0325 - val_loss: 1.9370 - val_accuracy: 0.0115\n",
      "Epoch 115/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.0324\n",
      "Epoch 115: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0180 - accuracy: 0.0328 - val_loss: 2.0854 - val_accuracy: 0.0035\n",
      "Epoch 116/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.0326\n",
      "Epoch 116: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0079 - accuracy: 0.0326 - val_loss: 1.8874 - val_accuracy: 0.0330\n",
      "Epoch 117/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.0325\n",
      "Epoch 117: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0028 - accuracy: 0.0326 - val_loss: 1.8856 - val_accuracy: 0.0260\n",
      "Epoch 118/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.0326\n",
      "Epoch 118: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0024 - accuracy: 0.0326 - val_loss: 2.0252 - val_accuracy: 0.0245\n",
      "Epoch 119/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.0325\n",
      "Epoch 119: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0132 - accuracy: 0.0323 - val_loss: 2.4466 - val_accuracy: 0.0290\n",
      "Epoch 120/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0348 - accuracy: 0.0325\n",
      "Epoch 120: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0346 - accuracy: 0.0326 - val_loss: 3.3678 - val_accuracy: 0.1238\n",
      "Epoch 121/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.0326\n",
      "Epoch 121: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0131 - accuracy: 0.0326 - val_loss: 1.8767 - val_accuracy: 0.0230\n",
      "Epoch 122/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.0321\n",
      "Epoch 122: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0120 - accuracy: 0.0325 - val_loss: 2.0454 - val_accuracy: 0.0185\n",
      "Epoch 123/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.0325\n",
      "Epoch 123: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0150 - accuracy: 0.0323 - val_loss: 1.9219 - val_accuracy: 0.0295\n",
      "Epoch 124/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.0329\n",
      "Epoch 124: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0117 - accuracy: 0.0327 - val_loss: 2.1176 - val_accuracy: 0.0135\n",
      "Epoch 125/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.0324\n",
      "Epoch 125: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0149 - accuracy: 0.0325 - val_loss: 2.6125 - val_accuracy: 0.0240\n",
      "Epoch 126/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.0325\n",
      "Epoch 126: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0152 - accuracy: 0.0326 - val_loss: 1.9429 - val_accuracy: 0.0185\n",
      "Epoch 127/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.0326\n",
      "Epoch 127: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0035 - accuracy: 0.0326 - val_loss: 2.0128 - val_accuracy: 0.0315\n",
      "Epoch 128/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.0324\n",
      "Epoch 128: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0066 - accuracy: 0.0323 - val_loss: 3.1811 - val_accuracy: 0.0824\n",
      "Epoch 129/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.0323\n",
      "Epoch 129: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0231 - accuracy: 0.0325 - val_loss: 2.2047 - val_accuracy: 0.0409\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.0325\n",
      "Epoch 130: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0299 - accuracy: 0.0325 - val_loss: 2.4923 - val_accuracy: 0.0639\n",
      "Epoch 131/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.0326\n",
      "Epoch 131: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0241 - accuracy: 0.0326 - val_loss: 2.3265 - val_accuracy: 0.0085\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.0325\n",
      "Epoch 132: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0098 - accuracy: 0.0325 - val_loss: 1.9626 - val_accuracy: 0.0220\n",
      "Epoch 133/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.0323\n",
      "Epoch 133: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0021 - accuracy: 0.0326 - val_loss: 1.9557 - val_accuracy: 0.0305\n",
      "Epoch 134/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 9.6583e-04 - accuracy: 0.0326\n",
      "Epoch 134: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 9.6562e-04 - accuracy: 0.0326 - val_loss: 1.9865 - val_accuracy: 0.0215\n",
      "Epoch 135/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 6.2827e-04 - accuracy: 0.0323\n",
      "Epoch 135: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 6.4161e-04 - accuracy: 0.0326 - val_loss: 1.9768 - val_accuracy: 0.0215\n",
      "Epoch 136/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 9.3815e-04 - accuracy: 0.0325\n",
      "Epoch 136: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 9.5086e-04 - accuracy: 0.0326 - val_loss: 2.0149 - val_accuracy: 0.0285\n",
      "Epoch 137/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.0325\n",
      "Epoch 137: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0043 - accuracy: 0.0326 - val_loss: 2.2258 - val_accuracy: 0.0220\n",
      "Epoch 138/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.0327\n",
      "Epoch 138: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0544 - accuracy: 0.0330 - val_loss: 2.1386 - val_accuracy: 0.0195\n",
      "Epoch 139/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.0326\n",
      "Epoch 139: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0173 - accuracy: 0.0326 - val_loss: 1.9770 - val_accuracy: 0.0165\n",
      "Epoch 140/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.0328\n",
      "Epoch 140: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0044 - accuracy: 0.0327 - val_loss: 2.0283 - val_accuracy: 0.0240\n",
      "Epoch 141/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.0325\n",
      "Epoch 141: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0034 - accuracy: 0.0325 - val_loss: 2.2915 - val_accuracy: 0.0180\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.0327\n",
      "Epoch 142: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0097 - accuracy: 0.0327 - val_loss: 2.0344 - val_accuracy: 0.0245\n",
      "Epoch 143/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.0325\n",
      "Epoch 143: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0058 - accuracy: 0.0327 - val_loss: 2.0900 - val_accuracy: 0.0190\n",
      "Epoch 144/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.0328\n",
      "Epoch 144: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0207 - accuracy: 0.0326 - val_loss: 2.1247 - val_accuracy: 0.0295\n",
      "Epoch 145/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.0326\n",
      "Epoch 145: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0263 - accuracy: 0.0327 - val_loss: 2.0801 - val_accuracy: 0.0165\n",
      "Epoch 146/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.0326\n",
      "Epoch 146: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0053 - accuracy: 0.0327 - val_loss: 2.2947 - val_accuracy: 0.0290\n",
      "Epoch 147/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.0330\n",
      "Epoch 147: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0057 - accuracy: 0.0326 - val_loss: 2.1278 - val_accuracy: 0.0424\n",
      "Epoch 148/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.0326\n",
      "Epoch 148: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0019 - accuracy: 0.0326 - val_loss: 2.0997 - val_accuracy: 0.0290\n",
      "Epoch 149/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.0328\n",
      "Epoch 149: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0014 - accuracy: 0.0326 - val_loss: 2.2511 - val_accuracy: 0.0240\n",
      "Epoch 150/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.0324\n",
      "Epoch 150: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0410 - accuracy: 0.0325 - val_loss: 2.4185 - val_accuracy: 0.0305\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.0323\n",
      "Epoch 151: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0364 - accuracy: 0.0323 - val_loss: 2.0454 - val_accuracy: 0.0285\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.0327\n",
      "Epoch 152: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0122 - accuracy: 0.0327 - val_loss: 1.9703 - val_accuracy: 0.0285\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.0326\n",
      "Epoch 153: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 12ms/step - loss: 0.0075 - accuracy: 0.0326 - val_loss: 2.1620 - val_accuracy: 0.0649\n",
      "Epoch 154/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.0321\n",
      "Epoch 154: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0031 - accuracy: 0.0326 - val_loss: 1.9607 - val_accuracy: 0.0290\n",
      "Epoch 155/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 8.4203e-04 - accuracy: 0.0324\n",
      "Epoch 155: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 8.3436e-04 - accuracy: 0.0326 - val_loss: 2.0203 - val_accuracy: 0.0220\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 5.5184e-04 - accuracy: 0.0326\n",
      "Epoch 156: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 5.5184e-04 - accuracy: 0.0326 - val_loss: 2.0419 - val_accuracy: 0.0230\n",
      "Epoch 157/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 4.6543e-04 - accuracy: 0.0324\n",
      "Epoch 157: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 4.6446e-04 - accuracy: 0.0326 - val_loss: 2.0697 - val_accuracy: 0.0195\n",
      "Epoch 158/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 8.5387e-04 - accuracy: 0.0325\n",
      "Epoch 158: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 8.4867e-04 - accuracy: 0.0326 - val_loss: 2.1546 - val_accuracy: 0.0150\n",
      "Epoch 159/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 6.1882e-04 - accuracy: 0.0323\n",
      "Epoch 159: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 6.1632e-04 - accuracy: 0.0326 - val_loss: 2.1211 - val_accuracy: 0.0195\n",
      "Epoch 160/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 4.4413e-04 - accuracy: 0.0324\n",
      "Epoch 160: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 4.4153e-04 - accuracy: 0.0326 - val_loss: 2.1152 - val_accuracy: 0.0280\n",
      "Epoch 161/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.0326\n",
      "Epoch 161: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0202 - accuracy: 0.0323 - val_loss: 2.3859 - val_accuracy: 0.0240\n",
      "Epoch 162/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.0329\n",
      "Epoch 162: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0790 - accuracy: 0.0330 - val_loss: 1.9121 - val_accuracy: 0.0190\n",
      "Epoch 163/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.0320\n",
      "Epoch 163: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0117 - accuracy: 0.0322 - val_loss: 1.8696 - val_accuracy: 0.0225\n",
      "Epoch 164/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.0325\n",
      "Epoch 164: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0068 - accuracy: 0.0326 - val_loss: 1.9045 - val_accuracy: 0.0429\n",
      "Epoch 165/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.0324\n",
      "Epoch 165: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0028 - accuracy: 0.0327 - val_loss: 2.0767 - val_accuracy: 0.0090\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.0326\n",
      "Epoch 166: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0057 - accuracy: 0.0326 - val_loss: 1.9386 - val_accuracy: 0.0260\n",
      "Epoch 167/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.0329\n",
      "Epoch 167: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0060 - accuracy: 0.0326 - val_loss: 2.1433 - val_accuracy: 0.0115\n",
      "Epoch 168/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.0327\n",
      "Epoch 168: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0073 - accuracy: 0.0326 - val_loss: 2.0731 - val_accuracy: 0.0185\n",
      "Epoch 169/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.0328\n",
      "Epoch 169: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0080 - accuracy: 0.0326 - val_loss: 2.5441 - val_accuracy: 0.0364\n",
      "Epoch 170/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.0326\n",
      "Epoch 170: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0323 - accuracy: 0.0327 - val_loss: 2.1389 - val_accuracy: 0.0090\n",
      "Epoch 171/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.0323\n",
      "Epoch 171: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.0144 - accuracy: 0.0325 - val_loss: 2.0737 - val_accuracy: 0.0270\n",
      "Epoch 172/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.0327\n",
      "Epoch 172: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0133 - accuracy: 0.0327 - val_loss: 2.2295 - val_accuracy: 0.0285\n",
      "Epoch 173/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.0324\n",
      "Epoch 173: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0029 - accuracy: 0.0326 - val_loss: 2.0546 - val_accuracy: 0.0310\n",
      "Epoch 174/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.0323\n",
      "Epoch 174: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0023 - accuracy: 0.0325 - val_loss: 2.0911 - val_accuracy: 0.0210\n",
      "Epoch 175/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.0326\n",
      "Epoch 175: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0011 - accuracy: 0.0326 - val_loss: 2.1017 - val_accuracy: 0.0315\n",
      "Epoch 176/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 9.2118e-04 - accuracy: 0.0326\n",
      "Epoch 176: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 9.7851e-04 - accuracy: 0.0326 - val_loss: 2.0524 - val_accuracy: 0.0180\n",
      "Epoch 177/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.0328\n",
      "Epoch 177: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0336 - accuracy: 0.0328 - val_loss: 2.4039 - val_accuracy: 0.0075\n",
      "Epoch 178/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.0325\n",
      "Epoch 178: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0176 - accuracy: 0.0325 - val_loss: 2.1074 - val_accuracy: 0.0534\n",
      "Epoch 179/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.0328\n",
      "Epoch 179: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0040 - accuracy: 0.0326 - val_loss: 2.1892 - val_accuracy: 0.0270\n",
      "Epoch 180/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.0321\n",
      "Epoch 180: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0075 - accuracy: 0.0323 - val_loss: 2.1743 - val_accuracy: 0.0344\n",
      "Epoch 181/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.0329\n",
      "Epoch 181: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0018 - accuracy: 0.0326 - val_loss: 2.1410 - val_accuracy: 0.0190\n",
      "Epoch 182/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 5.1277e-04 - accuracy: 0.0325\n",
      "Epoch 182: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 5.1288e-04 - accuracy: 0.0326 - val_loss: 2.0822 - val_accuracy: 0.0270\n",
      "Epoch 183/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.0325\n",
      "Epoch 183: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0024 - accuracy: 0.0326 - val_loss: 2.2053 - val_accuracy: 0.0100\n",
      "Epoch 184/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.0325\n",
      "Epoch 184: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.0153 - accuracy: 0.0325 - val_loss: 3.1186 - val_accuracy: 0.0065\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.0326\n",
      "Epoch 185: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0379 - accuracy: 0.0326 - val_loss: 2.3288 - val_accuracy: 0.0090\n",
      "Epoch 186/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.0323\n",
      "Epoch 186: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0174 - accuracy: 0.0323 - val_loss: 2.2899 - val_accuracy: 0.0300\n",
      "Epoch 187/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.0326\n",
      "Epoch 187: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0070 - accuracy: 0.0326 - val_loss: 2.1405 - val_accuracy: 0.0210\n",
      "Epoch 188/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.0328\n",
      "Epoch 188: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0050 - accuracy: 0.0326 - val_loss: 2.2558 - val_accuracy: 0.0210\n",
      "Epoch 189/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.0324\n",
      "Epoch 189: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0059 - accuracy: 0.0326 - val_loss: 2.1593 - val_accuracy: 0.0230\n",
      "Epoch 190/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.0325\n",
      "Epoch 190: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0019 - accuracy: 0.0326 - val_loss: 2.1245 - val_accuracy: 0.0245\n",
      "Epoch 191/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.0325\n",
      "Epoch 191: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0069 - accuracy: 0.0326 - val_loss: 2.2591 - val_accuracy: 0.0280\n",
      "Epoch 192/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.0329\n",
      "Epoch 192: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0067 - accuracy: 0.0327 - val_loss: 2.5461 - val_accuracy: 0.0320\n",
      "Epoch 193/200\n",
      "248/251 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.0324\n",
      "Epoch 193: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0291 - accuracy: 0.0322 - val_loss: 2.1059 - val_accuracy: 0.0305\n",
      "Epoch 194/200\n",
      "245/251 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.0324\n",
      "Epoch 194: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0220 - accuracy: 0.0326 - val_loss: 2.3504 - val_accuracy: 0.0305\n",
      "Epoch 195/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.0323\n",
      "Epoch 195: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 10ms/step - loss: 0.0106 - accuracy: 0.0326 - val_loss: 2.1175 - val_accuracy: 0.0255\n",
      "Epoch 196/200\n",
      "249/251 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.0324\n",
      "Epoch 196: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0039 - accuracy: 0.0325 - val_loss: 2.1272 - val_accuracy: 0.0265\n",
      "Epoch 197/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.0326\n",
      "Epoch 197: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0013 - accuracy: 0.0326 - val_loss: 2.1080 - val_accuracy: 0.0230\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.0325\n",
      "Epoch 198: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0086 - accuracy: 0.0325 - val_loss: 2.2363 - val_accuracy: 0.0589\n",
      "Epoch 199/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.0329\n",
      "Epoch 199: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0076 - accuracy: 0.0328 - val_loss: 2.4740 - val_accuracy: 0.0210\n",
      "Epoch 200/200\n",
      "246/251 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.0319\n",
      "Epoch 200: val_loss did not improve from 0.72770\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.0184 - accuracy: 0.0323 - val_loss: 2.3038 - val_accuracy: 0.0744\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 2.3038 - accuracy: 0.0744\n",
      "63/63 [==============================] - 1s 6ms/step\n",
      "model4 trained\n"
     ]
    }
   ],
   "source": [
    "# Define lists to store evaluation metrics\n",
    "acc_scores = []\n",
    "auc_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "mcc_scores = []\n",
    "loss_scores = []\n",
    "cm_list = []\n",
    "y_pred_list = []\n",
    "history_list=[]\n",
    "n_splits=5\n",
    "# Define Stratified K-Fold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "print(\"training model\")\n",
    "i=0\n",
    "for train_index, test_index in skf.split(X_resize, y):\n",
    "    \n",
    "    X_train, X_test = X_resize[train_index], X_resize[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    acc, auc_score, precision, recall, f1, mcc, loss, cm, y_pred,history = train_evaluate_model(X_train, y_train, X_test, y_test,i)\n",
    "    \n",
    "    acc_scores.append(acc)\n",
    "    auc_scores.append(auc_score)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    mcc_scores.append(mcc)\n",
    "    loss_scores.append(loss)\n",
    "    cm_list.append(cm)\n",
    "    y_pred_list.append(y_pred)\n",
    "    history_list.append(history)\n",
    "    print(f\"model{i} trained\")\n",
    "    i+=1\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "mean_acc = np.mean(acc_scores)\n",
    "std_acc = np.std(acc_scores)\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "\n",
    "mean_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "\n",
    "mean_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "\n",
    "mean_mcc = np.mean(mcc_scores)\n",
    "std_mcc = np.std(mcc_scores)\n",
    "\n",
    "mean_loss = np.mean(loss_scores)\n",
    "std_loss = np.std(loss_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics per Model:\n",
      "     Model  Accuracy       AUC  Precision    Recall  F1 Score       MCC  \\\n",
      "0  Model 0  0.730904  0.907976   0.723946  0.730904  0.715673  0.463591   \n",
      "1  Model 1  0.740389  0.896439   0.733883  0.740389  0.733868  0.486779   \n",
      "2  Model 2  0.745382  0.909781   0.730433  0.745382  0.733843  0.488955   \n",
      "3  Model 3  0.736395  0.890267   0.705984  0.736395  0.713863  0.446930   \n",
      "4  Model 4  0.705941  0.884838   0.720262  0.705941  0.709737  0.450120   \n",
      "\n",
      "       Loss  \n",
      "0  2.124256  \n",
      "1  1.900169  \n",
      "2  2.002961  \n",
      "3  2.421261  \n",
      "4  2.303769  \n",
      "Performance Metrics of all models:\n",
      "      Metric      Mean   Std Dev\n",
      "0   Accuracy  0.731802  0.013776\n",
      "1        AUC  0.897860  0.009733\n",
      "2  Precision  0.722902  0.009712\n",
      "3     Recall  0.731802  0.013776\n",
      "4   F1 Score  0.721397  0.010353\n",
      "5        MCC  0.467275  0.017732\n",
      "6       Loss  2.150483  0.190749\n"
     ]
    }
   ],
   "source": [
    "results_per_model = pd.DataFrame({\n",
    "    \"Model\": [f\"Model {i}\" for i in range(n_splits)],\n",
    "    \"Accuracy\": acc_scores,\n",
    "    \"AUC\": auc_scores,\n",
    "    \"Precision\": precision_scores,\n",
    "    \"Recall\": recall_scores,\n",
    "    \"F1 Score\": f1_scores,\n",
    "    \"MCC\": mcc_scores,\n",
    "    \"Loss\": loss_scores\n",
    "})\n",
    "print(\"Performance Metrics per Model:\")\n",
    "print(results_per_model)\n",
    "\n",
    "# Display results in a table\n",
    "results_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"AUC\", \"Precision\", \"Recall\", \"F1 Score\", \"MCC\", \"Loss\"],\n",
    "    \"Mean\": [mean_acc, mean_auc, mean_precision, mean_recall, mean_f1, mean_mcc, mean_loss],\n",
    "    \"Std Dev\": [std_acc, std_auc, std_precision, std_recall, std_f1, std_mcc, std_loss]\n",
    "})\n",
    "\n",
    "print(\"Performance Metrics of all models:\")\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model : 2\n",
      "\n",
      "Confusion Matrix of the Best Model (Maximized AUC):\n",
      "[[  22   13   16    1    5    1    7]\n",
      " [   6   47   26    1   18    1    4]\n",
      " [  14   10  105    0   70    1   20]\n",
      " [   1    7    2    2   10    0    1]\n",
      " [   9    5   53    0 1223    1   50]\n",
      " [   0    0    0    0    9   17    3]\n",
      " [   4    4   40    0   97    0   77]]\n",
      "Lengths of y_test and best_y_pred are equal.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix of the best model\n",
    "best_auc_index = np.argmax(auc_scores)\n",
    "print(\"Best Model : \" + str(best_auc_index))\n",
    "best_cm = cm_list[best_auc_index]\n",
    "print(\"\\nConfusion Matrix of the Best Model (Maximized AUC):\")\n",
    "print(best_cm)\n",
    "\n",
    "#Best prediction\n",
    "best_y_pred = y_pred_list[best_auc_index]\n",
    "\n",
    "# Ensure that y_test and best_y_pred have the same length\n",
    "if len(y_test) > len(best_y_pred):\n",
    "    y_test = y_test[:len(best_y_pred)]\n",
    "    print(\"Lengths of y_test and best_y_pred are not equal. Resized y_test to match the length of best_y_pred.\")\n",
    "elif len(best_y_pred) > len(y_test):\n",
    "    best_y_pred = best_y_pred[:len(y_test)]\n",
    "    print(\"Lengths of y_test and best_y_pred are not equal. Resized best_y_pred to match the length of y_test.\")\n",
    "elif len(y_test) == len(best_y_pred):\n",
    "    print(\"Lengths of y_test and best_y_pred are equal.\")\n",
    "# Now, you can plot the curves\n",
    "plot_curves(y_test, best_y_pred, n_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a3966be3d0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "history=history_list[best_auc_index]\n",
    "# Plot mean loss vs epochs for training and validation\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.title('Mean Loss vs Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curves_v2(y_test, best_y_pred, n_classes=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybersecurity-Z7yOgMbu-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
